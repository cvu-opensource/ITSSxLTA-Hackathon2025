{
  "best_global_step": 1915,
  "best_metric": 0.6315542443341826,
  "best_model_checkpoint": "my_awesome_model_more_balanced/checkpoint-1915",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 1915,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02610966057441253,
      "grad_norm": 17.946308135986328,
      "learning_rate": 5.221932114882507e-06,
      "loss": 9.6047,
      "step": 10
    },
    {
      "epoch": 0.05221932114882506,
      "grad_norm": 17.19219398498535,
      "learning_rate": 1.0443864229765014e-05,
      "loss": 8.1139,
      "step": 20
    },
    {
      "epoch": 0.0783289817232376,
      "grad_norm": 16.76392936706543,
      "learning_rate": 1.566579634464752e-05,
      "loss": 5.533,
      "step": 30
    },
    {
      "epoch": 0.10443864229765012,
      "grad_norm": 6.914274215698242,
      "learning_rate": 2.0887728459530027e-05,
      "loss": 2.3608,
      "step": 40
    },
    {
      "epoch": 0.13054830287206268,
      "grad_norm": 4.091241359710693,
      "learning_rate": 2.6109660574412533e-05,
      "loss": 0.8324,
      "step": 50
    },
    {
      "epoch": 0.1566579634464752,
      "grad_norm": 3.3840792179107666,
      "learning_rate": 3.133159268929504e-05,
      "loss": 0.5492,
      "step": 60
    },
    {
      "epoch": 0.18276762402088773,
      "grad_norm": 2.401167392730713,
      "learning_rate": 3.6553524804177546e-05,
      "loss": 0.4687,
      "step": 70
    },
    {
      "epoch": 0.20887728459530025,
      "grad_norm": 1.9035714864730835,
      "learning_rate": 4.1775456919060055e-05,
      "loss": 0.3796,
      "step": 80
    },
    {
      "epoch": 0.2349869451697128,
      "grad_norm": 1.81691312789917,
      "learning_rate": 4.6997389033942557e-05,
      "loss": 0.3594,
      "step": 90
    },
    {
      "epoch": 0.26109660574412535,
      "grad_norm": 2.960916519165039,
      "learning_rate": 5.2219321148825065e-05,
      "loss": 0.2909,
      "step": 100
    },
    {
      "epoch": 0.28720626631853785,
      "grad_norm": 3.1666572093963623,
      "learning_rate": 5.7441253263707574e-05,
      "loss": 0.2918,
      "step": 110
    },
    {
      "epoch": 0.3133159268929504,
      "grad_norm": 2.78542423248291,
      "learning_rate": 6.266318537859008e-05,
      "loss": 0.37,
      "step": 120
    },
    {
      "epoch": 0.3394255874673629,
      "grad_norm": 1.4770156145095825,
      "learning_rate": 6.78851174934726e-05,
      "loss": 0.301,
      "step": 130
    },
    {
      "epoch": 0.36553524804177545,
      "grad_norm": 7.606187343597412,
      "learning_rate": 7.310704960835509e-05,
      "loss": 0.3307,
      "step": 140
    },
    {
      "epoch": 0.391644908616188,
      "grad_norm": 6.2681474685668945,
      "learning_rate": 7.83289817232376e-05,
      "loss": 0.2701,
      "step": 150
    },
    {
      "epoch": 0.4177545691906005,
      "grad_norm": 2.6272192001342773,
      "learning_rate": 8.355091383812011e-05,
      "loss": 0.2748,
      "step": 160
    },
    {
      "epoch": 0.44386422976501305,
      "grad_norm": 3.9255130290985107,
      "learning_rate": 8.877284595300262e-05,
      "loss": 0.2245,
      "step": 170
    },
    {
      "epoch": 0.4699738903394256,
      "grad_norm": 5.870166301727295,
      "learning_rate": 9.399477806788511e-05,
      "loss": 0.2565,
      "step": 180
    },
    {
      "epoch": 0.4960835509138381,
      "grad_norm": 4.433294773101807,
      "learning_rate": 9.921671018276762e-05,
      "loss": 0.2525,
      "step": 190
    },
    {
      "epoch": 0.5221932114882507,
      "grad_norm": 3.490124464035034,
      "learning_rate": 0.00010443864229765013,
      "loss": 0.2276,
      "step": 200
    },
    {
      "epoch": 0.5483028720626631,
      "grad_norm": 1.6793863773345947,
      "learning_rate": 0.00010966057441253265,
      "loss": 0.2306,
      "step": 210
    },
    {
      "epoch": 0.5744125326370757,
      "grad_norm": 4.286341190338135,
      "learning_rate": 0.00011488250652741515,
      "loss": 0.1827,
      "step": 220
    },
    {
      "epoch": 0.6005221932114883,
      "grad_norm": 2.6080515384674072,
      "learning_rate": 0.00012010443864229766,
      "loss": 0.2336,
      "step": 230
    },
    {
      "epoch": 0.6266318537859008,
      "grad_norm": 4.004640579223633,
      "learning_rate": 0.00012532637075718015,
      "loss": 0.2229,
      "step": 240
    },
    {
      "epoch": 0.6527415143603134,
      "grad_norm": 2.2009191513061523,
      "learning_rate": 0.0001305483028720627,
      "loss": 0.2443,
      "step": 250
    },
    {
      "epoch": 0.6788511749347258,
      "grad_norm": 1.611212134361267,
      "learning_rate": 0.0001357702349869452,
      "loss": 0.2078,
      "step": 260
    },
    {
      "epoch": 0.7049608355091384,
      "grad_norm": 5.583144664764404,
      "learning_rate": 0.00014099216710182768,
      "loss": 0.2753,
      "step": 270
    },
    {
      "epoch": 0.7310704960835509,
      "grad_norm": 3.490934133529663,
      "learning_rate": 0.00014621409921671019,
      "loss": 0.1958,
      "step": 280
    },
    {
      "epoch": 0.7571801566579635,
      "grad_norm": 1.7219780683517456,
      "learning_rate": 0.0001514360313315927,
      "loss": 0.1879,
      "step": 290
    },
    {
      "epoch": 0.783289817232376,
      "grad_norm": 2.9462928771972656,
      "learning_rate": 0.0001566579634464752,
      "loss": 0.2313,
      "step": 300
    },
    {
      "epoch": 0.8093994778067886,
      "grad_norm": 1.765010118484497,
      "learning_rate": 0.0001618798955613577,
      "loss": 0.1756,
      "step": 310
    },
    {
      "epoch": 0.835509138381201,
      "grad_norm": 4.450467109680176,
      "learning_rate": 0.00016710182767624022,
      "loss": 0.1637,
      "step": 320
    },
    {
      "epoch": 0.8616187989556136,
      "grad_norm": 2.7867486476898193,
      "learning_rate": 0.00017232375979112273,
      "loss": 0.2382,
      "step": 330
    },
    {
      "epoch": 0.8877284595300261,
      "grad_norm": 1.421220302581787,
      "learning_rate": 0.00017754569190600524,
      "loss": 0.2142,
      "step": 340
    },
    {
      "epoch": 0.9138381201044387,
      "grad_norm": 2.719564914703369,
      "learning_rate": 0.00018276762402088772,
      "loss": 0.1779,
      "step": 350
    },
    {
      "epoch": 0.9399477806788512,
      "grad_norm": 2.027235269546509,
      "learning_rate": 0.00018798955613577023,
      "loss": 0.2102,
      "step": 360
    },
    {
      "epoch": 0.9660574412532638,
      "grad_norm": 4.8482794761657715,
      "learning_rate": 0.00019321148825065273,
      "loss": 0.1979,
      "step": 370
    },
    {
      "epoch": 0.9921671018276762,
      "grad_norm": 1.2535954713821411,
      "learning_rate": 0.00019843342036553524,
      "loss": 0.2315,
      "step": 380
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5956819096151267,
      "eval_loss": 0.9483075141906738,
      "eval_runtime": 270.0907,
      "eval_samples_per_second": 55.218,
      "eval_steps_per_second": 3.454,
      "step": 383
    },
    {
      "epoch": 1.0182767624020888,
      "grad_norm": 3.12469744682312,
      "learning_rate": 0.00020365535248041775,
      "loss": 0.1664,
      "step": 390
    },
    {
      "epoch": 1.0443864229765012,
      "grad_norm": 2.5142910480499268,
      "learning_rate": 0.00020887728459530026,
      "loss": 0.1671,
      "step": 400
    },
    {
      "epoch": 1.0704960835509139,
      "grad_norm": 2.3418617248535156,
      "learning_rate": 0.00021409921671018277,
      "loss": 0.1508,
      "step": 410
    },
    {
      "epoch": 1.0966057441253263,
      "grad_norm": 0.43511030077934265,
      "learning_rate": 0.0002193211488250653,
      "loss": 0.115,
      "step": 420
    },
    {
      "epoch": 1.122715404699739,
      "grad_norm": 1.8191475868225098,
      "learning_rate": 0.00022454308093994779,
      "loss": 0.198,
      "step": 430
    },
    {
      "epoch": 1.1488250652741514,
      "grad_norm": 1.3093862533569336,
      "learning_rate": 0.0002297650130548303,
      "loss": 0.1895,
      "step": 440
    },
    {
      "epoch": 1.174934725848564,
      "grad_norm": 2.39597225189209,
      "learning_rate": 0.0002349869451697128,
      "loss": 0.2134,
      "step": 450
    },
    {
      "epoch": 1.2010443864229765,
      "grad_norm": 1.6521369218826294,
      "learning_rate": 0.0002402088772845953,
      "loss": 0.1902,
      "step": 460
    },
    {
      "epoch": 1.227154046997389,
      "grad_norm": 1.6876541376113892,
      "learning_rate": 0.0002454308093994778,
      "loss": 0.2403,
      "step": 470
    },
    {
      "epoch": 1.2532637075718016,
      "grad_norm": 1.8780542612075806,
      "learning_rate": 0.0002506527415143603,
      "loss": 0.1617,
      "step": 480
    },
    {
      "epoch": 1.279373368146214,
      "grad_norm": 3.368678092956543,
      "learning_rate": 0.00025587467362924284,
      "loss": 0.208,
      "step": 490
    },
    {
      "epoch": 1.3054830287206267,
      "grad_norm": 2.093738079071045,
      "learning_rate": 0.0002610966057441254,
      "loss": 0.2067,
      "step": 500
    },
    {
      "epoch": 1.3315926892950392,
      "grad_norm": 1.3396846055984497,
      "learning_rate": 0.00026631853785900785,
      "loss": 0.1225,
      "step": 510
    },
    {
      "epoch": 1.3577023498694518,
      "grad_norm": 1.5334959030151367,
      "learning_rate": 0.0002715404699738904,
      "loss": 0.1828,
      "step": 520
    },
    {
      "epoch": 1.3838120104438643,
      "grad_norm": 0.9651405811309814,
      "learning_rate": 0.00027676240208877287,
      "loss": 0.176,
      "step": 530
    },
    {
      "epoch": 1.4099216710182767,
      "grad_norm": 5.622433185577393,
      "learning_rate": 0.00028198433420365535,
      "loss": 0.2538,
      "step": 540
    },
    {
      "epoch": 1.4360313315926894,
      "grad_norm": 1.349848985671997,
      "learning_rate": 0.00028720626631853783,
      "loss": 0.2531,
      "step": 550
    },
    {
      "epoch": 1.4621409921671018,
      "grad_norm": 1.654699444770813,
      "learning_rate": 0.00029242819843342037,
      "loss": 0.1598,
      "step": 560
    },
    {
      "epoch": 1.4882506527415145,
      "grad_norm": 1.9523894786834717,
      "learning_rate": 0.00029765013054830285,
      "loss": 0.2146,
      "step": 570
    },
    {
      "epoch": 1.514360313315927,
      "grad_norm": 1.5256439447402954,
      "learning_rate": 0.0003028720626631854,
      "loss": 0.174,
      "step": 580
    },
    {
      "epoch": 1.5404699738903394,
      "grad_norm": 1.894466757774353,
      "learning_rate": 0.00030809399477806787,
      "loss": 0.1799,
      "step": 590
    },
    {
      "epoch": 1.566579634464752,
      "grad_norm": 2.2506656646728516,
      "learning_rate": 0.0003133159268929504,
      "loss": 0.1235,
      "step": 600
    },
    {
      "epoch": 1.5926892950391645,
      "grad_norm": 1.500329613685608,
      "learning_rate": 0.0003185378590078329,
      "loss": 0.2108,
      "step": 610
    },
    {
      "epoch": 1.6187989556135771,
      "grad_norm": 1.7099699974060059,
      "learning_rate": 0.0003237597911227154,
      "loss": 0.2207,
      "step": 620
    },
    {
      "epoch": 1.6449086161879896,
      "grad_norm": 2.0339910984039307,
      "learning_rate": 0.0003289817232375979,
      "loss": 0.2691,
      "step": 630
    },
    {
      "epoch": 1.671018276762402,
      "grad_norm": 1.5426855087280273,
      "learning_rate": 0.00033420365535248044,
      "loss": 0.1785,
      "step": 640
    },
    {
      "epoch": 1.6971279373368147,
      "grad_norm": 1.6345703601837158,
      "learning_rate": 0.0003394255874673629,
      "loss": 0.1704,
      "step": 650
    },
    {
      "epoch": 1.723237597911227,
      "grad_norm": 2.8885345458984375,
      "learning_rate": 0.00034464751958224546,
      "loss": 0.2168,
      "step": 660
    },
    {
      "epoch": 1.7493472584856398,
      "grad_norm": 2.87302303314209,
      "learning_rate": 0.000349869451697128,
      "loss": 0.2149,
      "step": 670
    },
    {
      "epoch": 1.7754569190600522,
      "grad_norm": 1.971517562866211,
      "learning_rate": 0.00035509138381201047,
      "loss": 0.1941,
      "step": 680
    },
    {
      "epoch": 1.8015665796344646,
      "grad_norm": 0.9395660161972046,
      "learning_rate": 0.000360313315926893,
      "loss": 0.146,
      "step": 690
    },
    {
      "epoch": 1.8276762402088773,
      "grad_norm": 3.2822632789611816,
      "learning_rate": 0.00036553524804177544,
      "loss": 0.2287,
      "step": 700
    },
    {
      "epoch": 1.85378590078329,
      "grad_norm": 0.9430159330368042,
      "learning_rate": 0.00037075718015665797,
      "loss": 0.1812,
      "step": 710
    },
    {
      "epoch": 1.8798955613577024,
      "grad_norm": 2.4386396408081055,
      "learning_rate": 0.00037597911227154045,
      "loss": 0.2177,
      "step": 720
    },
    {
      "epoch": 1.9060052219321149,
      "grad_norm": 1.8555184602737427,
      "learning_rate": 0.000381201044386423,
      "loss": 0.1601,
      "step": 730
    },
    {
      "epoch": 1.9321148825065273,
      "grad_norm": 2.4379379749298096,
      "learning_rate": 0.00038642297650130547,
      "loss": 0.161,
      "step": 740
    },
    {
      "epoch": 1.95822454308094,
      "grad_norm": 2.504373073577881,
      "learning_rate": 0.000391644908616188,
      "loss": 0.2229,
      "step": 750
    },
    {
      "epoch": 1.9843342036553526,
      "grad_norm": 1.3688297271728516,
      "learning_rate": 0.0003968668407310705,
      "loss": 0.2176,
      "step": 760
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.5195118680434491,
      "eval_loss": 1.2082442045211792,
      "eval_runtime": 217.1465,
      "eval_samples_per_second": 68.682,
      "eval_steps_per_second": 4.297,
      "step": 766
    },
    {
      "epoch": 2.010443864229765,
      "grad_norm": 1.01714289188385,
      "learning_rate": 0.000402088772845953,
      "loss": 0.1717,
      "step": 770
    },
    {
      "epoch": 2.0365535248041775,
      "grad_norm": 1.7554398775100708,
      "learning_rate": 0.0004073107049608355,
      "loss": 0.1048,
      "step": 780
    },
    {
      "epoch": 2.06266318537859,
      "grad_norm": 2.5276503562927246,
      "learning_rate": 0.00041253263707571804,
      "loss": 0.1906,
      "step": 790
    },
    {
      "epoch": 2.0887728459530024,
      "grad_norm": 1.7639625072479248,
      "learning_rate": 0.0004177545691906005,
      "loss": 0.185,
      "step": 800
    },
    {
      "epoch": 2.1148825065274153,
      "grad_norm": 1.7484503984451294,
      "learning_rate": 0.00042297650130548306,
      "loss": 0.1695,
      "step": 810
    },
    {
      "epoch": 2.1409921671018277,
      "grad_norm": 0.9370795488357544,
      "learning_rate": 0.00042819843342036554,
      "loss": 0.1906,
      "step": 820
    },
    {
      "epoch": 2.16710182767624,
      "grad_norm": 2.685730218887329,
      "learning_rate": 0.0004334203655352481,
      "loss": 0.1934,
      "step": 830
    },
    {
      "epoch": 2.1932114882506526,
      "grad_norm": 1.0377329587936401,
      "learning_rate": 0.0004386422976501306,
      "loss": 0.1738,
      "step": 840
    },
    {
      "epoch": 2.2193211488250655,
      "grad_norm": 2.176839590072632,
      "learning_rate": 0.00044386422976501304,
      "loss": 0.1648,
      "step": 850
    },
    {
      "epoch": 2.245430809399478,
      "grad_norm": 2.3194754123687744,
      "learning_rate": 0.00044908616187989557,
      "loss": 0.1716,
      "step": 860
    },
    {
      "epoch": 2.2715404699738904,
      "grad_norm": 1.1578269004821777,
      "learning_rate": 0.00045430809399477805,
      "loss": 0.1733,
      "step": 870
    },
    {
      "epoch": 2.297650130548303,
      "grad_norm": 3.628868341445923,
      "learning_rate": 0.0004595300261096606,
      "loss": 0.2485,
      "step": 880
    },
    {
      "epoch": 2.3237597911227152,
      "grad_norm": 0.9711304903030396,
      "learning_rate": 0.00046475195822454307,
      "loss": 0.1869,
      "step": 890
    },
    {
      "epoch": 2.349869451697128,
      "grad_norm": 0.9495311379432678,
      "learning_rate": 0.0004699738903394256,
      "loss": 0.1274,
      "step": 900
    },
    {
      "epoch": 2.3759791122715406,
      "grad_norm": 1.0740487575531006,
      "learning_rate": 0.0004751958224543081,
      "loss": 0.1416,
      "step": 910
    },
    {
      "epoch": 2.402088772845953,
      "grad_norm": 1.937583327293396,
      "learning_rate": 0.0004804177545691906,
      "loss": 0.2504,
      "step": 920
    },
    {
      "epoch": 2.4281984334203655,
      "grad_norm": 1.4877369403839111,
      "learning_rate": 0.0004856396866840731,
      "loss": 0.2105,
      "step": 930
    },
    {
      "epoch": 2.454308093994778,
      "grad_norm": 2.240720272064209,
      "learning_rate": 0.0004908616187989556,
      "loss": 0.2357,
      "step": 940
    },
    {
      "epoch": 2.480417754569191,
      "grad_norm": 2.7716875076293945,
      "learning_rate": 0.0004960835509138381,
      "loss": 0.149,
      "step": 950
    },
    {
      "epoch": 2.506527415143603,
      "grad_norm": 0.8599538207054138,
      "learning_rate": 0.0005013054830287206,
      "loss": 0.1827,
      "step": 960
    },
    {
      "epoch": 2.5326370757180157,
      "grad_norm": 1.6747627258300781,
      "learning_rate": 0.0005065274151436031,
      "loss": 0.2158,
      "step": 970
    },
    {
      "epoch": 2.558746736292428,
      "grad_norm": 1.260284662246704,
      "learning_rate": 0.0005117493472584857,
      "loss": 0.1963,
      "step": 980
    },
    {
      "epoch": 2.584856396866841,
      "grad_norm": 2.5713727474212646,
      "learning_rate": 0.0005169712793733682,
      "loss": 0.2004,
      "step": 990
    },
    {
      "epoch": 2.6109660574412534,
      "grad_norm": 2.555398941040039,
      "learning_rate": 0.0005221932114882507,
      "loss": 0.236,
      "step": 1000
    },
    {
      "epoch": 2.637075718015666,
      "grad_norm": 1.6468639373779297,
      "learning_rate": 0.0005274151436031331,
      "loss": 0.1945,
      "step": 1010
    },
    {
      "epoch": 2.6631853785900783,
      "grad_norm": 2.8660566806793213,
      "learning_rate": 0.0005326370757180157,
      "loss": 0.2388,
      "step": 1020
    },
    {
      "epoch": 2.6892950391644908,
      "grad_norm": 1.7758747339248657,
      "learning_rate": 0.0005378590078328982,
      "loss": 0.2356,
      "step": 1030
    },
    {
      "epoch": 2.7154046997389036,
      "grad_norm": 1.257531762123108,
      "learning_rate": 0.0005430809399477808,
      "loss": 0.2426,
      "step": 1040
    },
    {
      "epoch": 2.741514360313316,
      "grad_norm": 2.226226329803467,
      "learning_rate": 0.0005483028720626632,
      "loss": 0.2138,
      "step": 1050
    },
    {
      "epoch": 2.7676240208877285,
      "grad_norm": 2.487786054611206,
      "learning_rate": 0.0005535248041775457,
      "loss": 0.2739,
      "step": 1060
    },
    {
      "epoch": 2.793733681462141,
      "grad_norm": 1.3279402256011963,
      "learning_rate": 0.0005587467362924282,
      "loss": 0.2594,
      "step": 1070
    },
    {
      "epoch": 2.8198433420365534,
      "grad_norm": 1.1058685779571533,
      "learning_rate": 0.0005639686684073107,
      "loss": 0.1922,
      "step": 1080
    },
    {
      "epoch": 2.8459530026109663,
      "grad_norm": 2.582308769226074,
      "learning_rate": 0.0005691906005221932,
      "loss": 0.1716,
      "step": 1090
    },
    {
      "epoch": 2.8720626631853787,
      "grad_norm": 0.9095695614814758,
      "learning_rate": 0.0005744125326370757,
      "loss": 0.1914,
      "step": 1100
    },
    {
      "epoch": 2.898172323759791,
      "grad_norm": 5.982551574707031,
      "learning_rate": 0.0005796344647519583,
      "loss": 0.2865,
      "step": 1110
    },
    {
      "epoch": 2.9242819843342036,
      "grad_norm": 3.2357993125915527,
      "learning_rate": 0.0005848563968668407,
      "loss": 0.2312,
      "step": 1120
    },
    {
      "epoch": 2.950391644908616,
      "grad_norm": 1.0638797283172607,
      "learning_rate": 0.0005900783289817232,
      "loss": 0.2193,
      "step": 1130
    },
    {
      "epoch": 2.976501305483029,
      "grad_norm": 0.9146257638931274,
      "learning_rate": 0.0005953002610966057,
      "loss": 0.201,
      "step": 1140
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.5394930937374279,
      "eval_loss": 1.0465890169143677,
      "eval_runtime": 216.1572,
      "eval_samples_per_second": 68.996,
      "eval_steps_per_second": 4.316,
      "step": 1149
    },
    {
      "epoch": 3.0026109660574414,
      "grad_norm": 1.4583196640014648,
      "learning_rate": 0.0006005221932114883,
      "loss": 0.2076,
      "step": 1150
    },
    {
      "epoch": 3.028720626631854,
      "grad_norm": 4.27601957321167,
      "learning_rate": 0.0006057441253263708,
      "loss": 0.1995,
      "step": 1160
    },
    {
      "epoch": 3.0548302872062663,
      "grad_norm": 0.47857537865638733,
      "learning_rate": 0.0006109660574412534,
      "loss": 0.2246,
      "step": 1170
    },
    {
      "epoch": 3.0809399477806787,
      "grad_norm": 1.153926968574524,
      "learning_rate": 0.0006161879895561357,
      "loss": 0.2665,
      "step": 1180
    },
    {
      "epoch": 3.1070496083550916,
      "grad_norm": 1.1488749980926514,
      "learning_rate": 0.0006214099216710183,
      "loss": 0.218,
      "step": 1190
    },
    {
      "epoch": 3.133159268929504,
      "grad_norm": 2.1426281929016113,
      "learning_rate": 0.0006266318537859008,
      "loss": 0.201,
      "step": 1200
    },
    {
      "epoch": 3.1592689295039165,
      "grad_norm": 2.866730213165283,
      "learning_rate": 0.0006318537859007834,
      "loss": 0.1853,
      "step": 1210
    },
    {
      "epoch": 3.185378590078329,
      "grad_norm": 1.6272860765457153,
      "learning_rate": 0.0006370757180156658,
      "loss": 0.2258,
      "step": 1220
    },
    {
      "epoch": 3.2114882506527413,
      "grad_norm": 1.7675813436508179,
      "learning_rate": 0.0006422976501305483,
      "loss": 0.1776,
      "step": 1230
    },
    {
      "epoch": 3.2375979112271542,
      "grad_norm": 1.599737286567688,
      "learning_rate": 0.0006475195822454308,
      "loss": 0.2317,
      "step": 1240
    },
    {
      "epoch": 3.2637075718015667,
      "grad_norm": 3.1108193397521973,
      "learning_rate": 0.0006527415143603133,
      "loss": 0.2546,
      "step": 1250
    },
    {
      "epoch": 3.289817232375979,
      "grad_norm": 1.2916333675384521,
      "learning_rate": 0.0006579634464751958,
      "loss": 0.2486,
      "step": 1260
    },
    {
      "epoch": 3.3159268929503916,
      "grad_norm": 2.2987589836120605,
      "learning_rate": 0.0006631853785900783,
      "loss": 0.2147,
      "step": 1270
    },
    {
      "epoch": 3.342036553524804,
      "grad_norm": 0.7603431344032288,
      "learning_rate": 0.0006684073107049609,
      "loss": 0.207,
      "step": 1280
    },
    {
      "epoch": 3.368146214099217,
      "grad_norm": 5.001506805419922,
      "learning_rate": 0.0006736292428198434,
      "loss": 0.2154,
      "step": 1290
    },
    {
      "epoch": 3.3942558746736293,
      "grad_norm": 1.1557246446609497,
      "learning_rate": 0.0006788511749347258,
      "loss": 0.1936,
      "step": 1300
    },
    {
      "epoch": 3.4203655352480418,
      "grad_norm": 2.0072786808013916,
      "learning_rate": 0.0006840731070496083,
      "loss": 0.2283,
      "step": 1310
    },
    {
      "epoch": 3.446475195822454,
      "grad_norm": 3.2615840435028076,
      "learning_rate": 0.0006892950391644909,
      "loss": 0.2351,
      "step": 1320
    },
    {
      "epoch": 3.4725848563968666,
      "grad_norm": 1.0873425006866455,
      "learning_rate": 0.0006945169712793734,
      "loss": 0.1844,
      "step": 1330
    },
    {
      "epoch": 3.4986945169712795,
      "grad_norm": 1.7652713060379028,
      "learning_rate": 0.000699738903394256,
      "loss": 0.2166,
      "step": 1340
    },
    {
      "epoch": 3.524804177545692,
      "grad_norm": 2.2928435802459717,
      "learning_rate": 0.0007049608355091384,
      "loss": 0.1832,
      "step": 1350
    },
    {
      "epoch": 3.5509138381201044,
      "grad_norm": 3.418790340423584,
      "learning_rate": 0.0007101827676240209,
      "loss": 0.3024,
      "step": 1360
    },
    {
      "epoch": 3.577023498694517,
      "grad_norm": 1.3010226488113403,
      "learning_rate": 0.0007154046997389034,
      "loss": 0.2449,
      "step": 1370
    },
    {
      "epoch": 3.6031331592689293,
      "grad_norm": 0.6921146512031555,
      "learning_rate": 0.000720626631853786,
      "loss": 0.1753,
      "step": 1380
    },
    {
      "epoch": 3.629242819843342,
      "grad_norm": 2.0592453479766846,
      "learning_rate": 0.0007258485639686684,
      "loss": 0.2123,
      "step": 1390
    },
    {
      "epoch": 3.6553524804177546,
      "grad_norm": 2.0718672275543213,
      "learning_rate": 0.0007310704960835509,
      "loss": 0.2349,
      "step": 1400
    },
    {
      "epoch": 3.681462140992167,
      "grad_norm": 1.2655158042907715,
      "learning_rate": 0.0007362924281984335,
      "loss": 0.25,
      "step": 1410
    },
    {
      "epoch": 3.7075718015665795,
      "grad_norm": 1.111106276512146,
      "learning_rate": 0.0007415143603133159,
      "loss": 0.2146,
      "step": 1420
    },
    {
      "epoch": 3.733681462140992,
      "grad_norm": 1.020246148109436,
      "learning_rate": 0.0007467362924281984,
      "loss": 0.3176,
      "step": 1430
    },
    {
      "epoch": 3.759791122715405,
      "grad_norm": 0.6359341740608215,
      "learning_rate": 0.0007519582245430809,
      "loss": 0.2212,
      "step": 1440
    },
    {
      "epoch": 3.7859007832898173,
      "grad_norm": 2.284743309020996,
      "learning_rate": 0.0007571801566579635,
      "loss": 0.2392,
      "step": 1450
    },
    {
      "epoch": 3.8120104438642297,
      "grad_norm": 1.2499079704284668,
      "learning_rate": 0.000762402088772846,
      "loss": 0.3176,
      "step": 1460
    },
    {
      "epoch": 3.838120104438642,
      "grad_norm": 4.045180320739746,
      "learning_rate": 0.0007676240208877285,
      "loss": 0.2648,
      "step": 1470
    },
    {
      "epoch": 3.8642297650130546,
      "grad_norm": 0.7389131188392639,
      "learning_rate": 0.0007728459530026109,
      "loss": 0.2643,
      "step": 1480
    },
    {
      "epoch": 3.8903394255874675,
      "grad_norm": 0.9305279850959778,
      "learning_rate": 0.0007780678851174935,
      "loss": 0.1868,
      "step": 1490
    },
    {
      "epoch": 3.91644908616188,
      "grad_norm": 4.703307628631592,
      "learning_rate": 0.000783289817232376,
      "loss": 0.2387,
      "step": 1500
    },
    {
      "epoch": 3.9425587467362924,
      "grad_norm": 2.4562058448791504,
      "learning_rate": 0.0007885117493472586,
      "loss": 0.3242,
      "step": 1510
    },
    {
      "epoch": 3.968668407310705,
      "grad_norm": 0.8549246191978455,
      "learning_rate": 0.000793733681462141,
      "loss": 0.1854,
      "step": 1520
    },
    {
      "epoch": 3.9947780678851172,
      "grad_norm": 1.5567442178726196,
      "learning_rate": 0.0007989556135770236,
      "loss": 0.2375,
      "step": 1530
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.49121630682580125,
      "eval_loss": 1.2184861898422241,
      "eval_runtime": 216.4449,
      "eval_samples_per_second": 68.904,
      "eval_steps_per_second": 4.311,
      "step": 1532
    },
    {
      "epoch": 4.02088772845953,
      "grad_norm": 1.0676419734954834,
      "learning_rate": 0.000804177545691906,
      "loss": 0.1236,
      "step": 1540
    },
    {
      "epoch": 4.046997389033942,
      "grad_norm": 1.3535051345825195,
      "learning_rate": 0.0008093994778067885,
      "loss": 0.1547,
      "step": 1550
    },
    {
      "epoch": 4.073107049608355,
      "grad_norm": 1.3143093585968018,
      "learning_rate": 0.000814621409921671,
      "loss": 0.221,
      "step": 1560
    },
    {
      "epoch": 4.099216710182768,
      "grad_norm": 0.8082460165023804,
      "learning_rate": 0.0008198433420365535,
      "loss": 0.2437,
      "step": 1570
    },
    {
      "epoch": 4.12532637075718,
      "grad_norm": 0.9909085035324097,
      "learning_rate": 0.0008250652741514361,
      "loss": 0.175,
      "step": 1580
    },
    {
      "epoch": 4.151436031331593,
      "grad_norm": 1.9388383626937866,
      "learning_rate": 0.0008302872062663186,
      "loss": 0.2022,
      "step": 1590
    },
    {
      "epoch": 4.177545691906005,
      "grad_norm": 0.717997133731842,
      "learning_rate": 0.000835509138381201,
      "loss": 0.2095,
      "step": 1600
    },
    {
      "epoch": 4.203655352480418,
      "grad_norm": 1.5714972019195557,
      "learning_rate": 0.0008407310704960835,
      "loss": 0.2615,
      "step": 1610
    },
    {
      "epoch": 4.2297650130548305,
      "grad_norm": 2.5060949325561523,
      "learning_rate": 0.0008459530026109661,
      "loss": 0.2378,
      "step": 1620
    },
    {
      "epoch": 4.2558746736292425,
      "grad_norm": 1.373615026473999,
      "learning_rate": 0.0008511749347258486,
      "loss": 0.2129,
      "step": 1630
    },
    {
      "epoch": 4.281984334203655,
      "grad_norm": 2.024733781814575,
      "learning_rate": 0.0008563968668407311,
      "loss": 0.2627,
      "step": 1640
    },
    {
      "epoch": 4.308093994778067,
      "grad_norm": 1.006895899772644,
      "learning_rate": 0.0008616187989556136,
      "loss": 0.209,
      "step": 1650
    },
    {
      "epoch": 4.33420365535248,
      "grad_norm": 1.4338908195495605,
      "learning_rate": 0.0008668407310704961,
      "loss": 0.23,
      "step": 1660
    },
    {
      "epoch": 4.360313315926893,
      "grad_norm": 1.3707677125930786,
      "learning_rate": 0.0008720626631853786,
      "loss": 0.2012,
      "step": 1670
    },
    {
      "epoch": 4.386422976501305,
      "grad_norm": 0.7340162396430969,
      "learning_rate": 0.0008772845953002612,
      "loss": 0.2694,
      "step": 1680
    },
    {
      "epoch": 4.412532637075718,
      "grad_norm": 2.337959051132202,
      "learning_rate": 0.0008825065274151436,
      "loss": 0.2314,
      "step": 1690
    },
    {
      "epoch": 4.438642297650131,
      "grad_norm": 0.6706256866455078,
      "learning_rate": 0.0008877284595300261,
      "loss": 0.2674,
      "step": 1700
    },
    {
      "epoch": 4.464751958224543,
      "grad_norm": 1.9217472076416016,
      "learning_rate": 0.0008929503916449087,
      "loss": 0.2127,
      "step": 1710
    },
    {
      "epoch": 4.490861618798956,
      "grad_norm": 1.648224115371704,
      "learning_rate": 0.0008981723237597911,
      "loss": 0.2154,
      "step": 1720
    },
    {
      "epoch": 4.516971279373368,
      "grad_norm": 1.209415078163147,
      "learning_rate": 0.0009033942558746736,
      "loss": 0.1984,
      "step": 1730
    },
    {
      "epoch": 4.543080939947781,
      "grad_norm": 1.1006059646606445,
      "learning_rate": 0.0009086161879895561,
      "loss": 0.207,
      "step": 1740
    },
    {
      "epoch": 4.569190600522193,
      "grad_norm": 2.7100143432617188,
      "learning_rate": 0.0009138381201044387,
      "loss": 0.2145,
      "step": 1750
    },
    {
      "epoch": 4.595300261096606,
      "grad_norm": 0.9885204434394836,
      "learning_rate": 0.0009190600522193212,
      "loss": 0.2396,
      "step": 1760
    },
    {
      "epoch": 4.6214099216710185,
      "grad_norm": 2.0751564502716064,
      "learning_rate": 0.0009242819843342037,
      "loss": 0.222,
      "step": 1770
    },
    {
      "epoch": 4.6475195822454305,
      "grad_norm": 0.6440920829772949,
      "learning_rate": 0.0009295039164490861,
      "loss": 0.2307,
      "step": 1780
    },
    {
      "epoch": 4.673629242819843,
      "grad_norm": 3.0797953605651855,
      "learning_rate": 0.0009347258485639687,
      "loss": 0.2256,
      "step": 1790
    },
    {
      "epoch": 4.699738903394256,
      "grad_norm": 0.7042582035064697,
      "learning_rate": 0.0009399477806788512,
      "loss": 0.2054,
      "step": 1800
    },
    {
      "epoch": 4.725848563968668,
      "grad_norm": 2.1657979488372803,
      "learning_rate": 0.0009451697127937337,
      "loss": 0.2753,
      "step": 1810
    },
    {
      "epoch": 4.751958224543081,
      "grad_norm": 0.7734511494636536,
      "learning_rate": 0.0009503916449086162,
      "loss": 0.2026,
      "step": 1820
    },
    {
      "epoch": 4.778067885117493,
      "grad_norm": 0.9476833939552307,
      "learning_rate": 0.0009556135770234988,
      "loss": 0.3022,
      "step": 1830
    },
    {
      "epoch": 4.804177545691906,
      "grad_norm": 2.030050039291382,
      "learning_rate": 0.0009608355091383812,
      "loss": 0.2294,
      "step": 1840
    },
    {
      "epoch": 4.830287206266319,
      "grad_norm": 1.6351065635681152,
      "learning_rate": 0.0009660574412532637,
      "loss": 0.1863,
      "step": 1850
    },
    {
      "epoch": 4.856396866840731,
      "grad_norm": 1.4777615070343018,
      "learning_rate": 0.0009712793733681462,
      "loss": 0.2401,
      "step": 1860
    },
    {
      "epoch": 4.882506527415144,
      "grad_norm": 1.3347386121749878,
      "learning_rate": 0.0009765013054830287,
      "loss": 0.2014,
      "step": 1870
    },
    {
      "epoch": 4.908616187989556,
      "grad_norm": 1.2528581619262695,
      "learning_rate": 0.0009817232375979113,
      "loss": 0.2358,
      "step": 1880
    },
    {
      "epoch": 4.934725848563969,
      "grad_norm": 1.9579567909240723,
      "learning_rate": 0.0009869451697127939,
      "loss": 0.2425,
      "step": 1890
    },
    {
      "epoch": 4.960835509138382,
      "grad_norm": 0.9871573448181152,
      "learning_rate": 0.0009921671018276762,
      "loss": 0.2827,
      "step": 1900
    },
    {
      "epoch": 4.986945169712794,
      "grad_norm": 1.0640450716018677,
      "learning_rate": 0.0009973890339425588,
      "loss": 0.2805,
      "step": 1910
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.6315542443341826,
      "eval_loss": 0.7781941890716553,
      "eval_runtime": 216.8618,
      "eval_samples_per_second": 68.772,
      "eval_steps_per_second": 4.302,
      "step": 1915
    }
  ],
  "logging_steps": 10,
  "max_steps": 19150,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.824960723291865e+19,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
