{
  "best_global_step": 1902,
  "best_metric": 0.8901510645890329,
  "best_model_checkpoint": "my_awesome_model/checkpoint-1902",
  "epoch": 22.0,
  "eval_steps": 500,
  "global_step": 13948,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.015779092702169626,
      "grad_norm": 1.7391250133514404,
      "learning_rate": 2.6329647182727754e-07,
      "loss": 0.6289,
      "step": 10
    },
    {
      "epoch": 0.03155818540433925,
      "grad_norm": 1.8507322072982788,
      "learning_rate": 5.265929436545551e-07,
      "loss": 0.6283,
      "step": 20
    },
    {
      "epoch": 0.047337278106508875,
      "grad_norm": 1.8064931631088257,
      "learning_rate": 7.898894154818326e-07,
      "loss": 0.6208,
      "step": 30
    },
    {
      "epoch": 0.0631163708086785,
      "grad_norm": 1.6448795795440674,
      "learning_rate": 1.0531858873091101e-06,
      "loss": 0.5993,
      "step": 40
    },
    {
      "epoch": 0.07889546351084813,
      "grad_norm": 1.6401801109313965,
      "learning_rate": 1.3164823591363876e-06,
      "loss": 0.5758,
      "step": 50
    },
    {
      "epoch": 0.09467455621301775,
      "grad_norm": 1.3196070194244385,
      "learning_rate": 1.5797788309636651e-06,
      "loss": 0.5559,
      "step": 60
    },
    {
      "epoch": 0.11045364891518737,
      "grad_norm": 1.4685463905334473,
      "learning_rate": 1.8430753027909426e-06,
      "loss": 0.507,
      "step": 70
    },
    {
      "epoch": 0.126232741617357,
      "grad_norm": 1.5748175382614136,
      "learning_rate": 2.1063717746182203e-06,
      "loss": 0.4742,
      "step": 80
    },
    {
      "epoch": 0.14201183431952663,
      "grad_norm": 1.3099663257598877,
      "learning_rate": 2.3696682464454976e-06,
      "loss": 0.4498,
      "step": 90
    },
    {
      "epoch": 0.15779092702169625,
      "grad_norm": 1.2303693294525146,
      "learning_rate": 2.6329647182727753e-06,
      "loss": 0.4032,
      "step": 100
    },
    {
      "epoch": 0.17357001972386588,
      "grad_norm": 0.9665882587432861,
      "learning_rate": 2.896261190100053e-06,
      "loss": 0.3823,
      "step": 110
    },
    {
      "epoch": 0.1893491124260355,
      "grad_norm": 0.8491628766059875,
      "learning_rate": 3.1595576619273302e-06,
      "loss": 0.3521,
      "step": 120
    },
    {
      "epoch": 0.20512820512820512,
      "grad_norm": 0.5423752665519714,
      "learning_rate": 3.422854133754608e-06,
      "loss": 0.3505,
      "step": 130
    },
    {
      "epoch": 0.22090729783037474,
      "grad_norm": 0.5336556434631348,
      "learning_rate": 3.686150605581885e-06,
      "loss": 0.2714,
      "step": 140
    },
    {
      "epoch": 0.23668639053254437,
      "grad_norm": 0.741020679473877,
      "learning_rate": 3.949447077409163e-06,
      "loss": 0.3372,
      "step": 150
    },
    {
      "epoch": 0.252465483234714,
      "grad_norm": 0.7609168887138367,
      "learning_rate": 4.212743549236441e-06,
      "loss": 0.3245,
      "step": 160
    },
    {
      "epoch": 0.2682445759368836,
      "grad_norm": 0.633055567741394,
      "learning_rate": 4.476040021063718e-06,
      "loss": 0.2695,
      "step": 170
    },
    {
      "epoch": 0.28402366863905326,
      "grad_norm": 0.7710171341896057,
      "learning_rate": 4.739336492890995e-06,
      "loss": 0.2981,
      "step": 180
    },
    {
      "epoch": 0.29980276134122286,
      "grad_norm": 0.5995982885360718,
      "learning_rate": 5.002632964718273e-06,
      "loss": 0.2621,
      "step": 190
    },
    {
      "epoch": 0.3155818540433925,
      "grad_norm": 0.4897489845752716,
      "learning_rate": 5.2659294365455505e-06,
      "loss": 0.2726,
      "step": 200
    },
    {
      "epoch": 0.33136094674556216,
      "grad_norm": 0.8908438682556152,
      "learning_rate": 5.529225908372828e-06,
      "loss": 0.2622,
      "step": 210
    },
    {
      "epoch": 0.34714003944773175,
      "grad_norm": 0.674349308013916,
      "learning_rate": 5.792522380200106e-06,
      "loss": 0.2662,
      "step": 220
    },
    {
      "epoch": 0.3629191321499014,
      "grad_norm": 0.8314926028251648,
      "learning_rate": 6.055818852027384e-06,
      "loss": 0.2649,
      "step": 230
    },
    {
      "epoch": 0.378698224852071,
      "grad_norm": 0.6224046349525452,
      "learning_rate": 6.3191153238546605e-06,
      "loss": 0.2765,
      "step": 240
    },
    {
      "epoch": 0.39447731755424065,
      "grad_norm": 0.6808822751045227,
      "learning_rate": 6.582411795681938e-06,
      "loss": 0.2406,
      "step": 250
    },
    {
      "epoch": 0.41025641025641024,
      "grad_norm": 0.7146959900856018,
      "learning_rate": 6.845708267509216e-06,
      "loss": 0.2455,
      "step": 260
    },
    {
      "epoch": 0.4260355029585799,
      "grad_norm": 0.5985401272773743,
      "learning_rate": 7.109004739336493e-06,
      "loss": 0.2489,
      "step": 270
    },
    {
      "epoch": 0.4418145956607495,
      "grad_norm": 0.4614385962486267,
      "learning_rate": 7.37230121116377e-06,
      "loss": 0.2596,
      "step": 280
    },
    {
      "epoch": 0.45759368836291914,
      "grad_norm": 0.8326202630996704,
      "learning_rate": 7.635597682991048e-06,
      "loss": 0.2714,
      "step": 290
    },
    {
      "epoch": 0.47337278106508873,
      "grad_norm": 0.6065999269485474,
      "learning_rate": 7.898894154818326e-06,
      "loss": 0.268,
      "step": 300
    },
    {
      "epoch": 0.4891518737672584,
      "grad_norm": 0.6498188376426697,
      "learning_rate": 8.162190626645603e-06,
      "loss": 0.23,
      "step": 310
    },
    {
      "epoch": 0.504930966469428,
      "grad_norm": 0.7084789872169495,
      "learning_rate": 8.425487098472881e-06,
      "loss": 0.2193,
      "step": 320
    },
    {
      "epoch": 0.5207100591715976,
      "grad_norm": 0.49012795090675354,
      "learning_rate": 8.688783570300159e-06,
      "loss": 0.2253,
      "step": 330
    },
    {
      "epoch": 0.5364891518737672,
      "grad_norm": 0.7386151552200317,
      "learning_rate": 8.952080042127437e-06,
      "loss": 0.236,
      "step": 340
    },
    {
      "epoch": 0.5522682445759369,
      "grad_norm": 0.813961923122406,
      "learning_rate": 9.215376513954714e-06,
      "loss": 0.2185,
      "step": 350
    },
    {
      "epoch": 0.5680473372781065,
      "grad_norm": 0.5447490215301514,
      "learning_rate": 9.47867298578199e-06,
      "loss": 0.2227,
      "step": 360
    },
    {
      "epoch": 0.5838264299802761,
      "grad_norm": 0.5070000886917114,
      "learning_rate": 9.741969457609268e-06,
      "loss": 0.2128,
      "step": 370
    },
    {
      "epoch": 0.5996055226824457,
      "grad_norm": 0.8080070614814758,
      "learning_rate": 1.0005265929436546e-05,
      "loss": 0.2379,
      "step": 380
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.5667093396186829,
      "learning_rate": 1.0268562401263823e-05,
      "loss": 0.2103,
      "step": 390
    },
    {
      "epoch": 0.631163708086785,
      "grad_norm": 0.8220949172973633,
      "learning_rate": 1.0531858873091101e-05,
      "loss": 0.1851,
      "step": 400
    },
    {
      "epoch": 0.6469428007889546,
      "grad_norm": 0.955345094203949,
      "learning_rate": 1.0795155344918379e-05,
      "loss": 0.2148,
      "step": 410
    },
    {
      "epoch": 0.6627218934911243,
      "grad_norm": 0.7455905079841614,
      "learning_rate": 1.1058451816745656e-05,
      "loss": 0.2158,
      "step": 420
    },
    {
      "epoch": 0.6785009861932939,
      "grad_norm": 0.9365333318710327,
      "learning_rate": 1.1321748288572934e-05,
      "loss": 0.2109,
      "step": 430
    },
    {
      "epoch": 0.6942800788954635,
      "grad_norm": 1.0606203079223633,
      "learning_rate": 1.1585044760400212e-05,
      "loss": 0.2179,
      "step": 440
    },
    {
      "epoch": 0.7100591715976331,
      "grad_norm": 0.6507370471954346,
      "learning_rate": 1.184834123222749e-05,
      "loss": 0.1849,
      "step": 450
    },
    {
      "epoch": 0.7258382642998028,
      "grad_norm": 0.4430759847164154,
      "learning_rate": 1.2111637704054767e-05,
      "loss": 0.204,
      "step": 460
    },
    {
      "epoch": 0.7416173570019724,
      "grad_norm": 1.0779248476028442,
      "learning_rate": 1.2374934175882045e-05,
      "loss": 0.1715,
      "step": 470
    },
    {
      "epoch": 0.757396449704142,
      "grad_norm": 0.4724803864955902,
      "learning_rate": 1.2638230647709321e-05,
      "loss": 0.1486,
      "step": 480
    },
    {
      "epoch": 0.7731755424063116,
      "grad_norm": 0.8040956258773804,
      "learning_rate": 1.2901527119536599e-05,
      "loss": 0.2253,
      "step": 490
    },
    {
      "epoch": 0.7889546351084813,
      "grad_norm": 0.9232651591300964,
      "learning_rate": 1.3164823591363876e-05,
      "loss": 0.1806,
      "step": 500
    },
    {
      "epoch": 0.8047337278106509,
      "grad_norm": 1.0219824314117432,
      "learning_rate": 1.3428120063191154e-05,
      "loss": 0.1899,
      "step": 510
    },
    {
      "epoch": 0.8205128205128205,
      "grad_norm": 0.7128586173057556,
      "learning_rate": 1.3691416535018432e-05,
      "loss": 0.1774,
      "step": 520
    },
    {
      "epoch": 0.8362919132149902,
      "grad_norm": 0.8872504830360413,
      "learning_rate": 1.395471300684571e-05,
      "loss": 0.2079,
      "step": 530
    },
    {
      "epoch": 0.8520710059171598,
      "grad_norm": 0.808085024356842,
      "learning_rate": 1.4218009478672985e-05,
      "loss": 0.1925,
      "step": 540
    },
    {
      "epoch": 0.8678500986193294,
      "grad_norm": 0.826967716217041,
      "learning_rate": 1.4481305950500265e-05,
      "loss": 0.1723,
      "step": 550
    },
    {
      "epoch": 0.883629191321499,
      "grad_norm": 0.7287331223487854,
      "learning_rate": 1.474460242232754e-05,
      "loss": 0.1978,
      "step": 560
    },
    {
      "epoch": 0.8994082840236687,
      "grad_norm": 1.2287406921386719,
      "learning_rate": 1.500789889415482e-05,
      "loss": 0.1977,
      "step": 570
    },
    {
      "epoch": 0.9151873767258383,
      "grad_norm": 2.382805585861206,
      "learning_rate": 1.5271195365982096e-05,
      "loss": 0.1537,
      "step": 580
    },
    {
      "epoch": 0.9309664694280079,
      "grad_norm": 0.7140786647796631,
      "learning_rate": 1.5534491837809372e-05,
      "loss": 0.151,
      "step": 590
    },
    {
      "epoch": 0.9467455621301775,
      "grad_norm": 0.8852582573890686,
      "learning_rate": 1.579778830963665e-05,
      "loss": 0.1779,
      "step": 600
    },
    {
      "epoch": 0.9625246548323472,
      "grad_norm": 1.1475155353546143,
      "learning_rate": 1.6061084781463928e-05,
      "loss": 0.1615,
      "step": 610
    },
    {
      "epoch": 0.9783037475345168,
      "grad_norm": 5.256382465362549,
      "learning_rate": 1.6324381253291207e-05,
      "loss": 0.1875,
      "step": 620
    },
    {
      "epoch": 0.9940828402366864,
      "grad_norm": 0.44454824924468994,
      "learning_rate": 1.6587677725118483e-05,
      "loss": 0.136,
      "step": 630
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8897942191031284,
      "eval_loss": 0.3641950190067291,
      "eval_runtime": 269.9269,
      "eval_samples_per_second": 62.291,
      "eval_steps_per_second": 3.894,
      "step": 634
    },
    {
      "epoch": 1.0094674556213017,
      "grad_norm": 0.6947834491729736,
      "learning_rate": 1.6850974196945762e-05,
      "loss": 0.1494,
      "step": 640
    },
    {
      "epoch": 1.0252465483234714,
      "grad_norm": 0.8623563051223755,
      "learning_rate": 1.711427066877304e-05,
      "loss": 0.1167,
      "step": 650
    },
    {
      "epoch": 1.041025641025641,
      "grad_norm": 0.6643915772438049,
      "learning_rate": 1.7377567140600318e-05,
      "loss": 0.1625,
      "step": 660
    },
    {
      "epoch": 1.0568047337278106,
      "grad_norm": 0.6381509304046631,
      "learning_rate": 1.7640863612427594e-05,
      "loss": 0.1391,
      "step": 670
    },
    {
      "epoch": 1.0725838264299803,
      "grad_norm": 1.6635559797286987,
      "learning_rate": 1.7904160084254873e-05,
      "loss": 0.1383,
      "step": 680
    },
    {
      "epoch": 1.08836291913215,
      "grad_norm": 0.45624077320098877,
      "learning_rate": 1.816745655608215e-05,
      "loss": 0.1425,
      "step": 690
    },
    {
      "epoch": 1.1041420118343195,
      "grad_norm": 2.9841716289520264,
      "learning_rate": 1.843075302790943e-05,
      "loss": 0.1425,
      "step": 700
    },
    {
      "epoch": 1.1199211045364892,
      "grad_norm": 3.200032949447632,
      "learning_rate": 1.8694049499736705e-05,
      "loss": 0.1379,
      "step": 710
    },
    {
      "epoch": 1.1357001972386587,
      "grad_norm": 1.1468003988265991,
      "learning_rate": 1.895734597156398e-05,
      "loss": 0.1371,
      "step": 720
    },
    {
      "epoch": 1.1514792899408284,
      "grad_norm": 0.6516549587249756,
      "learning_rate": 1.922064244339126e-05,
      "loss": 0.1217,
      "step": 730
    },
    {
      "epoch": 1.167258382642998,
      "grad_norm": 0.5347599387168884,
      "learning_rate": 1.9483938915218536e-05,
      "loss": 0.1131,
      "step": 740
    },
    {
      "epoch": 1.1830374753451676,
      "grad_norm": 1.7380644083023071,
      "learning_rate": 1.9747235387045815e-05,
      "loss": 0.1318,
      "step": 750
    },
    {
      "epoch": 1.1988165680473373,
      "grad_norm": 0.7730966806411743,
      "learning_rate": 2.001053185887309e-05,
      "loss": 0.1458,
      "step": 760
    },
    {
      "epoch": 1.214595660749507,
      "grad_norm": 0.5439343452453613,
      "learning_rate": 2.027382833070037e-05,
      "loss": 0.1329,
      "step": 770
    },
    {
      "epoch": 1.2303747534516765,
      "grad_norm": 0.7116678953170776,
      "learning_rate": 2.0537124802527647e-05,
      "loss": 0.1262,
      "step": 780
    },
    {
      "epoch": 1.2461538461538462,
      "grad_norm": 1.2619482278823853,
      "learning_rate": 2.0800421274354926e-05,
      "loss": 0.1203,
      "step": 790
    },
    {
      "epoch": 1.2619329388560159,
      "grad_norm": 1.8035706281661987,
      "learning_rate": 2.1063717746182202e-05,
      "loss": 0.1195,
      "step": 800
    },
    {
      "epoch": 1.2777120315581854,
      "grad_norm": 1.564778208732605,
      "learning_rate": 2.132701421800948e-05,
      "loss": 0.1152,
      "step": 810
    },
    {
      "epoch": 1.293491124260355,
      "grad_norm": 1.154530644416809,
      "learning_rate": 2.1590310689836757e-05,
      "loss": 0.1333,
      "step": 820
    },
    {
      "epoch": 1.3092702169625245,
      "grad_norm": 2.9446043968200684,
      "learning_rate": 2.1853607161664037e-05,
      "loss": 0.103,
      "step": 830
    },
    {
      "epoch": 1.3250493096646943,
      "grad_norm": 1.2045243978500366,
      "learning_rate": 2.2116903633491313e-05,
      "loss": 0.1238,
      "step": 840
    },
    {
      "epoch": 1.340828402366864,
      "grad_norm": 0.38108760118484497,
      "learning_rate": 2.2380200105318592e-05,
      "loss": 0.1016,
      "step": 850
    },
    {
      "epoch": 1.3566074950690337,
      "grad_norm": 4.057867050170898,
      "learning_rate": 2.2643496577145868e-05,
      "loss": 0.129,
      "step": 860
    },
    {
      "epoch": 1.3723865877712031,
      "grad_norm": 0.5902647972106934,
      "learning_rate": 2.2906793048973144e-05,
      "loss": 0.1043,
      "step": 870
    },
    {
      "epoch": 1.3881656804733729,
      "grad_norm": 1.890192985534668,
      "learning_rate": 2.3170089520800424e-05,
      "loss": 0.1237,
      "step": 880
    },
    {
      "epoch": 1.4039447731755423,
      "grad_norm": 1.1564645767211914,
      "learning_rate": 2.34333859926277e-05,
      "loss": 0.1226,
      "step": 890
    },
    {
      "epoch": 1.419723865877712,
      "grad_norm": 2.446141242980957,
      "learning_rate": 2.369668246445498e-05,
      "loss": 0.1471,
      "step": 900
    },
    {
      "epoch": 1.4355029585798817,
      "grad_norm": 1.6706349849700928,
      "learning_rate": 2.3959978936282255e-05,
      "loss": 0.1344,
      "step": 910
    },
    {
      "epoch": 1.4512820512820512,
      "grad_norm": 0.7372813820838928,
      "learning_rate": 2.4223275408109534e-05,
      "loss": 0.1236,
      "step": 920
    },
    {
      "epoch": 1.467061143984221,
      "grad_norm": 1.2974215745925903,
      "learning_rate": 2.448657187993681e-05,
      "loss": 0.1046,
      "step": 930
    },
    {
      "epoch": 1.4828402366863904,
      "grad_norm": 1.0312824249267578,
      "learning_rate": 2.474986835176409e-05,
      "loss": 0.1259,
      "step": 940
    },
    {
      "epoch": 1.4986193293885601,
      "grad_norm": 0.7681568264961243,
      "learning_rate": 2.5013164823591366e-05,
      "loss": 0.1143,
      "step": 950
    },
    {
      "epoch": 1.5143984220907298,
      "grad_norm": 3.032527446746826,
      "learning_rate": 2.5276461295418642e-05,
      "loss": 0.1047,
      "step": 960
    },
    {
      "epoch": 1.5301775147928995,
      "grad_norm": 1.6791753768920898,
      "learning_rate": 2.553975776724592e-05,
      "loss": 0.0948,
      "step": 970
    },
    {
      "epoch": 1.545956607495069,
      "grad_norm": 0.4655206501483917,
      "learning_rate": 2.5803054239073197e-05,
      "loss": 0.1225,
      "step": 980
    },
    {
      "epoch": 1.5617357001972385,
      "grad_norm": 2.452855110168457,
      "learning_rate": 2.6066350710900477e-05,
      "loss": 0.0972,
      "step": 990
    },
    {
      "epoch": 1.5775147928994082,
      "grad_norm": 1.435630440711975,
      "learning_rate": 2.6329647182727753e-05,
      "loss": 0.1279,
      "step": 1000
    },
    {
      "epoch": 1.593293885601578,
      "grad_norm": 1.4220770597457886,
      "learning_rate": 2.6592943654555032e-05,
      "loss": 0.1211,
      "step": 1010
    },
    {
      "epoch": 1.6090729783037476,
      "grad_norm": 1.690445065498352,
      "learning_rate": 2.6856240126382308e-05,
      "loss": 0.1382,
      "step": 1020
    },
    {
      "epoch": 1.624852071005917,
      "grad_norm": 1.3054571151733398,
      "learning_rate": 2.7119536598209584e-05,
      "loss": 0.122,
      "step": 1030
    },
    {
      "epoch": 1.6406311637080868,
      "grad_norm": 2.9175922870635986,
      "learning_rate": 2.7382833070036863e-05,
      "loss": 0.0924,
      "step": 1040
    },
    {
      "epoch": 1.6564102564102563,
      "grad_norm": 0.4507225453853607,
      "learning_rate": 2.764612954186414e-05,
      "loss": 0.0859,
      "step": 1050
    },
    {
      "epoch": 1.672189349112426,
      "grad_norm": 3.0334174633026123,
      "learning_rate": 2.790942601369142e-05,
      "loss": 0.1147,
      "step": 1060
    },
    {
      "epoch": 1.6879684418145957,
      "grad_norm": 1.483511209487915,
      "learning_rate": 2.8172722485518695e-05,
      "loss": 0.1021,
      "step": 1070
    },
    {
      "epoch": 1.7037475345167654,
      "grad_norm": 0.806665301322937,
      "learning_rate": 2.843601895734597e-05,
      "loss": 0.0922,
      "step": 1080
    },
    {
      "epoch": 1.719526627218935,
      "grad_norm": 3.105099678039551,
      "learning_rate": 2.869931542917325e-05,
      "loss": 0.0873,
      "step": 1090
    },
    {
      "epoch": 1.7353057199211044,
      "grad_norm": 0.5711432695388794,
      "learning_rate": 2.896261190100053e-05,
      "loss": 0.1198,
      "step": 1100
    },
    {
      "epoch": 1.751084812623274,
      "grad_norm": 3.1220011711120605,
      "learning_rate": 2.9225908372827802e-05,
      "loss": 0.1226,
      "step": 1110
    },
    {
      "epoch": 1.7668639053254438,
      "grad_norm": 1.083001971244812,
      "learning_rate": 2.948920484465508e-05,
      "loss": 0.1259,
      "step": 1120
    },
    {
      "epoch": 1.7826429980276135,
      "grad_norm": 1.0483015775680542,
      "learning_rate": 2.975250131648236e-05,
      "loss": 0.1222,
      "step": 1130
    },
    {
      "epoch": 1.798422090729783,
      "grad_norm": 1.8187532424926758,
      "learning_rate": 3.001579778830964e-05,
      "loss": 0.1517,
      "step": 1140
    },
    {
      "epoch": 1.8142011834319527,
      "grad_norm": 2.2487173080444336,
      "learning_rate": 3.0279094260136913e-05,
      "loss": 0.1213,
      "step": 1150
    },
    {
      "epoch": 1.8299802761341222,
      "grad_norm": 1.3941487073898315,
      "learning_rate": 3.054239073196419e-05,
      "loss": 0.0954,
      "step": 1160
    },
    {
      "epoch": 1.8457593688362919,
      "grad_norm": 1.2994581460952759,
      "learning_rate": 3.080568720379147e-05,
      "loss": 0.1498,
      "step": 1170
    },
    {
      "epoch": 1.8615384615384616,
      "grad_norm": 1.2504298686981201,
      "learning_rate": 3.1068983675618744e-05,
      "loss": 0.1048,
      "step": 1180
    },
    {
      "epoch": 1.8773175542406313,
      "grad_norm": 1.0519400835037231,
      "learning_rate": 3.1332280147446024e-05,
      "loss": 0.151,
      "step": 1190
    },
    {
      "epoch": 1.8930966469428008,
      "grad_norm": 1.3878679275512695,
      "learning_rate": 3.15955766192733e-05,
      "loss": 0.1456,
      "step": 1200
    },
    {
      "epoch": 1.9088757396449703,
      "grad_norm": 2.6124420166015625,
      "learning_rate": 3.185887309110058e-05,
      "loss": 0.113,
      "step": 1210
    },
    {
      "epoch": 1.92465483234714,
      "grad_norm": 2.908538818359375,
      "learning_rate": 3.2122169562927855e-05,
      "loss": 0.1077,
      "step": 1220
    },
    {
      "epoch": 1.9404339250493097,
      "grad_norm": 0.7329539060592651,
      "learning_rate": 3.2385466034755135e-05,
      "loss": 0.0814,
      "step": 1230
    },
    {
      "epoch": 1.9562130177514794,
      "grad_norm": 1.2726796865463257,
      "learning_rate": 3.2648762506582414e-05,
      "loss": 0.0973,
      "step": 1240
    },
    {
      "epoch": 1.9719921104536489,
      "grad_norm": 1.2714768648147583,
      "learning_rate": 3.291205897840969e-05,
      "loss": 0.0763,
      "step": 1250
    },
    {
      "epoch": 1.9877712031558186,
      "grad_norm": 2.0324535369873047,
      "learning_rate": 3.3175355450236966e-05,
      "loss": 0.099,
      "step": 1260
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8761151421434519,
      "eval_loss": 0.40126556158065796,
      "eval_runtime": 203.9262,
      "eval_samples_per_second": 82.451,
      "eval_steps_per_second": 5.154,
      "step": 1268
    },
    {
      "epoch": 2.003155818540434,
      "grad_norm": 2.5127882957458496,
      "learning_rate": 3.3438651922064245e-05,
      "loss": 0.1062,
      "step": 1270
    },
    {
      "epoch": 2.0189349112426034,
      "grad_norm": 2.427389144897461,
      "learning_rate": 3.3701948393891525e-05,
      "loss": 0.0681,
      "step": 1280
    },
    {
      "epoch": 2.034714003944773,
      "grad_norm": 2.179764747619629,
      "learning_rate": 3.39652448657188e-05,
      "loss": 0.0875,
      "step": 1290
    },
    {
      "epoch": 2.050493096646943,
      "grad_norm": 1.4586856365203857,
      "learning_rate": 3.422854133754608e-05,
      "loss": 0.0834,
      "step": 1300
    },
    {
      "epoch": 2.0662721893491125,
      "grad_norm": 0.8376423716545105,
      "learning_rate": 3.4491837809373356e-05,
      "loss": 0.0741,
      "step": 1310
    },
    {
      "epoch": 2.082051282051282,
      "grad_norm": 2.375126600265503,
      "learning_rate": 3.4755134281200636e-05,
      "loss": 0.0925,
      "step": 1320
    },
    {
      "epoch": 2.0978303747534515,
      "grad_norm": 1.416471004486084,
      "learning_rate": 3.501843075302791e-05,
      "loss": 0.0759,
      "step": 1330
    },
    {
      "epoch": 2.113609467455621,
      "grad_norm": 1.9211573600769043,
      "learning_rate": 3.528172722485519e-05,
      "loss": 0.0641,
      "step": 1340
    },
    {
      "epoch": 2.129388560157791,
      "grad_norm": 2.491119384765625,
      "learning_rate": 3.554502369668247e-05,
      "loss": 0.1149,
      "step": 1350
    },
    {
      "epoch": 2.1451676528599606,
      "grad_norm": 1.7812334299087524,
      "learning_rate": 3.5808320168509746e-05,
      "loss": 0.1002,
      "step": 1360
    },
    {
      "epoch": 2.1609467455621303,
      "grad_norm": 0.2420184165239334,
      "learning_rate": 3.607161664033702e-05,
      "loss": 0.0714,
      "step": 1370
    },
    {
      "epoch": 2.1767258382643,
      "grad_norm": 1.0691113471984863,
      "learning_rate": 3.63349131121643e-05,
      "loss": 0.0828,
      "step": 1380
    },
    {
      "epoch": 2.1925049309664693,
      "grad_norm": 3.540065050125122,
      "learning_rate": 3.659820958399158e-05,
      "loss": 0.0923,
      "step": 1390
    },
    {
      "epoch": 2.208284023668639,
      "grad_norm": 0.6286438703536987,
      "learning_rate": 3.686150605581886e-05,
      "loss": 0.0894,
      "step": 1400
    },
    {
      "epoch": 2.2240631163708087,
      "grad_norm": 3.3376286029815674,
      "learning_rate": 3.712480252764613e-05,
      "loss": 0.0911,
      "step": 1410
    },
    {
      "epoch": 2.2398422090729784,
      "grad_norm": 4.499612808227539,
      "learning_rate": 3.738809899947341e-05,
      "loss": 0.0747,
      "step": 1420
    },
    {
      "epoch": 2.255621301775148,
      "grad_norm": 0.6825276613235474,
      "learning_rate": 3.765139547130069e-05,
      "loss": 0.1133,
      "step": 1430
    },
    {
      "epoch": 2.2714003944773173,
      "grad_norm": 0.8437731266021729,
      "learning_rate": 3.791469194312796e-05,
      "loss": 0.086,
      "step": 1440
    },
    {
      "epoch": 2.287179487179487,
      "grad_norm": 0.6317580938339233,
      "learning_rate": 3.817798841495524e-05,
      "loss": 0.0797,
      "step": 1450
    },
    {
      "epoch": 2.3029585798816568,
      "grad_norm": 1.368124008178711,
      "learning_rate": 3.844128488678252e-05,
      "loss": 0.0881,
      "step": 1460
    },
    {
      "epoch": 2.3187376725838265,
      "grad_norm": 2.2712879180908203,
      "learning_rate": 3.87045813586098e-05,
      "loss": 0.0826,
      "step": 1470
    },
    {
      "epoch": 2.334516765285996,
      "grad_norm": 0.8186475038528442,
      "learning_rate": 3.896787783043707e-05,
      "loss": 0.0778,
      "step": 1480
    },
    {
      "epoch": 2.350295857988166,
      "grad_norm": 2.085022211074829,
      "learning_rate": 3.923117430226435e-05,
      "loss": 0.0801,
      "step": 1490
    },
    {
      "epoch": 2.366074950690335,
      "grad_norm": 2.338177442550659,
      "learning_rate": 3.949447077409163e-05,
      "loss": 0.0574,
      "step": 1500
    },
    {
      "epoch": 2.381854043392505,
      "grad_norm": 0.9747551083564758,
      "learning_rate": 3.975776724591891e-05,
      "loss": 0.07,
      "step": 1510
    },
    {
      "epoch": 2.3976331360946745,
      "grad_norm": 1.2857344150543213,
      "learning_rate": 4.002106371774618e-05,
      "loss": 0.0918,
      "step": 1520
    },
    {
      "epoch": 2.4134122287968442,
      "grad_norm": 1.1981943845748901,
      "learning_rate": 4.028436018957346e-05,
      "loss": 0.0695,
      "step": 1530
    },
    {
      "epoch": 2.429191321499014,
      "grad_norm": 1.3051873445510864,
      "learning_rate": 4.054765666140074e-05,
      "loss": 0.0669,
      "step": 1540
    },
    {
      "epoch": 2.444970414201183,
      "grad_norm": 0.7516889572143555,
      "learning_rate": 4.081095313322802e-05,
      "loss": 0.0896,
      "step": 1550
    },
    {
      "epoch": 2.460749506903353,
      "grad_norm": 0.9892362952232361,
      "learning_rate": 4.1074249605055293e-05,
      "loss": 0.1002,
      "step": 1560
    },
    {
      "epoch": 2.4765285996055226,
      "grad_norm": 0.5881178975105286,
      "learning_rate": 4.133754607688257e-05,
      "loss": 0.0768,
      "step": 1570
    },
    {
      "epoch": 2.4923076923076923,
      "grad_norm": 0.4370865225791931,
      "learning_rate": 4.160084254870985e-05,
      "loss": 0.0915,
      "step": 1580
    },
    {
      "epoch": 2.508086785009862,
      "grad_norm": 2.272282838821411,
      "learning_rate": 4.1864139020537125e-05,
      "loss": 0.051,
      "step": 1590
    },
    {
      "epoch": 2.5238658777120317,
      "grad_norm": 0.33013656735420227,
      "learning_rate": 4.2127435492364404e-05,
      "loss": 0.0814,
      "step": 1600
    },
    {
      "epoch": 2.5396449704142015,
      "grad_norm": 0.7874273657798767,
      "learning_rate": 4.2390731964191684e-05,
      "loss": 0.0926,
      "step": 1610
    },
    {
      "epoch": 2.5554240631163707,
      "grad_norm": 1.0173892974853516,
      "learning_rate": 4.265402843601896e-05,
      "loss": 0.0992,
      "step": 1620
    },
    {
      "epoch": 2.5712031558185404,
      "grad_norm": 0.5973772406578064,
      "learning_rate": 4.2917324907846236e-05,
      "loss": 0.0675,
      "step": 1630
    },
    {
      "epoch": 2.58698224852071,
      "grad_norm": 1.9326552152633667,
      "learning_rate": 4.3180621379673515e-05,
      "loss": 0.0711,
      "step": 1640
    },
    {
      "epoch": 2.60276134122288,
      "grad_norm": 1.983398675918579,
      "learning_rate": 4.3443917851500794e-05,
      "loss": 0.0757,
      "step": 1650
    },
    {
      "epoch": 2.618540433925049,
      "grad_norm": 2.2425997257232666,
      "learning_rate": 4.3707214323328074e-05,
      "loss": 0.0857,
      "step": 1660
    },
    {
      "epoch": 2.634319526627219,
      "grad_norm": 2.0935025215148926,
      "learning_rate": 4.3970510795155346e-05,
      "loss": 0.0999,
      "step": 1670
    },
    {
      "epoch": 2.6500986193293885,
      "grad_norm": 0.4606736898422241,
      "learning_rate": 4.4233807266982626e-05,
      "loss": 0.0927,
      "step": 1680
    },
    {
      "epoch": 2.665877712031558,
      "grad_norm": 0.9829091429710388,
      "learning_rate": 4.4497103738809905e-05,
      "loss": 0.1143,
      "step": 1690
    },
    {
      "epoch": 2.681656804733728,
      "grad_norm": 2.748898983001709,
      "learning_rate": 4.4760400210637185e-05,
      "loss": 0.0784,
      "step": 1700
    },
    {
      "epoch": 2.6974358974358976,
      "grad_norm": 0.594853401184082,
      "learning_rate": 4.502369668246446e-05,
      "loss": 0.1056,
      "step": 1710
    },
    {
      "epoch": 2.7132149901380673,
      "grad_norm": 1.4379408359527588,
      "learning_rate": 4.5286993154291737e-05,
      "loss": 0.0924,
      "step": 1720
    },
    {
      "epoch": 2.7289940828402366,
      "grad_norm": 0.8313022255897522,
      "learning_rate": 4.5550289626119016e-05,
      "loss": 0.0868,
      "step": 1730
    },
    {
      "epoch": 2.7447731755424063,
      "grad_norm": 1.1911401748657227,
      "learning_rate": 4.581358609794629e-05,
      "loss": 0.07,
      "step": 1740
    },
    {
      "epoch": 2.760552268244576,
      "grad_norm": 1.2129124402999878,
      "learning_rate": 4.607688256977357e-05,
      "loss": 0.0674,
      "step": 1750
    },
    {
      "epoch": 2.7763313609467457,
      "grad_norm": 2.2599964141845703,
      "learning_rate": 4.634017904160085e-05,
      "loss": 0.077,
      "step": 1760
    },
    {
      "epoch": 2.792110453648915,
      "grad_norm": 0.720647394657135,
      "learning_rate": 4.660347551342813e-05,
      "loss": 0.0875,
      "step": 1770
    },
    {
      "epoch": 2.8078895463510847,
      "grad_norm": 2.561479091644287,
      "learning_rate": 4.68667719852554e-05,
      "loss": 0.0936,
      "step": 1780
    },
    {
      "epoch": 2.8236686390532544,
      "grad_norm": 1.023428201675415,
      "learning_rate": 4.713006845708268e-05,
      "loss": 0.078,
      "step": 1790
    },
    {
      "epoch": 2.839447731755424,
      "grad_norm": 2.6803343296051025,
      "learning_rate": 4.739336492890996e-05,
      "loss": 0.103,
      "step": 1800
    },
    {
      "epoch": 2.855226824457594,
      "grad_norm": 1.7757574319839478,
      "learning_rate": 4.765666140073724e-05,
      "loss": 0.0926,
      "step": 1810
    },
    {
      "epoch": 2.8710059171597635,
      "grad_norm": 1.0570307970046997,
      "learning_rate": 4.791995787256451e-05,
      "loss": 0.0442,
      "step": 1820
    },
    {
      "epoch": 2.886785009861933,
      "grad_norm": 0.9910600781440735,
      "learning_rate": 4.818325434439179e-05,
      "loss": 0.0796,
      "step": 1830
    },
    {
      "epoch": 2.9025641025641025,
      "grad_norm": 1.5243223905563354,
      "learning_rate": 4.844655081621907e-05,
      "loss": 0.084,
      "step": 1840
    },
    {
      "epoch": 2.918343195266272,
      "grad_norm": 0.9263142943382263,
      "learning_rate": 4.870984728804635e-05,
      "loss": 0.0958,
      "step": 1850
    },
    {
      "epoch": 2.934122287968442,
      "grad_norm": 1.7401869297027588,
      "learning_rate": 4.897314375987362e-05,
      "loss": 0.0754,
      "step": 1860
    },
    {
      "epoch": 2.9499013806706116,
      "grad_norm": 0.6635515689849854,
      "learning_rate": 4.92364402317009e-05,
      "loss": 0.0674,
      "step": 1870
    },
    {
      "epoch": 2.965680473372781,
      "grad_norm": 1.3961642980575562,
      "learning_rate": 4.949973670352818e-05,
      "loss": 0.1194,
      "step": 1880
    },
    {
      "epoch": 2.9814595660749506,
      "grad_norm": 0.9337673187255859,
      "learning_rate": 4.976303317535545e-05,
      "loss": 0.0627,
      "step": 1890
    },
    {
      "epoch": 2.9972386587771203,
      "grad_norm": 0.7731611132621765,
      "learning_rate": 4.9997074483646365e-05,
      "loss": 0.105,
      "step": 1900
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8901510645890329,
      "eval_loss": 0.4137847125530243,
      "eval_runtime": 199.8118,
      "eval_samples_per_second": 84.149,
      "eval_steps_per_second": 5.26,
      "step": 1902
    },
    {
      "epoch": 3.0126232741617356,
      "grad_norm": 0.7122796773910522,
      "learning_rate": 4.9967819320110005e-05,
      "loss": 0.0352,
      "step": 1910
    },
    {
      "epoch": 3.0284023668639053,
      "grad_norm": 0.31983962655067444,
      "learning_rate": 4.993856415657364e-05,
      "loss": 0.0364,
      "step": 1920
    },
    {
      "epoch": 3.044181459566075,
      "grad_norm": 1.6196759939193726,
      "learning_rate": 4.990930899303727e-05,
      "loss": 0.0391,
      "step": 1930
    },
    {
      "epoch": 3.0599605522682447,
      "grad_norm": 1.2095513343811035,
      "learning_rate": 4.988005382950091e-05,
      "loss": 0.0633,
      "step": 1940
    },
    {
      "epoch": 3.0757396449704144,
      "grad_norm": 2.346975088119507,
      "learning_rate": 4.9850798665964545e-05,
      "loss": 0.0392,
      "step": 1950
    },
    {
      "epoch": 3.0915187376725837,
      "grad_norm": 1.7032681703567505,
      "learning_rate": 4.982154350242818e-05,
      "loss": 0.0462,
      "step": 1960
    },
    {
      "epoch": 3.1072978303747534,
      "grad_norm": 1.0148990154266357,
      "learning_rate": 4.979228833889182e-05,
      "loss": 0.0916,
      "step": 1970
    },
    {
      "epoch": 3.123076923076923,
      "grad_norm": 1.329097867012024,
      "learning_rate": 4.976303317535545e-05,
      "loss": 0.0576,
      "step": 1980
    },
    {
      "epoch": 3.138856015779093,
      "grad_norm": 0.49566882848739624,
      "learning_rate": 4.9733778011819086e-05,
      "loss": 0.0469,
      "step": 1990
    },
    {
      "epoch": 3.1546351084812625,
      "grad_norm": 2.375258445739746,
      "learning_rate": 4.9704522848282726e-05,
      "loss": 0.0688,
      "step": 2000
    },
    {
      "epoch": 3.1704142011834318,
      "grad_norm": 1.0392298698425293,
      "learning_rate": 4.9675267684746366e-05,
      "loss": 0.0455,
      "step": 2010
    },
    {
      "epoch": 3.1861932938856015,
      "grad_norm": 0.3837747871875763,
      "learning_rate": 4.964601252120999e-05,
      "loss": 0.0383,
      "step": 2020
    },
    {
      "epoch": 3.201972386587771,
      "grad_norm": 1.5877552032470703,
      "learning_rate": 4.961675735767363e-05,
      "loss": 0.047,
      "step": 2030
    },
    {
      "epoch": 3.217751479289941,
      "grad_norm": 3.8974123001098633,
      "learning_rate": 4.958750219413727e-05,
      "loss": 0.0531,
      "step": 2040
    },
    {
      "epoch": 3.2335305719921106,
      "grad_norm": 2.5829520225524902,
      "learning_rate": 4.95582470306009e-05,
      "loss": 0.0626,
      "step": 2050
    },
    {
      "epoch": 3.2493096646942803,
      "grad_norm": 0.6952030658721924,
      "learning_rate": 4.952899186706454e-05,
      "loss": 0.0706,
      "step": 2060
    },
    {
      "epoch": 3.2650887573964495,
      "grad_norm": 0.22169740498065948,
      "learning_rate": 4.949973670352818e-05,
      "loss": 0.0557,
      "step": 2070
    },
    {
      "epoch": 3.2808678500986193,
      "grad_norm": 0.7201980352401733,
      "learning_rate": 4.9470481539991806e-05,
      "loss": 0.0675,
      "step": 2080
    },
    {
      "epoch": 3.296646942800789,
      "grad_norm": 1.6931768655776978,
      "learning_rate": 4.9441226376455446e-05,
      "loss": 0.0429,
      "step": 2090
    },
    {
      "epoch": 3.3124260355029587,
      "grad_norm": 0.881061851978302,
      "learning_rate": 4.9411971212919087e-05,
      "loss": 0.0383,
      "step": 2100
    },
    {
      "epoch": 3.3282051282051284,
      "grad_norm": 0.27279436588287354,
      "learning_rate": 4.938271604938271e-05,
      "loss": 0.0666,
      "step": 2110
    },
    {
      "epoch": 3.3439842209072976,
      "grad_norm": 1.0529465675354004,
      "learning_rate": 4.935346088584635e-05,
      "loss": 0.0534,
      "step": 2120
    },
    {
      "epoch": 3.3597633136094673,
      "grad_norm": 1.7890745401382446,
      "learning_rate": 4.9324205722309993e-05,
      "loss": 0.0859,
      "step": 2130
    },
    {
      "epoch": 3.375542406311637,
      "grad_norm": 1.5256483554840088,
      "learning_rate": 4.929495055877363e-05,
      "loss": 0.0779,
      "step": 2140
    },
    {
      "epoch": 3.3913214990138068,
      "grad_norm": 1.1349526643753052,
      "learning_rate": 4.926569539523726e-05,
      "loss": 0.0501,
      "step": 2150
    },
    {
      "epoch": 3.4071005917159765,
      "grad_norm": 0.29662948846817017,
      "learning_rate": 4.92364402317009e-05,
      "loss": 0.0685,
      "step": 2160
    },
    {
      "epoch": 3.422879684418146,
      "grad_norm": 0.33672529458999634,
      "learning_rate": 4.9207185068164534e-05,
      "loss": 0.0752,
      "step": 2170
    },
    {
      "epoch": 3.4386587771203154,
      "grad_norm": 0.22993086278438568,
      "learning_rate": 4.917792990462817e-05,
      "loss": 0.0276,
      "step": 2180
    },
    {
      "epoch": 3.454437869822485,
      "grad_norm": 0.971343457698822,
      "learning_rate": 4.914867474109181e-05,
      "loss": 0.0529,
      "step": 2190
    },
    {
      "epoch": 3.470216962524655,
      "grad_norm": 1.7328697443008423,
      "learning_rate": 4.911941957755544e-05,
      "loss": 0.0711,
      "step": 2200
    },
    {
      "epoch": 3.4859960552268245,
      "grad_norm": 1.3712157011032104,
      "learning_rate": 4.9090164414019074e-05,
      "loss": 0.0537,
      "step": 2210
    },
    {
      "epoch": 3.5017751479289942,
      "grad_norm": 0.11204992979764938,
      "learning_rate": 4.9060909250482714e-05,
      "loss": 0.0373,
      "step": 2220
    },
    {
      "epoch": 3.5175542406311635,
      "grad_norm": 0.9778099060058594,
      "learning_rate": 4.903165408694635e-05,
      "loss": 0.0457,
      "step": 2230
    },
    {
      "epoch": 3.533333333333333,
      "grad_norm": 2.2745981216430664,
      "learning_rate": 4.900239892340999e-05,
      "loss": 0.0604,
      "step": 2240
    },
    {
      "epoch": 3.549112426035503,
      "grad_norm": 3.673447608947754,
      "learning_rate": 4.897314375987362e-05,
      "loss": 0.0544,
      "step": 2250
    },
    {
      "epoch": 3.5648915187376726,
      "grad_norm": 1.9695992469787598,
      "learning_rate": 4.8943888596337254e-05,
      "loss": 0.0487,
      "step": 2260
    },
    {
      "epoch": 3.5806706114398423,
      "grad_norm": 1.033577561378479,
      "learning_rate": 4.8914633432800894e-05,
      "loss": 0.0818,
      "step": 2270
    },
    {
      "epoch": 3.596449704142012,
      "grad_norm": 0.2817200720310211,
      "learning_rate": 4.888537826926453e-05,
      "loss": 0.0632,
      "step": 2280
    },
    {
      "epoch": 3.6122287968441813,
      "grad_norm": 3.3951170444488525,
      "learning_rate": 4.885612310572816e-05,
      "loss": 0.046,
      "step": 2290
    },
    {
      "epoch": 3.628007889546351,
      "grad_norm": 1.4967576265335083,
      "learning_rate": 4.88268679421918e-05,
      "loss": 0.0662,
      "step": 2300
    },
    {
      "epoch": 3.6437869822485207,
      "grad_norm": 2.1610357761383057,
      "learning_rate": 4.8797612778655435e-05,
      "loss": 0.039,
      "step": 2310
    },
    {
      "epoch": 3.6595660749506904,
      "grad_norm": 3.9086122512817383,
      "learning_rate": 4.876835761511907e-05,
      "loss": 0.0758,
      "step": 2320
    },
    {
      "epoch": 3.67534516765286,
      "grad_norm": 1.4941045045852661,
      "learning_rate": 4.873910245158271e-05,
      "loss": 0.049,
      "step": 2330
    },
    {
      "epoch": 3.6911242603550294,
      "grad_norm": 0.49478843808174133,
      "learning_rate": 4.870984728804635e-05,
      "loss": 0.0659,
      "step": 2340
    },
    {
      "epoch": 3.706903353057199,
      "grad_norm": 0.7178099155426025,
      "learning_rate": 4.8680592124509975e-05,
      "loss": 0.042,
      "step": 2350
    },
    {
      "epoch": 3.722682445759369,
      "grad_norm": 0.8274059295654297,
      "learning_rate": 4.8651336960973615e-05,
      "loss": 0.0587,
      "step": 2360
    },
    {
      "epoch": 3.7384615384615385,
      "grad_norm": 0.9855260252952576,
      "learning_rate": 4.8622081797437255e-05,
      "loss": 0.0444,
      "step": 2370
    },
    {
      "epoch": 3.754240631163708,
      "grad_norm": 0.5825424790382385,
      "learning_rate": 4.859282663390088e-05,
      "loss": 0.0641,
      "step": 2380
    },
    {
      "epoch": 3.770019723865878,
      "grad_norm": 3.5941569805145264,
      "learning_rate": 4.856357147036452e-05,
      "loss": 0.0525,
      "step": 2390
    },
    {
      "epoch": 3.785798816568047,
      "grad_norm": 0.5278379321098328,
      "learning_rate": 4.853431630682816e-05,
      "loss": 0.0207,
      "step": 2400
    },
    {
      "epoch": 3.801577909270217,
      "grad_norm": 1.8331063985824585,
      "learning_rate": 4.850506114329179e-05,
      "loss": 0.0623,
      "step": 2410
    },
    {
      "epoch": 3.8173570019723866,
      "grad_norm": 0.3907650411128998,
      "learning_rate": 4.847580597975543e-05,
      "loss": 0.0627,
      "step": 2420
    },
    {
      "epoch": 3.8331360946745563,
      "grad_norm": 2.333859920501709,
      "learning_rate": 4.844655081621907e-05,
      "loss": 0.0488,
      "step": 2430
    },
    {
      "epoch": 3.848915187376726,
      "grad_norm": 2.543337106704712,
      "learning_rate": 4.8417295652682695e-05,
      "loss": 0.0618,
      "step": 2440
    },
    {
      "epoch": 3.8646942800788953,
      "grad_norm": 0.1025291234254837,
      "learning_rate": 4.8388040489146336e-05,
      "loss": 0.039,
      "step": 2450
    },
    {
      "epoch": 3.880473372781065,
      "grad_norm": 0.3922275900840759,
      "learning_rate": 4.8358785325609976e-05,
      "loss": 0.0491,
      "step": 2460
    },
    {
      "epoch": 3.8962524654832347,
      "grad_norm": 5.035499095916748,
      "learning_rate": 4.832953016207361e-05,
      "loss": 0.0579,
      "step": 2470
    },
    {
      "epoch": 3.9120315581854044,
      "grad_norm": 0.11964967101812363,
      "learning_rate": 4.830027499853724e-05,
      "loss": 0.0515,
      "step": 2480
    },
    {
      "epoch": 3.927810650887574,
      "grad_norm": 0.6790785789489746,
      "learning_rate": 4.827101983500088e-05,
      "loss": 0.0499,
      "step": 2490
    },
    {
      "epoch": 3.943589743589744,
      "grad_norm": 0.6352558135986328,
      "learning_rate": 4.8241764671464516e-05,
      "loss": 0.0311,
      "step": 2500
    },
    {
      "epoch": 3.959368836291913,
      "grad_norm": 1.5138894319534302,
      "learning_rate": 4.821250950792815e-05,
      "loss": 0.0481,
      "step": 2510
    },
    {
      "epoch": 3.9751479289940828,
      "grad_norm": 1.8658668994903564,
      "learning_rate": 4.818325434439179e-05,
      "loss": 0.0352,
      "step": 2520
    },
    {
      "epoch": 3.9909270216962525,
      "grad_norm": 0.28377413749694824,
      "learning_rate": 4.815399918085542e-05,
      "loss": 0.0523,
      "step": 2530
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8702866658736766,
      "eval_loss": 0.5212267637252808,
      "eval_runtime": 207.4185,
      "eval_samples_per_second": 81.063,
      "eval_steps_per_second": 5.067,
      "step": 2536
    },
    {
      "epoch": 4.006311637080868,
      "grad_norm": 0.5584222078323364,
      "learning_rate": 4.8124744017319056e-05,
      "loss": 0.0467,
      "step": 2540
    },
    {
      "epoch": 4.022090729783037,
      "grad_norm": 0.9942345023155212,
      "learning_rate": 4.8095488853782696e-05,
      "loss": 0.0326,
      "step": 2550
    },
    {
      "epoch": 4.037869822485207,
      "grad_norm": 0.9343410134315491,
      "learning_rate": 4.806623369024633e-05,
      "loss": 0.0305,
      "step": 2560
    },
    {
      "epoch": 4.0536489151873765,
      "grad_norm": 0.12703515589237213,
      "learning_rate": 4.803697852670997e-05,
      "loss": 0.0321,
      "step": 2570
    },
    {
      "epoch": 4.069428007889546,
      "grad_norm": 1.270214557647705,
      "learning_rate": 4.80077233631736e-05,
      "loss": 0.026,
      "step": 2580
    },
    {
      "epoch": 4.085207100591716,
      "grad_norm": 0.2562118172645569,
      "learning_rate": 4.797846819963724e-05,
      "loss": 0.0229,
      "step": 2590
    },
    {
      "epoch": 4.100986193293886,
      "grad_norm": 1.6153943538665771,
      "learning_rate": 4.794921303610088e-05,
      "loss": 0.0337,
      "step": 2600
    },
    {
      "epoch": 4.116765285996055,
      "grad_norm": 0.08970104157924652,
      "learning_rate": 4.791995787256451e-05,
      "loss": 0.0296,
      "step": 2610
    },
    {
      "epoch": 4.132544378698225,
      "grad_norm": 0.025684790685772896,
      "learning_rate": 4.7890702709028143e-05,
      "loss": 0.0288,
      "step": 2620
    },
    {
      "epoch": 4.148323471400395,
      "grad_norm": 1.6213947534561157,
      "learning_rate": 4.7861447545491784e-05,
      "loss": 0.025,
      "step": 2630
    },
    {
      "epoch": 4.164102564102564,
      "grad_norm": 0.04627876728773117,
      "learning_rate": 4.783219238195542e-05,
      "loss": 0.0234,
      "step": 2640
    },
    {
      "epoch": 4.179881656804734,
      "grad_norm": 0.12557685375213623,
      "learning_rate": 4.780293721841905e-05,
      "loss": 0.0214,
      "step": 2650
    },
    {
      "epoch": 4.195660749506903,
      "grad_norm": 0.01787669025361538,
      "learning_rate": 4.777368205488269e-05,
      "loss": 0.0242,
      "step": 2660
    },
    {
      "epoch": 4.211439842209073,
      "grad_norm": 0.04513806849718094,
      "learning_rate": 4.7744426891346324e-05,
      "loss": 0.0239,
      "step": 2670
    },
    {
      "epoch": 4.227218934911242,
      "grad_norm": 1.3550835847854614,
      "learning_rate": 4.771517172780996e-05,
      "loss": 0.061,
      "step": 2680
    },
    {
      "epoch": 4.242998027613412,
      "grad_norm": 0.4659636914730072,
      "learning_rate": 4.76859165642736e-05,
      "loss": 0.0242,
      "step": 2690
    },
    {
      "epoch": 4.258777120315582,
      "grad_norm": 0.5970607399940491,
      "learning_rate": 4.765666140073724e-05,
      "loss": 0.0324,
      "step": 2700
    },
    {
      "epoch": 4.2745562130177515,
      "grad_norm": 0.35014280676841736,
      "learning_rate": 4.7627406237200864e-05,
      "loss": 0.058,
      "step": 2710
    },
    {
      "epoch": 4.290335305719921,
      "grad_norm": 1.4250216484069824,
      "learning_rate": 4.7598151073664504e-05,
      "loss": 0.0363,
      "step": 2720
    },
    {
      "epoch": 4.306114398422091,
      "grad_norm": 0.28853920102119446,
      "learning_rate": 4.7568895910128144e-05,
      "loss": 0.0307,
      "step": 2730
    },
    {
      "epoch": 4.321893491124261,
      "grad_norm": 0.11392979323863983,
      "learning_rate": 4.753964074659177e-05,
      "loss": 0.0303,
      "step": 2740
    },
    {
      "epoch": 4.33767258382643,
      "grad_norm": 0.8877840042114258,
      "learning_rate": 4.751038558305541e-05,
      "loss": 0.0269,
      "step": 2750
    },
    {
      "epoch": 4.3534516765286,
      "grad_norm": 0.7551915049552917,
      "learning_rate": 4.748113041951905e-05,
      "loss": 0.0343,
      "step": 2760
    },
    {
      "epoch": 4.36923076923077,
      "grad_norm": 0.10011833161115646,
      "learning_rate": 4.745187525598268e-05,
      "loss": 0.0212,
      "step": 2770
    },
    {
      "epoch": 4.3850098619329385,
      "grad_norm": 0.40160369873046875,
      "learning_rate": 4.742262009244632e-05,
      "loss": 0.045,
      "step": 2780
    },
    {
      "epoch": 4.400788954635108,
      "grad_norm": 0.18973328173160553,
      "learning_rate": 4.739336492890996e-05,
      "loss": 0.0387,
      "step": 2790
    },
    {
      "epoch": 4.416568047337278,
      "grad_norm": 3.2575488090515137,
      "learning_rate": 4.736410976537359e-05,
      "loss": 0.0462,
      "step": 2800
    },
    {
      "epoch": 4.432347140039448,
      "grad_norm": 0.5652849674224854,
      "learning_rate": 4.7334854601837225e-05,
      "loss": 0.0218,
      "step": 2810
    },
    {
      "epoch": 4.448126232741617,
      "grad_norm": 0.06928128749132156,
      "learning_rate": 4.7305599438300865e-05,
      "loss": 0.0254,
      "step": 2820
    },
    {
      "epoch": 4.463905325443787,
      "grad_norm": 0.19706116616725922,
      "learning_rate": 4.72763442747645e-05,
      "loss": 0.0303,
      "step": 2830
    },
    {
      "epoch": 4.479684418145957,
      "grad_norm": 0.959631621837616,
      "learning_rate": 4.724708911122813e-05,
      "loss": 0.0367,
      "step": 2840
    },
    {
      "epoch": 4.4954635108481265,
      "grad_norm": 0.7533410787582397,
      "learning_rate": 4.721783394769177e-05,
      "loss": 0.0379,
      "step": 2850
    },
    {
      "epoch": 4.511242603550296,
      "grad_norm": 0.7661481499671936,
      "learning_rate": 4.7188578784155405e-05,
      "loss": 0.0268,
      "step": 2860
    },
    {
      "epoch": 4.527021696252466,
      "grad_norm": 0.4008255898952484,
      "learning_rate": 4.715932362061904e-05,
      "loss": 0.0391,
      "step": 2870
    },
    {
      "epoch": 4.542800788954635,
      "grad_norm": 0.8585015535354614,
      "learning_rate": 4.713006845708268e-05,
      "loss": 0.0259,
      "step": 2880
    },
    {
      "epoch": 4.558579881656804,
      "grad_norm": 2.254192590713501,
      "learning_rate": 4.710081329354631e-05,
      "loss": 0.0435,
      "step": 2890
    },
    {
      "epoch": 4.574358974358974,
      "grad_norm": 3.0172007083892822,
      "learning_rate": 4.707155813000995e-05,
      "loss": 0.0252,
      "step": 2900
    },
    {
      "epoch": 4.590138067061144,
      "grad_norm": 2.1166720390319824,
      "learning_rate": 4.7042302966473586e-05,
      "loss": 0.0391,
      "step": 2910
    },
    {
      "epoch": 4.6059171597633135,
      "grad_norm": 0.0665624737739563,
      "learning_rate": 4.701304780293722e-05,
      "loss": 0.0114,
      "step": 2920
    },
    {
      "epoch": 4.621696252465483,
      "grad_norm": 3.2114269733428955,
      "learning_rate": 4.698379263940086e-05,
      "loss": 0.0161,
      "step": 2930
    },
    {
      "epoch": 4.637475345167653,
      "grad_norm": 0.5018526911735535,
      "learning_rate": 4.695453747586449e-05,
      "loss": 0.0215,
      "step": 2940
    },
    {
      "epoch": 4.653254437869823,
      "grad_norm": 0.3202168345451355,
      "learning_rate": 4.6925282312328126e-05,
      "loss": 0.0425,
      "step": 2950
    },
    {
      "epoch": 4.669033530571992,
      "grad_norm": 0.23622184991836548,
      "learning_rate": 4.6896027148791766e-05,
      "loss": 0.0339,
      "step": 2960
    },
    {
      "epoch": 4.684812623274162,
      "grad_norm": 2.851116895675659,
      "learning_rate": 4.68667719852554e-05,
      "loss": 0.0535,
      "step": 2970
    },
    {
      "epoch": 4.700591715976332,
      "grad_norm": 0.6126900911331177,
      "learning_rate": 4.683751682171903e-05,
      "loss": 0.0551,
      "step": 2980
    },
    {
      "epoch": 4.7163708086785014,
      "grad_norm": 0.4081922769546509,
      "learning_rate": 4.680826165818267e-05,
      "loss": 0.0455,
      "step": 2990
    },
    {
      "epoch": 4.73214990138067,
      "grad_norm": 1.0592361688613892,
      "learning_rate": 4.6779006494646306e-05,
      "loss": 0.0334,
      "step": 3000
    },
    {
      "epoch": 4.74792899408284,
      "grad_norm": 1.1764851808547974,
      "learning_rate": 4.674975133110994e-05,
      "loss": 0.0583,
      "step": 3010
    },
    {
      "epoch": 4.76370808678501,
      "grad_norm": 1.4801008701324463,
      "learning_rate": 4.672049616757358e-05,
      "loss": 0.0278,
      "step": 3020
    },
    {
      "epoch": 4.779487179487179,
      "grad_norm": 0.9706279635429382,
      "learning_rate": 4.669124100403722e-05,
      "loss": 0.0318,
      "step": 3030
    },
    {
      "epoch": 4.795266272189349,
      "grad_norm": 0.5689172148704529,
      "learning_rate": 4.6661985840500846e-05,
      "loss": 0.0525,
      "step": 3040
    },
    {
      "epoch": 4.811045364891519,
      "grad_norm": 2.7963783740997314,
      "learning_rate": 4.6632730676964487e-05,
      "loss": 0.0358,
      "step": 3050
    },
    {
      "epoch": 4.8268244575936885,
      "grad_norm": 0.6012548208236694,
      "learning_rate": 4.660347551342813e-05,
      "loss": 0.0258,
      "step": 3060
    },
    {
      "epoch": 4.842603550295858,
      "grad_norm": 0.23902933299541473,
      "learning_rate": 4.657422034989175e-05,
      "loss": 0.0264,
      "step": 3070
    },
    {
      "epoch": 4.858382642998028,
      "grad_norm": 5.291225910186768,
      "learning_rate": 4.6544965186355393e-05,
      "loss": 0.0337,
      "step": 3080
    },
    {
      "epoch": 4.874161735700198,
      "grad_norm": 0.06552672386169434,
      "learning_rate": 4.6515710022819034e-05,
      "loss": 0.0394,
      "step": 3090
    },
    {
      "epoch": 4.889940828402366,
      "grad_norm": 0.45310357213020325,
      "learning_rate": 4.648645485928266e-05,
      "loss": 0.0078,
      "step": 3100
    },
    {
      "epoch": 4.905719921104536,
      "grad_norm": 0.47818297147750854,
      "learning_rate": 4.64571996957463e-05,
      "loss": 0.028,
      "step": 3110
    },
    {
      "epoch": 4.921499013806706,
      "grad_norm": 0.4306354820728302,
      "learning_rate": 4.642794453220994e-05,
      "loss": 0.0126,
      "step": 3120
    },
    {
      "epoch": 4.9372781065088756,
      "grad_norm": 1.6615344285964966,
      "learning_rate": 4.6398689368673574e-05,
      "loss": 0.0274,
      "step": 3130
    },
    {
      "epoch": 4.953057199211045,
      "grad_norm": 2.0297181606292725,
      "learning_rate": 4.636943420513721e-05,
      "loss": 0.0593,
      "step": 3140
    },
    {
      "epoch": 4.968836291913215,
      "grad_norm": 2.4953036308288574,
      "learning_rate": 4.634017904160085e-05,
      "loss": 0.0539,
      "step": 3150
    },
    {
      "epoch": 4.984615384615385,
      "grad_norm": 0.2525103688240051,
      "learning_rate": 4.631092387806448e-05,
      "loss": 0.0201,
      "step": 3160
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.03282719850540161,
      "learning_rate": 4.6281668714528114e-05,
      "loss": 0.0325,
      "step": 3170
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.8770667301058641,
      "eval_loss": 0.5366279482841492,
      "eval_runtime": 210.1874,
      "eval_samples_per_second": 79.995,
      "eval_steps_per_second": 5.0,
      "step": 3170
    },
    {
      "epoch": 5.01577909270217,
      "grad_norm": 0.052528973668813705,
      "learning_rate": 4.6252413550991754e-05,
      "loss": 0.0125,
      "step": 3180
    },
    {
      "epoch": 5.031558185404339,
      "grad_norm": 0.5801345109939575,
      "learning_rate": 4.622315838745539e-05,
      "loss": 0.0314,
      "step": 3190
    },
    {
      "epoch": 5.047337278106509,
      "grad_norm": 0.0460897758603096,
      "learning_rate": 4.619390322391902e-05,
      "loss": 0.01,
      "step": 3200
    },
    {
      "epoch": 5.063116370808679,
      "grad_norm": 0.6462591290473938,
      "learning_rate": 4.616464806038266e-05,
      "loss": 0.0184,
      "step": 3210
    },
    {
      "epoch": 5.0788954635108485,
      "grad_norm": 1.6911853551864624,
      "learning_rate": 4.6135392896846294e-05,
      "loss": 0.023,
      "step": 3220
    },
    {
      "epoch": 5.094674556213017,
      "grad_norm": 3.041011333465576,
      "learning_rate": 4.610613773330993e-05,
      "loss": 0.0249,
      "step": 3230
    },
    {
      "epoch": 5.110453648915187,
      "grad_norm": 0.1031661182641983,
      "learning_rate": 4.607688256977357e-05,
      "loss": 0.016,
      "step": 3240
    },
    {
      "epoch": 5.126232741617357,
      "grad_norm": 0.021294305101037025,
      "learning_rate": 4.60476274062372e-05,
      "loss": 0.0516,
      "step": 3250
    },
    {
      "epoch": 5.1420118343195265,
      "grad_norm": 0.12617583572864532,
      "learning_rate": 4.601837224270084e-05,
      "loss": 0.0378,
      "step": 3260
    },
    {
      "epoch": 5.157790927021696,
      "grad_norm": 0.19926272332668304,
      "learning_rate": 4.5989117079164475e-05,
      "loss": 0.0343,
      "step": 3270
    },
    {
      "epoch": 5.173570019723866,
      "grad_norm": 0.2689434587955475,
      "learning_rate": 4.595986191562811e-05,
      "loss": 0.0161,
      "step": 3280
    },
    {
      "epoch": 5.189349112426036,
      "grad_norm": 0.580790638923645,
      "learning_rate": 4.593060675209175e-05,
      "loss": 0.0136,
      "step": 3290
    },
    {
      "epoch": 5.205128205128205,
      "grad_norm": 0.024377338588237762,
      "learning_rate": 4.590135158855538e-05,
      "loss": 0.0148,
      "step": 3300
    },
    {
      "epoch": 5.220907297830375,
      "grad_norm": 4.878152847290039,
      "learning_rate": 4.5872096425019015e-05,
      "loss": 0.0224,
      "step": 3310
    },
    {
      "epoch": 5.236686390532545,
      "grad_norm": 0.13050827383995056,
      "learning_rate": 4.5842841261482655e-05,
      "loss": 0.0141,
      "step": 3320
    },
    {
      "epoch": 5.252465483234714,
      "grad_norm": 0.4276410937309265,
      "learning_rate": 4.581358609794629e-05,
      "loss": 0.0146,
      "step": 3330
    },
    {
      "epoch": 5.268244575936883,
      "grad_norm": 2.2303812503814697,
      "learning_rate": 4.578433093440992e-05,
      "loss": 0.0188,
      "step": 3340
    },
    {
      "epoch": 5.284023668639053,
      "grad_norm": 0.027497824281454086,
      "learning_rate": 4.575507577087356e-05,
      "loss": 0.02,
      "step": 3350
    },
    {
      "epoch": 5.299802761341223,
      "grad_norm": 2.2914693355560303,
      "learning_rate": 4.57258206073372e-05,
      "loss": 0.0301,
      "step": 3360
    },
    {
      "epoch": 5.315581854043392,
      "grad_norm": 0.5548809170722961,
      "learning_rate": 4.569656544380083e-05,
      "loss": 0.0132,
      "step": 3370
    },
    {
      "epoch": 5.331360946745562,
      "grad_norm": 0.0510341115295887,
      "learning_rate": 4.566731028026447e-05,
      "loss": 0.0234,
      "step": 3380
    },
    {
      "epoch": 5.347140039447732,
      "grad_norm": 0.8257516026496887,
      "learning_rate": 4.563805511672811e-05,
      "loss": 0.0183,
      "step": 3390
    },
    {
      "epoch": 5.3629191321499015,
      "grad_norm": 0.05683187395334244,
      "learning_rate": 4.5608799953191736e-05,
      "loss": 0.0085,
      "step": 3400
    },
    {
      "epoch": 5.378698224852071,
      "grad_norm": 0.1677439659833908,
      "learning_rate": 4.5579544789655376e-05,
      "loss": 0.0317,
      "step": 3410
    },
    {
      "epoch": 5.394477317554241,
      "grad_norm": 1.2246005535125732,
      "learning_rate": 4.5550289626119016e-05,
      "loss": 0.0281,
      "step": 3420
    },
    {
      "epoch": 5.410256410256411,
      "grad_norm": 0.5385112762451172,
      "learning_rate": 4.552103446258264e-05,
      "loss": 0.0156,
      "step": 3430
    },
    {
      "epoch": 5.42603550295858,
      "grad_norm": 0.0850900188088417,
      "learning_rate": 4.549177929904628e-05,
      "loss": 0.0347,
      "step": 3440
    },
    {
      "epoch": 5.441814595660749,
      "grad_norm": 0.28826674818992615,
      "learning_rate": 4.546252413550992e-05,
      "loss": 0.0188,
      "step": 3450
    },
    {
      "epoch": 5.457593688362919,
      "grad_norm": 1.698662519454956,
      "learning_rate": 4.5433268971973556e-05,
      "loss": 0.0146,
      "step": 3460
    },
    {
      "epoch": 5.4733727810650885,
      "grad_norm": 1.359809160232544,
      "learning_rate": 4.540401380843719e-05,
      "loss": 0.0205,
      "step": 3470
    },
    {
      "epoch": 5.489151873767258,
      "grad_norm": 1.462205410003662,
      "learning_rate": 4.537475864490083e-05,
      "loss": 0.0175,
      "step": 3480
    },
    {
      "epoch": 5.504930966469428,
      "grad_norm": 0.025118175894021988,
      "learning_rate": 4.534550348136446e-05,
      "loss": 0.014,
      "step": 3490
    },
    {
      "epoch": 5.520710059171598,
      "grad_norm": 0.5169796943664551,
      "learning_rate": 4.5316248317828096e-05,
      "loss": 0.0196,
      "step": 3500
    },
    {
      "epoch": 5.536489151873767,
      "grad_norm": 0.7617453336715698,
      "learning_rate": 4.5286993154291737e-05,
      "loss": 0.0062,
      "step": 3510
    },
    {
      "epoch": 5.552268244575937,
      "grad_norm": 0.31227219104766846,
      "learning_rate": 4.525773799075537e-05,
      "loss": 0.0161,
      "step": 3520
    },
    {
      "epoch": 5.568047337278107,
      "grad_norm": 1.047655463218689,
      "learning_rate": 4.5228482827219e-05,
      "loss": 0.0274,
      "step": 3530
    },
    {
      "epoch": 5.5838264299802765,
      "grad_norm": 3.8694283962249756,
      "learning_rate": 4.5199227663682643e-05,
      "loss": 0.0174,
      "step": 3540
    },
    {
      "epoch": 5.599605522682445,
      "grad_norm": 3.1333775520324707,
      "learning_rate": 4.516997250014628e-05,
      "loss": 0.0259,
      "step": 3550
    },
    {
      "epoch": 5.615384615384615,
      "grad_norm": 0.7620066404342651,
      "learning_rate": 4.514071733660991e-05,
      "loss": 0.0161,
      "step": 3560
    },
    {
      "epoch": 5.631163708086785,
      "grad_norm": 0.015527992509305477,
      "learning_rate": 4.511146217307355e-05,
      "loss": 0.0208,
      "step": 3570
    },
    {
      "epoch": 5.646942800788954,
      "grad_norm": 3.202822685241699,
      "learning_rate": 4.5082207009537184e-05,
      "loss": 0.0283,
      "step": 3580
    },
    {
      "epoch": 5.662721893491124,
      "grad_norm": 2.0907349586486816,
      "learning_rate": 4.5052951846000824e-05,
      "loss": 0.0203,
      "step": 3590
    },
    {
      "epoch": 5.678500986193294,
      "grad_norm": 0.03584684804081917,
      "learning_rate": 4.502369668246446e-05,
      "loss": 0.0244,
      "step": 3600
    },
    {
      "epoch": 5.6942800788954635,
      "grad_norm": 0.2894107699394226,
      "learning_rate": 4.499444151892809e-05,
      "loss": 0.037,
      "step": 3610
    },
    {
      "epoch": 5.710059171597633,
      "grad_norm": 0.20292699337005615,
      "learning_rate": 4.496518635539173e-05,
      "loss": 0.0084,
      "step": 3620
    },
    {
      "epoch": 5.725838264299803,
      "grad_norm": 1.2850444316864014,
      "learning_rate": 4.4935931191855364e-05,
      "loss": 0.0117,
      "step": 3630
    },
    {
      "epoch": 5.741617357001973,
      "grad_norm": 0.014745702035725117,
      "learning_rate": 4.4906676028319e-05,
      "loss": 0.0094,
      "step": 3640
    },
    {
      "epoch": 5.757396449704142,
      "grad_norm": 0.4417083263397217,
      "learning_rate": 4.487742086478264e-05,
      "loss": 0.0244,
      "step": 3650
    },
    {
      "epoch": 5.773175542406312,
      "grad_norm": 0.11104865372180939,
      "learning_rate": 4.484816570124627e-05,
      "loss": 0.02,
      "step": 3660
    },
    {
      "epoch": 5.788954635108482,
      "grad_norm": 0.11174998432397842,
      "learning_rate": 4.4818910537709904e-05,
      "loss": 0.0046,
      "step": 3670
    },
    {
      "epoch": 5.804733727810651,
      "grad_norm": 0.12345612794160843,
      "learning_rate": 4.4789655374173544e-05,
      "loss": 0.0263,
      "step": 3680
    },
    {
      "epoch": 5.82051282051282,
      "grad_norm": 0.02207750640809536,
      "learning_rate": 4.4760400210637185e-05,
      "loss": 0.0155,
      "step": 3690
    },
    {
      "epoch": 5.83629191321499,
      "grad_norm": 2.3778774738311768,
      "learning_rate": 4.473114504710081e-05,
      "loss": 0.0096,
      "step": 3700
    },
    {
      "epoch": 5.85207100591716,
      "grad_norm": 0.5400883555412292,
      "learning_rate": 4.470188988356445e-05,
      "loss": 0.0342,
      "step": 3710
    },
    {
      "epoch": 5.867850098619329,
      "grad_norm": 1.328544020652771,
      "learning_rate": 4.467263472002809e-05,
      "loss": 0.0397,
      "step": 3720
    },
    {
      "epoch": 5.883629191321499,
      "grad_norm": 0.04681739583611488,
      "learning_rate": 4.464337955649172e-05,
      "loss": 0.0139,
      "step": 3730
    },
    {
      "epoch": 5.899408284023669,
      "grad_norm": 0.07767568528652191,
      "learning_rate": 4.461412439295536e-05,
      "loss": 0.0203,
      "step": 3740
    },
    {
      "epoch": 5.9151873767258385,
      "grad_norm": 0.18965326249599457,
      "learning_rate": 4.4584869229419e-05,
      "loss": 0.0329,
      "step": 3750
    },
    {
      "epoch": 5.930966469428008,
      "grad_norm": 0.3129485845565796,
      "learning_rate": 4.4555614065882625e-05,
      "loss": 0.0189,
      "step": 3760
    },
    {
      "epoch": 5.946745562130177,
      "grad_norm": 0.1883663535118103,
      "learning_rate": 4.4526358902346265e-05,
      "loss": 0.0425,
      "step": 3770
    },
    {
      "epoch": 5.962524654832347,
      "grad_norm": 0.025818489491939545,
      "learning_rate": 4.4497103738809905e-05,
      "loss": 0.0096,
      "step": 3780
    },
    {
      "epoch": 5.978303747534516,
      "grad_norm": 0.26229143142700195,
      "learning_rate": 4.446784857527354e-05,
      "loss": 0.0174,
      "step": 3790
    },
    {
      "epoch": 5.994082840236686,
      "grad_norm": 1.590037226676941,
      "learning_rate": 4.443859341173717e-05,
      "loss": 0.018,
      "step": 3800
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.8814083501843701,
      "eval_loss": 0.6012779474258423,
      "eval_runtime": 201.4913,
      "eval_samples_per_second": 83.448,
      "eval_steps_per_second": 5.216,
      "step": 3804
    },
    {
      "epoch": 6.0094674556213015,
      "grad_norm": 0.06985031068325043,
      "learning_rate": 4.440933824820081e-05,
      "loss": 0.0157,
      "step": 3810
    },
    {
      "epoch": 6.025246548323471,
      "grad_norm": 0.044444914907217026,
      "learning_rate": 4.4380083084664445e-05,
      "loss": 0.0306,
      "step": 3820
    },
    {
      "epoch": 6.041025641025641,
      "grad_norm": 0.3511672914028168,
      "learning_rate": 4.435082792112808e-05,
      "loss": 0.03,
      "step": 3830
    },
    {
      "epoch": 6.056804733727811,
      "grad_norm": 0.12164810299873352,
      "learning_rate": 4.432157275759172e-05,
      "loss": 0.0241,
      "step": 3840
    },
    {
      "epoch": 6.07258382642998,
      "grad_norm": 0.22742144763469696,
      "learning_rate": 4.429231759405535e-05,
      "loss": 0.0117,
      "step": 3850
    },
    {
      "epoch": 6.08836291913215,
      "grad_norm": 0.29041215777397156,
      "learning_rate": 4.4263062430518986e-05,
      "loss": 0.008,
      "step": 3860
    },
    {
      "epoch": 6.10414201183432,
      "grad_norm": 0.08198900520801544,
      "learning_rate": 4.4233807266982626e-05,
      "loss": 0.0117,
      "step": 3870
    },
    {
      "epoch": 6.119921104536489,
      "grad_norm": 0.8045758605003357,
      "learning_rate": 4.420455210344626e-05,
      "loss": 0.0139,
      "step": 3880
    },
    {
      "epoch": 6.135700197238659,
      "grad_norm": 0.5139451026916504,
      "learning_rate": 4.417529693990989e-05,
      "loss": 0.032,
      "step": 3890
    },
    {
      "epoch": 6.151479289940829,
      "grad_norm": 1.7477734088897705,
      "learning_rate": 4.414604177637353e-05,
      "loss": 0.0299,
      "step": 3900
    },
    {
      "epoch": 6.167258382642998,
      "grad_norm": 0.27831268310546875,
      "learning_rate": 4.4116786612837166e-05,
      "loss": 0.0123,
      "step": 3910
    },
    {
      "epoch": 6.183037475345167,
      "grad_norm": 0.18857687711715698,
      "learning_rate": 4.4087531449300806e-05,
      "loss": 0.0092,
      "step": 3920
    },
    {
      "epoch": 6.198816568047337,
      "grad_norm": 0.011404969729483128,
      "learning_rate": 4.405827628576444e-05,
      "loss": 0.0093,
      "step": 3930
    },
    {
      "epoch": 6.214595660749507,
      "grad_norm": 1.237561821937561,
      "learning_rate": 4.402902112222807e-05,
      "loss": 0.0055,
      "step": 3940
    },
    {
      "epoch": 6.2303747534516765,
      "grad_norm": 0.16481684148311615,
      "learning_rate": 4.399976595869171e-05,
      "loss": 0.0254,
      "step": 3950
    },
    {
      "epoch": 6.246153846153846,
      "grad_norm": 1.0518981218338013,
      "learning_rate": 4.3970510795155346e-05,
      "loss": 0.0161,
      "step": 3960
    },
    {
      "epoch": 6.261932938856016,
      "grad_norm": 0.020243095234036446,
      "learning_rate": 4.394125563161898e-05,
      "loss": 0.0258,
      "step": 3970
    },
    {
      "epoch": 6.277712031558186,
      "grad_norm": 0.12294413894414902,
      "learning_rate": 4.391200046808262e-05,
      "loss": 0.0198,
      "step": 3980
    },
    {
      "epoch": 6.293491124260355,
      "grad_norm": 0.0343402661383152,
      "learning_rate": 4.388274530454625e-05,
      "loss": 0.0149,
      "step": 3990
    },
    {
      "epoch": 6.309270216962525,
      "grad_norm": 1.0853698253631592,
      "learning_rate": 4.385349014100989e-05,
      "loss": 0.0158,
      "step": 4000
    },
    {
      "epoch": 6.325049309664694,
      "grad_norm": 1.1834975481033325,
      "learning_rate": 4.382423497747353e-05,
      "loss": 0.0358,
      "step": 4010
    },
    {
      "epoch": 6.3408284023668635,
      "grad_norm": 0.5232424736022949,
      "learning_rate": 4.379497981393717e-05,
      "loss": 0.0223,
      "step": 4020
    },
    {
      "epoch": 6.356607495069033,
      "grad_norm": 0.07631134241819382,
      "learning_rate": 4.3765724650400793e-05,
      "loss": 0.022,
      "step": 4030
    },
    {
      "epoch": 6.372386587771203,
      "grad_norm": 0.48798930644989014,
      "learning_rate": 4.3736469486864434e-05,
      "loss": 0.0216,
      "step": 4040
    },
    {
      "epoch": 6.388165680473373,
      "grad_norm": 0.01765827275812626,
      "learning_rate": 4.3707214323328074e-05,
      "loss": 0.0154,
      "step": 4050
    },
    {
      "epoch": 6.403944773175542,
      "grad_norm": 0.029281791299581528,
      "learning_rate": 4.36779591597917e-05,
      "loss": 0.0219,
      "step": 4060
    },
    {
      "epoch": 6.419723865877712,
      "grad_norm": 1.2863438129425049,
      "learning_rate": 4.364870399625534e-05,
      "loss": 0.0289,
      "step": 4070
    },
    {
      "epoch": 6.435502958579882,
      "grad_norm": 0.12536095082759857,
      "learning_rate": 4.361944883271898e-05,
      "loss": 0.0051,
      "step": 4080
    },
    {
      "epoch": 6.4512820512820515,
      "grad_norm": 0.0371282659471035,
      "learning_rate": 4.3590193669182614e-05,
      "loss": 0.014,
      "step": 4090
    },
    {
      "epoch": 6.467061143984221,
      "grad_norm": 0.21694181859493256,
      "learning_rate": 4.356093850564625e-05,
      "loss": 0.0163,
      "step": 4100
    },
    {
      "epoch": 6.482840236686391,
      "grad_norm": 0.052309729158878326,
      "learning_rate": 4.353168334210989e-05,
      "loss": 0.0133,
      "step": 4110
    },
    {
      "epoch": 6.498619329388561,
      "grad_norm": 0.09604379534721375,
      "learning_rate": 4.350242817857352e-05,
      "loss": 0.0247,
      "step": 4120
    },
    {
      "epoch": 6.51439842209073,
      "grad_norm": 0.03418343514204025,
      "learning_rate": 4.3473173015037154e-05,
      "loss": 0.0164,
      "step": 4130
    },
    {
      "epoch": 6.530177514792899,
      "grad_norm": 3.0268921852111816,
      "learning_rate": 4.3443917851500794e-05,
      "loss": 0.0107,
      "step": 4140
    },
    {
      "epoch": 6.545956607495069,
      "grad_norm": 1.4225904941558838,
      "learning_rate": 4.341466268796443e-05,
      "loss": 0.0169,
      "step": 4150
    },
    {
      "epoch": 6.5617357001972385,
      "grad_norm": 2.273333787918091,
      "learning_rate": 4.338540752442806e-05,
      "loss": 0.0035,
      "step": 4160
    },
    {
      "epoch": 6.577514792899408,
      "grad_norm": 6.213264465332031,
      "learning_rate": 4.33561523608917e-05,
      "loss": 0.0084,
      "step": 4170
    },
    {
      "epoch": 6.593293885601578,
      "grad_norm": 1.4770134687423706,
      "learning_rate": 4.3326897197355335e-05,
      "loss": 0.0146,
      "step": 4180
    },
    {
      "epoch": 6.609072978303748,
      "grad_norm": 0.10953360050916672,
      "learning_rate": 4.329764203381897e-05,
      "loss": 0.0025,
      "step": 4190
    },
    {
      "epoch": 6.624852071005917,
      "grad_norm": 0.29918426275253296,
      "learning_rate": 4.326838687028261e-05,
      "loss": 0.0276,
      "step": 4200
    },
    {
      "epoch": 6.640631163708087,
      "grad_norm": 8.890954971313477,
      "learning_rate": 4.323913170674624e-05,
      "loss": 0.0089,
      "step": 4210
    },
    {
      "epoch": 6.656410256410257,
      "grad_norm": 0.2132849395275116,
      "learning_rate": 4.3209876543209875e-05,
      "loss": 0.0143,
      "step": 4220
    },
    {
      "epoch": 6.672189349112426,
      "grad_norm": 0.011949315667152405,
      "learning_rate": 4.3180621379673515e-05,
      "loss": 0.0155,
      "step": 4230
    },
    {
      "epoch": 6.687968441814595,
      "grad_norm": 3.0653183460235596,
      "learning_rate": 4.315136621613715e-05,
      "loss": 0.0312,
      "step": 4240
    },
    {
      "epoch": 6.703747534516765,
      "grad_norm": 0.02269068732857704,
      "learning_rate": 4.312211105260079e-05,
      "loss": 0.0256,
      "step": 4250
    },
    {
      "epoch": 6.719526627218935,
      "grad_norm": 0.172673299908638,
      "learning_rate": 4.309285588906442e-05,
      "loss": 0.0229,
      "step": 4260
    },
    {
      "epoch": 6.735305719921104,
      "grad_norm": 1.8061985969543457,
      "learning_rate": 4.3063600725528055e-05,
      "loss": 0.0091,
      "step": 4270
    },
    {
      "epoch": 6.751084812623274,
      "grad_norm": 0.07561706006526947,
      "learning_rate": 4.3034345561991695e-05,
      "loss": 0.0241,
      "step": 4280
    },
    {
      "epoch": 6.766863905325444,
      "grad_norm": 0.4487381875514984,
      "learning_rate": 4.300509039845533e-05,
      "loss": 0.0182,
      "step": 4290
    },
    {
      "epoch": 6.7826429980276135,
      "grad_norm": 0.32128313183784485,
      "learning_rate": 4.297583523491896e-05,
      "loss": 0.0087,
      "step": 4300
    },
    {
      "epoch": 6.798422090729783,
      "grad_norm": 0.013273555785417557,
      "learning_rate": 4.29465800713826e-05,
      "loss": 0.0113,
      "step": 4310
    },
    {
      "epoch": 6.814201183431953,
      "grad_norm": 2.611356258392334,
      "learning_rate": 4.2917324907846236e-05,
      "loss": 0.0176,
      "step": 4320
    },
    {
      "epoch": 6.829980276134123,
      "grad_norm": 0.3103744089603424,
      "learning_rate": 4.288806974430987e-05,
      "loss": 0.0092,
      "step": 4330
    },
    {
      "epoch": 6.845759368836292,
      "grad_norm": 0.2215832769870758,
      "learning_rate": 4.285881458077351e-05,
      "loss": 0.0279,
      "step": 4340
    },
    {
      "epoch": 6.861538461538462,
      "grad_norm": 0.1537320464849472,
      "learning_rate": 4.282955941723714e-05,
      "loss": 0.0234,
      "step": 4350
    },
    {
      "epoch": 6.877317554240631,
      "grad_norm": 0.010784070938825607,
      "learning_rate": 4.280030425370078e-05,
      "loss": 0.0152,
      "step": 4360
    },
    {
      "epoch": 6.8930966469428006,
      "grad_norm": 0.0735778734087944,
      "learning_rate": 4.2771049090164416e-05,
      "loss": 0.0337,
      "step": 4370
    },
    {
      "epoch": 6.90887573964497,
      "grad_norm": 0.045729346573352814,
      "learning_rate": 4.2741793926628056e-05,
      "loss": 0.0155,
      "step": 4380
    },
    {
      "epoch": 6.92465483234714,
      "grad_norm": 1.035165786743164,
      "learning_rate": 4.271253876309169e-05,
      "loss": 0.0086,
      "step": 4390
    },
    {
      "epoch": 6.94043392504931,
      "grad_norm": 0.6266957521438599,
      "learning_rate": 4.268328359955532e-05,
      "loss": 0.0311,
      "step": 4400
    },
    {
      "epoch": 6.956213017751479,
      "grad_norm": 0.09634855389595032,
      "learning_rate": 4.265402843601896e-05,
      "loss": 0.0149,
      "step": 4410
    },
    {
      "epoch": 6.971992110453649,
      "grad_norm": 0.019426653161644936,
      "learning_rate": 4.2624773272482596e-05,
      "loss": 0.0102,
      "step": 4420
    },
    {
      "epoch": 6.987771203155819,
      "grad_norm": 0.051778268069028854,
      "learning_rate": 4.259551810894623e-05,
      "loss": 0.0126,
      "step": 4430
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.8757582966575472,
      "eval_loss": 0.6105496883392334,
      "eval_runtime": 212.4817,
      "eval_samples_per_second": 79.132,
      "eval_steps_per_second": 4.946,
      "step": 4438
    },
    {
      "epoch": 7.003155818540434,
      "grad_norm": 0.02394687570631504,
      "learning_rate": 4.256626294540987e-05,
      "loss": 0.017,
      "step": 4440
    },
    {
      "epoch": 7.018934911242604,
      "grad_norm": 0.08219816535711288,
      "learning_rate": 4.25370077818735e-05,
      "loss": 0.0111,
      "step": 4450
    },
    {
      "epoch": 7.0347140039447735,
      "grad_norm": 0.06318137049674988,
      "learning_rate": 4.2507752618337137e-05,
      "loss": 0.0264,
      "step": 4460
    },
    {
      "epoch": 7.050493096646943,
      "grad_norm": 0.05589878931641579,
      "learning_rate": 4.247849745480078e-05,
      "loss": 0.0122,
      "step": 4470
    },
    {
      "epoch": 7.066272189349112,
      "grad_norm": 0.08578209578990936,
      "learning_rate": 4.244924229126441e-05,
      "loss": 0.0201,
      "step": 4480
    },
    {
      "epoch": 7.082051282051282,
      "grad_norm": 0.02801964432001114,
      "learning_rate": 4.2419987127728043e-05,
      "loss": 0.0084,
      "step": 4490
    },
    {
      "epoch": 7.0978303747534515,
      "grad_norm": 0.010143310762941837,
      "learning_rate": 4.2390731964191684e-05,
      "loss": 0.0045,
      "step": 4500
    },
    {
      "epoch": 7.113609467455621,
      "grad_norm": 0.13118788599967957,
      "learning_rate": 4.236147680065532e-05,
      "loss": 0.0141,
      "step": 4510
    },
    {
      "epoch": 7.129388560157791,
      "grad_norm": 0.012179028242826462,
      "learning_rate": 4.233222163711895e-05,
      "loss": 0.0091,
      "step": 4520
    },
    {
      "epoch": 7.145167652859961,
      "grad_norm": 0.03329900652170181,
      "learning_rate": 4.230296647358259e-05,
      "loss": 0.0097,
      "step": 4530
    },
    {
      "epoch": 7.16094674556213,
      "grad_norm": 0.006032777018845081,
      "learning_rate": 4.2273711310046224e-05,
      "loss": 0.0021,
      "step": 4540
    },
    {
      "epoch": 7.1767258382643,
      "grad_norm": 0.05243273451924324,
      "learning_rate": 4.224445614650986e-05,
      "loss": 0.0032,
      "step": 4550
    },
    {
      "epoch": 7.19250493096647,
      "grad_norm": 0.01332933735102415,
      "learning_rate": 4.22152009829735e-05,
      "loss": 0.0026,
      "step": 4560
    },
    {
      "epoch": 7.208284023668639,
      "grad_norm": 0.0197971910238266,
      "learning_rate": 4.218594581943713e-05,
      "loss": 0.0112,
      "step": 4570
    },
    {
      "epoch": 7.224063116370809,
      "grad_norm": 1.026350975036621,
      "learning_rate": 4.215669065590077e-05,
      "loss": 0.0065,
      "step": 4580
    },
    {
      "epoch": 7.239842209072978,
      "grad_norm": 0.045384567230939865,
      "learning_rate": 4.2127435492364404e-05,
      "loss": 0.0027,
      "step": 4590
    },
    {
      "epoch": 7.255621301775148,
      "grad_norm": 0.014712037518620491,
      "learning_rate": 4.209818032882804e-05,
      "loss": 0.0067,
      "step": 4600
    },
    {
      "epoch": 7.271400394477317,
      "grad_norm": 0.03328992426395416,
      "learning_rate": 4.206892516529168e-05,
      "loss": 0.0403,
      "step": 4610
    },
    {
      "epoch": 7.287179487179487,
      "grad_norm": 0.034078169614076614,
      "learning_rate": 4.203967000175531e-05,
      "loss": 0.0071,
      "step": 4620
    },
    {
      "epoch": 7.302958579881657,
      "grad_norm": 0.050776407122612,
      "learning_rate": 4.2010414838218944e-05,
      "loss": 0.0082,
      "step": 4630
    },
    {
      "epoch": 7.3187376725838265,
      "grad_norm": 0.03349132090806961,
      "learning_rate": 4.1981159674682585e-05,
      "loss": 0.006,
      "step": 4640
    },
    {
      "epoch": 7.334516765285996,
      "grad_norm": 0.02265019901096821,
      "learning_rate": 4.195190451114622e-05,
      "loss": 0.0105,
      "step": 4650
    },
    {
      "epoch": 7.350295857988166,
      "grad_norm": 0.054092906415462494,
      "learning_rate": 4.192264934760986e-05,
      "loss": 0.0039,
      "step": 4660
    },
    {
      "epoch": 7.366074950690336,
      "grad_norm": 0.013856948353350163,
      "learning_rate": 4.189339418407349e-05,
      "loss": 0.0014,
      "step": 4670
    },
    {
      "epoch": 7.381854043392505,
      "grad_norm": 0.0796990841627121,
      "learning_rate": 4.1864139020537125e-05,
      "loss": 0.0127,
      "step": 4680
    },
    {
      "epoch": 7.397633136094674,
      "grad_norm": 0.3131590485572815,
      "learning_rate": 4.1834883857000765e-05,
      "loss": 0.002,
      "step": 4690
    },
    {
      "epoch": 7.413412228796844,
      "grad_norm": 0.0054233805276453495,
      "learning_rate": 4.18056286934644e-05,
      "loss": 0.0033,
      "step": 4700
    },
    {
      "epoch": 7.4291913214990135,
      "grad_norm": 0.396232932806015,
      "learning_rate": 4.177637352992804e-05,
      "loss": 0.02,
      "step": 4710
    },
    {
      "epoch": 7.444970414201183,
      "grad_norm": 0.019801951944828033,
      "learning_rate": 4.174711836639167e-05,
      "loss": 0.0052,
      "step": 4720
    },
    {
      "epoch": 7.460749506903353,
      "grad_norm": 0.006826908327639103,
      "learning_rate": 4.1717863202855305e-05,
      "loss": 0.0074,
      "step": 4730
    },
    {
      "epoch": 7.476528599605523,
      "grad_norm": 1.0829342603683472,
      "learning_rate": 4.1688608039318945e-05,
      "loss": 0.0076,
      "step": 4740
    },
    {
      "epoch": 7.492307692307692,
      "grad_norm": 0.017536042258143425,
      "learning_rate": 4.165935287578258e-05,
      "loss": 0.0172,
      "step": 4750
    },
    {
      "epoch": 7.508086785009862,
      "grad_norm": 1.226896047592163,
      "learning_rate": 4.163009771224621e-05,
      "loss": 0.0119,
      "step": 4760
    },
    {
      "epoch": 7.523865877712032,
      "grad_norm": 0.029934881255030632,
      "learning_rate": 4.160084254870985e-05,
      "loss": 0.0129,
      "step": 4770
    },
    {
      "epoch": 7.5396449704142015,
      "grad_norm": 0.01744828186929226,
      "learning_rate": 4.1571587385173486e-05,
      "loss": 0.0172,
      "step": 4780
    },
    {
      "epoch": 7.555424063116371,
      "grad_norm": 0.026391522958874702,
      "learning_rate": 4.154233222163712e-05,
      "loss": 0.0068,
      "step": 4790
    },
    {
      "epoch": 7.571203155818541,
      "grad_norm": 0.05243634805083275,
      "learning_rate": 4.151307705810076e-05,
      "loss": 0.0016,
      "step": 4800
    },
    {
      "epoch": 7.58698224852071,
      "grad_norm": 0.028539560735225677,
      "learning_rate": 4.148382189456439e-05,
      "loss": 0.0063,
      "step": 4810
    },
    {
      "epoch": 7.602761341222879,
      "grad_norm": 0.0874045193195343,
      "learning_rate": 4.1454566731028026e-05,
      "loss": 0.0012,
      "step": 4820
    },
    {
      "epoch": 7.618540433925049,
      "grad_norm": 0.015369763597846031,
      "learning_rate": 4.1425311567491666e-05,
      "loss": 0.0107,
      "step": 4830
    },
    {
      "epoch": 7.634319526627219,
      "grad_norm": 0.02872064895927906,
      "learning_rate": 4.13960564039553e-05,
      "loss": 0.0015,
      "step": 4840
    },
    {
      "epoch": 7.6500986193293885,
      "grad_norm": 0.01105371955782175,
      "learning_rate": 4.136680124041893e-05,
      "loss": 0.0098,
      "step": 4850
    },
    {
      "epoch": 7.665877712031558,
      "grad_norm": 0.15896335244178772,
      "learning_rate": 4.133754607688257e-05,
      "loss": 0.0183,
      "step": 4860
    },
    {
      "epoch": 7.681656804733728,
      "grad_norm": 0.1425144225358963,
      "learning_rate": 4.1308290913346206e-05,
      "loss": 0.0085,
      "step": 4870
    },
    {
      "epoch": 7.697435897435898,
      "grad_norm": 0.1333867609500885,
      "learning_rate": 4.127903574980984e-05,
      "loss": 0.0025,
      "step": 4880
    },
    {
      "epoch": 7.713214990138067,
      "grad_norm": 0.012034928426146507,
      "learning_rate": 4.124978058627348e-05,
      "loss": 0.0101,
      "step": 4890
    },
    {
      "epoch": 7.728994082840237,
      "grad_norm": 0.625001072883606,
      "learning_rate": 4.122052542273711e-05,
      "loss": 0.0059,
      "step": 4900
    },
    {
      "epoch": 7.744773175542406,
      "grad_norm": 5.055231094360352,
      "learning_rate": 4.1191270259200746e-05,
      "loss": 0.0199,
      "step": 4910
    },
    {
      "epoch": 7.760552268244576,
      "grad_norm": 0.00396701181307435,
      "learning_rate": 4.1162015095664387e-05,
      "loss": 0.0043,
      "step": 4920
    },
    {
      "epoch": 7.776331360946745,
      "grad_norm": 4.018349647521973,
      "learning_rate": 4.113275993212802e-05,
      "loss": 0.0357,
      "step": 4930
    },
    {
      "epoch": 7.792110453648915,
      "grad_norm": 0.05883222445845604,
      "learning_rate": 4.110350476859166e-05,
      "loss": 0.005,
      "step": 4940
    },
    {
      "epoch": 7.807889546351085,
      "grad_norm": 0.1935836374759674,
      "learning_rate": 4.1074249605055293e-05,
      "loss": 0.0135,
      "step": 4950
    },
    {
      "epoch": 7.823668639053254,
      "grad_norm": 0.2149910181760788,
      "learning_rate": 4.1044994441518934e-05,
      "loss": 0.0036,
      "step": 4960
    },
    {
      "epoch": 7.839447731755424,
      "grad_norm": 1.9852126836776733,
      "learning_rate": 4.101573927798257e-05,
      "loss": 0.0272,
      "step": 4970
    },
    {
      "epoch": 7.855226824457594,
      "grad_norm": 0.09026649594306946,
      "learning_rate": 4.09864841144462e-05,
      "loss": 0.0264,
      "step": 4980
    },
    {
      "epoch": 7.8710059171597635,
      "grad_norm": 0.5858010053634644,
      "learning_rate": 4.095722895090984e-05,
      "loss": 0.0172,
      "step": 4990
    },
    {
      "epoch": 7.886785009861933,
      "grad_norm": 0.06356684118509293,
      "learning_rate": 4.0927973787373474e-05,
      "loss": 0.0136,
      "step": 5000
    },
    {
      "epoch": 7.902564102564103,
      "grad_norm": 0.009439956396818161,
      "learning_rate": 4.089871862383711e-05,
      "loss": 0.0111,
      "step": 5010
    },
    {
      "epoch": 7.918343195266273,
      "grad_norm": 0.056362830102443695,
      "learning_rate": 4.086946346030075e-05,
      "loss": 0.0186,
      "step": 5020
    },
    {
      "epoch": 7.934122287968441,
      "grad_norm": 0.12050718069076538,
      "learning_rate": 4.084020829676438e-05,
      "loss": 0.0156,
      "step": 5030
    },
    {
      "epoch": 7.949901380670611,
      "grad_norm": 0.10461562126874924,
      "learning_rate": 4.081095313322802e-05,
      "loss": 0.0131,
      "step": 5040
    },
    {
      "epoch": 7.965680473372781,
      "grad_norm": 0.2781742215156555,
      "learning_rate": 4.0781697969691654e-05,
      "loss": 0.0084,
      "step": 5050
    },
    {
      "epoch": 7.9814595660749506,
      "grad_norm": 1.1466056108474731,
      "learning_rate": 4.075244280615529e-05,
      "loss": 0.0097,
      "step": 5060
    },
    {
      "epoch": 7.99723865877712,
      "grad_norm": 0.5138241052627563,
      "learning_rate": 4.072318764261893e-05,
      "loss": 0.025,
      "step": 5070
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.8662424170334245,
      "eval_loss": 0.7095739841461182,
      "eval_runtime": 209.2689,
      "eval_samples_per_second": 80.346,
      "eval_steps_per_second": 5.022,
      "step": 5072
    },
    {
      "epoch": 8.012623274161736,
      "grad_norm": 0.00798851903527975,
      "learning_rate": 4.069393247908256e-05,
      "loss": 0.0194,
      "step": 5080
    },
    {
      "epoch": 8.028402366863906,
      "grad_norm": 0.5786880850791931,
      "learning_rate": 4.0664677315546194e-05,
      "loss": 0.0036,
      "step": 5090
    },
    {
      "epoch": 8.044181459566074,
      "grad_norm": 2.2195727825164795,
      "learning_rate": 4.0635422152009835e-05,
      "loss": 0.004,
      "step": 5100
    },
    {
      "epoch": 8.059960552268244,
      "grad_norm": 0.006014765240252018,
      "learning_rate": 4.060616698847347e-05,
      "loss": 0.0138,
      "step": 5110
    },
    {
      "epoch": 8.075739644970414,
      "grad_norm": 0.09629178047180176,
      "learning_rate": 4.05769118249371e-05,
      "loss": 0.0073,
      "step": 5120
    },
    {
      "epoch": 8.091518737672583,
      "grad_norm": 0.00492057204246521,
      "learning_rate": 4.054765666140074e-05,
      "loss": 0.0134,
      "step": 5130
    },
    {
      "epoch": 8.107297830374753,
      "grad_norm": 0.07613085210323334,
      "learning_rate": 4.0518401497864375e-05,
      "loss": 0.012,
      "step": 5140
    },
    {
      "epoch": 8.123076923076923,
      "grad_norm": 0.02018551528453827,
      "learning_rate": 4.048914633432801e-05,
      "loss": 0.006,
      "step": 5150
    },
    {
      "epoch": 8.138856015779092,
      "grad_norm": 0.05077870935201645,
      "learning_rate": 4.045989117079165e-05,
      "loss": 0.0066,
      "step": 5160
    },
    {
      "epoch": 8.154635108481262,
      "grad_norm": 1.1129658222198486,
      "learning_rate": 4.043063600725528e-05,
      "loss": 0.0348,
      "step": 5170
    },
    {
      "epoch": 8.170414201183432,
      "grad_norm": 0.336326003074646,
      "learning_rate": 4.0401380843718915e-05,
      "loss": 0.0148,
      "step": 5180
    },
    {
      "epoch": 8.186193293885601,
      "grad_norm": 2.8921701908111572,
      "learning_rate": 4.0372125680182555e-05,
      "loss": 0.0144,
      "step": 5190
    },
    {
      "epoch": 8.201972386587771,
      "grad_norm": 0.046340085566043854,
      "learning_rate": 4.034287051664619e-05,
      "loss": 0.0091,
      "step": 5200
    },
    {
      "epoch": 8.21775147928994,
      "grad_norm": 1.1659610271453857,
      "learning_rate": 4.031361535310982e-05,
      "loss": 0.0216,
      "step": 5210
    },
    {
      "epoch": 8.23353057199211,
      "grad_norm": 0.054742373526096344,
      "learning_rate": 4.028436018957346e-05,
      "loss": 0.0027,
      "step": 5220
    },
    {
      "epoch": 8.24930966469428,
      "grad_norm": 0.7015115022659302,
      "learning_rate": 4.0255105026037095e-05,
      "loss": 0.0042,
      "step": 5230
    },
    {
      "epoch": 8.26508875739645,
      "grad_norm": 0.02816479094326496,
      "learning_rate": 4.022584986250073e-05,
      "loss": 0.0198,
      "step": 5240
    },
    {
      "epoch": 8.28086785009862,
      "grad_norm": 0.010592793114483356,
      "learning_rate": 4.019659469896437e-05,
      "loss": 0.0036,
      "step": 5250
    },
    {
      "epoch": 8.29664694280079,
      "grad_norm": 0.09080522507429123,
      "learning_rate": 4.016733953542801e-05,
      "loss": 0.0026,
      "step": 5260
    },
    {
      "epoch": 8.312426035502959,
      "grad_norm": 0.047365330159664154,
      "learning_rate": 4.013808437189164e-05,
      "loss": 0.0012,
      "step": 5270
    },
    {
      "epoch": 8.328205128205129,
      "grad_norm": 0.006058692466467619,
      "learning_rate": 4.0108829208355276e-05,
      "loss": 0.0145,
      "step": 5280
    },
    {
      "epoch": 8.343984220907299,
      "grad_norm": 1.7155430316925049,
      "learning_rate": 4.0079574044818916e-05,
      "loss": 0.0034,
      "step": 5290
    },
    {
      "epoch": 8.359763313609468,
      "grad_norm": 0.0838598683476448,
      "learning_rate": 4.005031888128255e-05,
      "loss": 0.001,
      "step": 5300
    },
    {
      "epoch": 8.375542406311638,
      "grad_norm": 0.021469442173838615,
      "learning_rate": 4.002106371774618e-05,
      "loss": 0.0086,
      "step": 5310
    },
    {
      "epoch": 8.391321499013806,
      "grad_norm": 0.16749246418476105,
      "learning_rate": 3.999180855420982e-05,
      "loss": 0.0125,
      "step": 5320
    },
    {
      "epoch": 8.407100591715976,
      "grad_norm": 0.034491587430238724,
      "learning_rate": 3.9962553390673456e-05,
      "loss": 0.0093,
      "step": 5330
    },
    {
      "epoch": 8.422879684418145,
      "grad_norm": 0.03943167254328728,
      "learning_rate": 3.993329822713709e-05,
      "loss": 0.0127,
      "step": 5340
    },
    {
      "epoch": 8.438658777120315,
      "grad_norm": 0.006053886841982603,
      "learning_rate": 3.990404306360073e-05,
      "loss": 0.0021,
      "step": 5350
    },
    {
      "epoch": 8.454437869822485,
      "grad_norm": 0.18024314939975739,
      "learning_rate": 3.987478790006436e-05,
      "loss": 0.0085,
      "step": 5360
    },
    {
      "epoch": 8.470216962524654,
      "grad_norm": 0.006914813537150621,
      "learning_rate": 3.9845532736528e-05,
      "loss": 0.0054,
      "step": 5370
    },
    {
      "epoch": 8.485996055226824,
      "grad_norm": 0.005932500120252371,
      "learning_rate": 3.9816277572991637e-05,
      "loss": 0.0216,
      "step": 5380
    },
    {
      "epoch": 8.501775147928994,
      "grad_norm": 0.05607425794005394,
      "learning_rate": 3.978702240945527e-05,
      "loss": 0.0022,
      "step": 5390
    },
    {
      "epoch": 8.517554240631164,
      "grad_norm": 0.4140099287033081,
      "learning_rate": 3.975776724591891e-05,
      "loss": 0.0111,
      "step": 5400
    },
    {
      "epoch": 8.533333333333333,
      "grad_norm": 0.060993850231170654,
      "learning_rate": 3.9728512082382543e-05,
      "loss": 0.0114,
      "step": 5410
    },
    {
      "epoch": 8.549112426035503,
      "grad_norm": 1.049685001373291,
      "learning_rate": 3.969925691884618e-05,
      "loss": 0.005,
      "step": 5420
    },
    {
      "epoch": 8.564891518737673,
      "grad_norm": 3.2233684062957764,
      "learning_rate": 3.967000175530982e-05,
      "loss": 0.0058,
      "step": 5430
    },
    {
      "epoch": 8.580670611439842,
      "grad_norm": 0.15339843928813934,
      "learning_rate": 3.964074659177345e-05,
      "loss": 0.022,
      "step": 5440
    },
    {
      "epoch": 8.596449704142012,
      "grad_norm": 0.047002486884593964,
      "learning_rate": 3.9611491428237084e-05,
      "loss": 0.008,
      "step": 5450
    },
    {
      "epoch": 8.612228796844182,
      "grad_norm": 0.44674113392829895,
      "learning_rate": 3.9582236264700724e-05,
      "loss": 0.0053,
      "step": 5460
    },
    {
      "epoch": 8.628007889546351,
      "grad_norm": 0.020724788308143616,
      "learning_rate": 3.955298110116436e-05,
      "loss": 0.0224,
      "step": 5470
    },
    {
      "epoch": 8.643786982248521,
      "grad_norm": 0.0769459679722786,
      "learning_rate": 3.952372593762799e-05,
      "loss": 0.0021,
      "step": 5480
    },
    {
      "epoch": 8.65956607495069,
      "grad_norm": 0.003506723325699568,
      "learning_rate": 3.949447077409163e-05,
      "loss": 0.0059,
      "step": 5490
    },
    {
      "epoch": 8.67534516765286,
      "grad_norm": 0.03350786119699478,
      "learning_rate": 3.9465215610555264e-05,
      "loss": 0.0169,
      "step": 5500
    },
    {
      "epoch": 8.69112426035503,
      "grad_norm": 4.03862190246582,
      "learning_rate": 3.94359604470189e-05,
      "loss": 0.0108,
      "step": 5510
    },
    {
      "epoch": 8.7069033530572,
      "grad_norm": 3.8526105880737305,
      "learning_rate": 3.940670528348254e-05,
      "loss": 0.0198,
      "step": 5520
    },
    {
      "epoch": 8.722682445759368,
      "grad_norm": 1.3968818187713623,
      "learning_rate": 3.937745011994618e-05,
      "loss": 0.0051,
      "step": 5530
    },
    {
      "epoch": 8.73846153846154,
      "grad_norm": 0.0173540860414505,
      "learning_rate": 3.9348194956409804e-05,
      "loss": 0.008,
      "step": 5540
    },
    {
      "epoch": 8.754240631163707,
      "grad_norm": 0.02322995848953724,
      "learning_rate": 3.9318939792873444e-05,
      "loss": 0.033,
      "step": 5550
    },
    {
      "epoch": 8.770019723865877,
      "grad_norm": 0.011355564929544926,
      "learning_rate": 3.9289684629337085e-05,
      "loss": 0.0105,
      "step": 5560
    },
    {
      "epoch": 8.785798816568047,
      "grad_norm": 0.7915616035461426,
      "learning_rate": 3.926042946580071e-05,
      "loss": 0.0172,
      "step": 5570
    },
    {
      "epoch": 8.801577909270216,
      "grad_norm": 0.029268572106957436,
      "learning_rate": 3.923117430226435e-05,
      "loss": 0.0192,
      "step": 5580
    },
    {
      "epoch": 8.817357001972386,
      "grad_norm": 0.10351608693599701,
      "learning_rate": 3.920191913872799e-05,
      "loss": 0.0029,
      "step": 5590
    },
    {
      "epoch": 8.833136094674556,
      "grad_norm": 0.8300508856773376,
      "learning_rate": 3.9172663975191625e-05,
      "loss": 0.0118,
      "step": 5600
    },
    {
      "epoch": 8.848915187376726,
      "grad_norm": 1.1682597398757935,
      "learning_rate": 3.914340881165526e-05,
      "loss": 0.0065,
      "step": 5610
    },
    {
      "epoch": 8.864694280078895,
      "grad_norm": 0.015186404809355736,
      "learning_rate": 3.91141536481189e-05,
      "loss": 0.0174,
      "step": 5620
    },
    {
      "epoch": 8.880473372781065,
      "grad_norm": 0.2656301259994507,
      "learning_rate": 3.908489848458253e-05,
      "loss": 0.0053,
      "step": 5630
    },
    {
      "epoch": 8.896252465483235,
      "grad_norm": 0.044251084327697754,
      "learning_rate": 3.9055643321046165e-05,
      "loss": 0.0034,
      "step": 5640
    },
    {
      "epoch": 8.912031558185404,
      "grad_norm": 0.043460603803396225,
      "learning_rate": 3.9026388157509805e-05,
      "loss": 0.0067,
      "step": 5650
    },
    {
      "epoch": 8.927810650887574,
      "grad_norm": 1.8549491167068481,
      "learning_rate": 3.899713299397344e-05,
      "loss": 0.0131,
      "step": 5660
    },
    {
      "epoch": 8.943589743589744,
      "grad_norm": 0.008230042643845081,
      "learning_rate": 3.896787783043707e-05,
      "loss": 0.0025,
      "step": 5670
    },
    {
      "epoch": 8.959368836291913,
      "grad_norm": 2.533273696899414,
      "learning_rate": 3.893862266690071e-05,
      "loss": 0.0173,
      "step": 5680
    },
    {
      "epoch": 8.975147928994083,
      "grad_norm": 0.14649423956871033,
      "learning_rate": 3.8909367503364345e-05,
      "loss": 0.0042,
      "step": 5690
    },
    {
      "epoch": 8.990927021696253,
      "grad_norm": 0.004378902725875378,
      "learning_rate": 3.888011233982798e-05,
      "loss": 0.0093,
      "step": 5700
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.8758772451528488,
      "eval_loss": 0.7530884742736816,
      "eval_runtime": 208.2249,
      "eval_samples_per_second": 80.749,
      "eval_steps_per_second": 5.047,
      "step": 5706
    },
    {
      "epoch": 9.006311637080868,
      "grad_norm": 0.005916853900998831,
      "learning_rate": 3.885085717629162e-05,
      "loss": 0.0016,
      "step": 5710
    },
    {
      "epoch": 9.022090729783038,
      "grad_norm": 0.021072793751955032,
      "learning_rate": 3.882160201275525e-05,
      "loss": 0.0013,
      "step": 5720
    },
    {
      "epoch": 9.037869822485208,
      "grad_norm": 0.039118800312280655,
      "learning_rate": 3.879234684921889e-05,
      "loss": 0.0026,
      "step": 5730
    },
    {
      "epoch": 9.053648915187377,
      "grad_norm": 6.679838180541992,
      "learning_rate": 3.8763091685682526e-05,
      "loss": 0.0113,
      "step": 5740
    },
    {
      "epoch": 9.069428007889547,
      "grad_norm": 0.11491631716489792,
      "learning_rate": 3.873383652214616e-05,
      "loss": 0.0148,
      "step": 5750
    },
    {
      "epoch": 9.085207100591717,
      "grad_norm": 0.1352979987859726,
      "learning_rate": 3.87045813586098e-05,
      "loss": 0.018,
      "step": 5760
    },
    {
      "epoch": 9.100986193293886,
      "grad_norm": 0.00987763237208128,
      "learning_rate": 3.867532619507343e-05,
      "loss": 0.0122,
      "step": 5770
    },
    {
      "epoch": 9.116765285996054,
      "grad_norm": 0.00749758118763566,
      "learning_rate": 3.8646071031537066e-05,
      "loss": 0.0015,
      "step": 5780
    },
    {
      "epoch": 9.132544378698224,
      "grad_norm": 0.0083521893247962,
      "learning_rate": 3.8616815868000706e-05,
      "loss": 0.0031,
      "step": 5790
    },
    {
      "epoch": 9.148323471400394,
      "grad_norm": 0.005279863718897104,
      "learning_rate": 3.858756070446434e-05,
      "loss": 0.0024,
      "step": 5800
    },
    {
      "epoch": 9.164102564102564,
      "grad_norm": 0.04319406673312187,
      "learning_rate": 3.855830554092797e-05,
      "loss": 0.0042,
      "step": 5810
    },
    {
      "epoch": 9.179881656804733,
      "grad_norm": 0.0065187751315534115,
      "learning_rate": 3.852905037739161e-05,
      "loss": 0.0013,
      "step": 5820
    },
    {
      "epoch": 9.195660749506903,
      "grad_norm": 0.06779365986585617,
      "learning_rate": 3.849979521385525e-05,
      "loss": 0.0149,
      "step": 5830
    },
    {
      "epoch": 9.211439842209073,
      "grad_norm": 1.6064021587371826,
      "learning_rate": 3.847054005031888e-05,
      "loss": 0.0019,
      "step": 5840
    },
    {
      "epoch": 9.227218934911242,
      "grad_norm": 0.0046832142397761345,
      "learning_rate": 3.844128488678252e-05,
      "loss": 0.0088,
      "step": 5850
    },
    {
      "epoch": 9.242998027613412,
      "grad_norm": 0.004138465970754623,
      "learning_rate": 3.841202972324616e-05,
      "loss": 0.0021,
      "step": 5860
    },
    {
      "epoch": 9.258777120315582,
      "grad_norm": 1.0880999565124512,
      "learning_rate": 3.8382774559709787e-05,
      "loss": 0.0018,
      "step": 5870
    },
    {
      "epoch": 9.274556213017751,
      "grad_norm": 0.013150051236152649,
      "learning_rate": 3.835351939617343e-05,
      "loss": 0.0005,
      "step": 5880
    },
    {
      "epoch": 9.290335305719921,
      "grad_norm": 0.002942306688055396,
      "learning_rate": 3.832426423263707e-05,
      "loss": 0.0016,
      "step": 5890
    },
    {
      "epoch": 9.30611439842209,
      "grad_norm": 3.0968568325042725,
      "learning_rate": 3.8295009069100693e-05,
      "loss": 0.0154,
      "step": 5900
    },
    {
      "epoch": 9.32189349112426,
      "grad_norm": 0.01844387874007225,
      "learning_rate": 3.8265753905564334e-05,
      "loss": 0.0214,
      "step": 5910
    },
    {
      "epoch": 9.33767258382643,
      "grad_norm": 0.3377164602279663,
      "learning_rate": 3.8236498742027974e-05,
      "loss": 0.0103,
      "step": 5920
    },
    {
      "epoch": 9.3534516765286,
      "grad_norm": 0.007159894332289696,
      "learning_rate": 3.820724357849161e-05,
      "loss": 0.0259,
      "step": 5930
    },
    {
      "epoch": 9.36923076923077,
      "grad_norm": 0.21092508733272552,
      "learning_rate": 3.817798841495524e-05,
      "loss": 0.0015,
      "step": 5940
    },
    {
      "epoch": 9.38500986193294,
      "grad_norm": 0.006304092705249786,
      "learning_rate": 3.814873325141888e-05,
      "loss": 0.0058,
      "step": 5950
    },
    {
      "epoch": 9.400788954635109,
      "grad_norm": 0.006464854348450899,
      "learning_rate": 3.8119478087882514e-05,
      "loss": 0.0044,
      "step": 5960
    },
    {
      "epoch": 9.416568047337279,
      "grad_norm": 0.6198660135269165,
      "learning_rate": 3.809022292434615e-05,
      "loss": 0.0128,
      "step": 5970
    },
    {
      "epoch": 9.432347140039449,
      "grad_norm": 0.007425724528729916,
      "learning_rate": 3.806096776080979e-05,
      "loss": 0.0177,
      "step": 5980
    },
    {
      "epoch": 9.448126232741618,
      "grad_norm": 0.07512633502483368,
      "learning_rate": 3.803171259727342e-05,
      "loss": 0.0034,
      "step": 5990
    },
    {
      "epoch": 9.463905325443786,
      "grad_norm": 0.008403393439948559,
      "learning_rate": 3.8002457433737054e-05,
      "loss": 0.0017,
      "step": 6000
    },
    {
      "epoch": 9.479684418145956,
      "grad_norm": 0.004091449547559023,
      "learning_rate": 3.7973202270200694e-05,
      "loss": 0.0054,
      "step": 6010
    },
    {
      "epoch": 9.495463510848126,
      "grad_norm": 0.002690128982067108,
      "learning_rate": 3.794394710666433e-05,
      "loss": 0.0025,
      "step": 6020
    },
    {
      "epoch": 9.511242603550295,
      "grad_norm": 0.036567069590091705,
      "learning_rate": 3.791469194312796e-05,
      "loss": 0.02,
      "step": 6030
    },
    {
      "epoch": 9.527021696252465,
      "grad_norm": 0.27219802141189575,
      "learning_rate": 3.78854367795916e-05,
      "loss": 0.0126,
      "step": 6040
    },
    {
      "epoch": 9.542800788954635,
      "grad_norm": 0.9714859127998352,
      "learning_rate": 3.7856181616055235e-05,
      "loss": 0.0049,
      "step": 6050
    },
    {
      "epoch": 9.558579881656804,
      "grad_norm": 0.9037764668464661,
      "learning_rate": 3.7826926452518875e-05,
      "loss": 0.0165,
      "step": 6060
    },
    {
      "epoch": 9.574358974358974,
      "grad_norm": 0.06554041802883148,
      "learning_rate": 3.779767128898251e-05,
      "loss": 0.0089,
      "step": 6070
    },
    {
      "epoch": 9.590138067061144,
      "grad_norm": 0.42647889256477356,
      "learning_rate": 3.776841612544614e-05,
      "loss": 0.0096,
      "step": 6080
    },
    {
      "epoch": 9.605917159763314,
      "grad_norm": 0.003569460939615965,
      "learning_rate": 3.773916096190978e-05,
      "loss": 0.0006,
      "step": 6090
    },
    {
      "epoch": 9.621696252465483,
      "grad_norm": 0.006328101735562086,
      "learning_rate": 3.7709905798373415e-05,
      "loss": 0.0089,
      "step": 6100
    },
    {
      "epoch": 9.637475345167653,
      "grad_norm": 2.632406234741211,
      "learning_rate": 3.768065063483705e-05,
      "loss": 0.0066,
      "step": 6110
    },
    {
      "epoch": 9.653254437869823,
      "grad_norm": 0.009582201950252056,
      "learning_rate": 3.765139547130069e-05,
      "loss": 0.0168,
      "step": 6120
    },
    {
      "epoch": 9.669033530571992,
      "grad_norm": 0.003536190139129758,
      "learning_rate": 3.762214030776432e-05,
      "loss": 0.004,
      "step": 6130
    },
    {
      "epoch": 9.684812623274162,
      "grad_norm": 0.004294687416404486,
      "learning_rate": 3.7592885144227955e-05,
      "loss": 0.0137,
      "step": 6140
    },
    {
      "epoch": 9.700591715976332,
      "grad_norm": 0.00443200021982193,
      "learning_rate": 3.7563629980691595e-05,
      "loss": 0.0179,
      "step": 6150
    },
    {
      "epoch": 9.716370808678501,
      "grad_norm": 0.14473439753055573,
      "learning_rate": 3.7534374817155235e-05,
      "loss": 0.0034,
      "step": 6160
    },
    {
      "epoch": 9.732149901380671,
      "grad_norm": 0.03581729158759117,
      "learning_rate": 3.750511965361886e-05,
      "loss": 0.0027,
      "step": 6170
    },
    {
      "epoch": 9.74792899408284,
      "grad_norm": 0.004060373641550541,
      "learning_rate": 3.74758644900825e-05,
      "loss": 0.0015,
      "step": 6180
    },
    {
      "epoch": 9.76370808678501,
      "grad_norm": 0.022209281101822853,
      "learning_rate": 3.744660932654614e-05,
      "loss": 0.0101,
      "step": 6190
    },
    {
      "epoch": 9.77948717948718,
      "grad_norm": 0.6666377186775208,
      "learning_rate": 3.741735416300977e-05,
      "loss": 0.0152,
      "step": 6200
    },
    {
      "epoch": 9.795266272189348,
      "grad_norm": 4.416590690612793,
      "learning_rate": 3.738809899947341e-05,
      "loss": 0.0178,
      "step": 6210
    },
    {
      "epoch": 9.811045364891518,
      "grad_norm": 0.03529088571667671,
      "learning_rate": 3.735884383593705e-05,
      "loss": 0.0072,
      "step": 6220
    },
    {
      "epoch": 9.826824457593688,
      "grad_norm": 0.012240342795848846,
      "learning_rate": 3.7329588672400676e-05,
      "loss": 0.0085,
      "step": 6230
    },
    {
      "epoch": 9.842603550295857,
      "grad_norm": 0.0052537876181304455,
      "learning_rate": 3.7300333508864316e-05,
      "loss": 0.0011,
      "step": 6240
    },
    {
      "epoch": 9.858382642998027,
      "grad_norm": 0.08233480900526047,
      "learning_rate": 3.7271078345327956e-05,
      "loss": 0.0203,
      "step": 6250
    },
    {
      "epoch": 9.874161735700197,
      "grad_norm": 0.016483929008245468,
      "learning_rate": 3.724182318179158e-05,
      "loss": 0.0026,
      "step": 6260
    },
    {
      "epoch": 9.889940828402366,
      "grad_norm": 0.04226939007639885,
      "learning_rate": 3.721256801825522e-05,
      "loss": 0.0063,
      "step": 6270
    },
    {
      "epoch": 9.905719921104536,
      "grad_norm": 0.007156239356845617,
      "learning_rate": 3.718331285471886e-05,
      "loss": 0.0074,
      "step": 6280
    },
    {
      "epoch": 9.921499013806706,
      "grad_norm": 0.19918853044509888,
      "learning_rate": 3.7154057691182496e-05,
      "loss": 0.0086,
      "step": 6290
    },
    {
      "epoch": 9.937278106508876,
      "grad_norm": 0.20286522805690765,
      "learning_rate": 3.712480252764613e-05,
      "loss": 0.0057,
      "step": 6300
    },
    {
      "epoch": 9.953057199211045,
      "grad_norm": 0.39861857891082764,
      "learning_rate": 3.709554736410977e-05,
      "loss": 0.0037,
      "step": 6310
    },
    {
      "epoch": 9.968836291913215,
      "grad_norm": 2.1834359169006348,
      "learning_rate": 3.70662922005734e-05,
      "loss": 0.0048,
      "step": 6320
    },
    {
      "epoch": 9.984615384615385,
      "grad_norm": 0.006710244808346033,
      "learning_rate": 3.7037037037037037e-05,
      "loss": 0.0006,
      "step": 6330
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.003261385951191187,
      "learning_rate": 3.700778187350068e-05,
      "loss": 0.0075,
      "step": 6340
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.8680861187105983,
      "eval_loss": 0.7149141430854797,
      "eval_runtime": 205.0436,
      "eval_samples_per_second": 82.002,
      "eval_steps_per_second": 5.126,
      "step": 6340
    },
    {
      "epoch": 10.01577909270217,
      "grad_norm": 0.010176112875342369,
      "learning_rate": 3.697852670996431e-05,
      "loss": 0.006,
      "step": 6350
    },
    {
      "epoch": 10.03155818540434,
      "grad_norm": 3.153332233428955,
      "learning_rate": 3.6949271546427943e-05,
      "loss": 0.0204,
      "step": 6360
    },
    {
      "epoch": 10.04733727810651,
      "grad_norm": 0.003246577922254801,
      "learning_rate": 3.6920016382891584e-05,
      "loss": 0.0007,
      "step": 6370
    },
    {
      "epoch": 10.063116370808679,
      "grad_norm": 0.042737334966659546,
      "learning_rate": 3.689076121935522e-05,
      "loss": 0.0039,
      "step": 6380
    },
    {
      "epoch": 10.078895463510849,
      "grad_norm": 1.9515069723129272,
      "learning_rate": 3.686150605581886e-05,
      "loss": 0.0079,
      "step": 6390
    },
    {
      "epoch": 10.094674556213018,
      "grad_norm": 4.698327541351318,
      "learning_rate": 3.683225089228249e-05,
      "loss": 0.0088,
      "step": 6400
    },
    {
      "epoch": 10.110453648915188,
      "grad_norm": 0.005055584013462067,
      "learning_rate": 3.6802995728746124e-05,
      "loss": 0.0109,
      "step": 6410
    },
    {
      "epoch": 10.126232741617358,
      "grad_norm": 1.3564282655715942,
      "learning_rate": 3.6773740565209764e-05,
      "loss": 0.0119,
      "step": 6420
    },
    {
      "epoch": 10.142011834319527,
      "grad_norm": 0.05171532556414604,
      "learning_rate": 3.67444854016734e-05,
      "loss": 0.0084,
      "step": 6430
    },
    {
      "epoch": 10.157790927021697,
      "grad_norm": 0.09873621165752411,
      "learning_rate": 3.671523023813703e-05,
      "loss": 0.0075,
      "step": 6440
    },
    {
      "epoch": 10.173570019723865,
      "grad_norm": 0.03782635182142258,
      "learning_rate": 3.668597507460067e-05,
      "loss": 0.0171,
      "step": 6450
    },
    {
      "epoch": 10.189349112426035,
      "grad_norm": 0.006517843808978796,
      "learning_rate": 3.6656719911064304e-05,
      "loss": 0.0054,
      "step": 6460
    },
    {
      "epoch": 10.205128205128204,
      "grad_norm": 0.10342228412628174,
      "learning_rate": 3.662746474752794e-05,
      "loss": 0.0008,
      "step": 6470
    },
    {
      "epoch": 10.220907297830374,
      "grad_norm": 0.0028630592860281467,
      "learning_rate": 3.659820958399158e-05,
      "loss": 0.0045,
      "step": 6480
    },
    {
      "epoch": 10.236686390532544,
      "grad_norm": 0.011443831957876682,
      "learning_rate": 3.656895442045522e-05,
      "loss": 0.0113,
      "step": 6490
    },
    {
      "epoch": 10.252465483234714,
      "grad_norm": 0.004889855161309242,
      "learning_rate": 3.6539699256918844e-05,
      "loss": 0.0128,
      "step": 6500
    },
    {
      "epoch": 10.268244575936883,
      "grad_norm": 0.020393412560224533,
      "learning_rate": 3.6510444093382485e-05,
      "loss": 0.0038,
      "step": 6510
    },
    {
      "epoch": 10.284023668639053,
      "grad_norm": 0.004539862275123596,
      "learning_rate": 3.6481188929846125e-05,
      "loss": 0.0165,
      "step": 6520
    },
    {
      "epoch": 10.299802761341223,
      "grad_norm": 0.22719581425189972,
      "learning_rate": 3.645193376630975e-05,
      "loss": 0.0043,
      "step": 6530
    },
    {
      "epoch": 10.315581854043392,
      "grad_norm": 0.06031925603747368,
      "learning_rate": 3.642267860277339e-05,
      "loss": 0.0268,
      "step": 6540
    },
    {
      "epoch": 10.331360946745562,
      "grad_norm": 0.0028031549882143736,
      "learning_rate": 3.639342343923703e-05,
      "loss": 0.0007,
      "step": 6550
    },
    {
      "epoch": 10.347140039447732,
      "grad_norm": 0.0326673723757267,
      "learning_rate": 3.636416827570066e-05,
      "loss": 0.0065,
      "step": 6560
    },
    {
      "epoch": 10.362919132149901,
      "grad_norm": 0.026158032938838005,
      "learning_rate": 3.63349131121643e-05,
      "loss": 0.0253,
      "step": 6570
    },
    {
      "epoch": 10.378698224852071,
      "grad_norm": 3.481098175048828,
      "learning_rate": 3.630565794862794e-05,
      "loss": 0.0285,
      "step": 6580
    },
    {
      "epoch": 10.39447731755424,
      "grad_norm": 0.20031818747520447,
      "learning_rate": 3.6276402785091565e-05,
      "loss": 0.0113,
      "step": 6590
    },
    {
      "epoch": 10.41025641025641,
      "grad_norm": 0.005647371057420969,
      "learning_rate": 3.6247147621555205e-05,
      "loss": 0.0049,
      "step": 6600
    },
    {
      "epoch": 10.42603550295858,
      "grad_norm": 0.004614153411239386,
      "learning_rate": 3.6217892458018845e-05,
      "loss": 0.0015,
      "step": 6610
    },
    {
      "epoch": 10.44181459566075,
      "grad_norm": 0.181566521525383,
      "learning_rate": 3.618863729448248e-05,
      "loss": 0.0175,
      "step": 6620
    },
    {
      "epoch": 10.45759368836292,
      "grad_norm": 0.14890387654304504,
      "learning_rate": 3.615938213094611e-05,
      "loss": 0.0159,
      "step": 6630
    },
    {
      "epoch": 10.47337278106509,
      "grad_norm": 0.004795723129063845,
      "learning_rate": 3.613012696740975e-05,
      "loss": 0.0013,
      "step": 6640
    },
    {
      "epoch": 10.489151873767259,
      "grad_norm": 0.13759130239486694,
      "learning_rate": 3.6100871803873386e-05,
      "loss": 0.0136,
      "step": 6650
    },
    {
      "epoch": 10.504930966469429,
      "grad_norm": 1.4313961267471313,
      "learning_rate": 3.607161664033702e-05,
      "loss": 0.0027,
      "step": 6660
    },
    {
      "epoch": 10.520710059171599,
      "grad_norm": 0.021877268329262733,
      "learning_rate": 3.604236147680066e-05,
      "loss": 0.0037,
      "step": 6670
    },
    {
      "epoch": 10.536489151873766,
      "grad_norm": 0.004463514778763056,
      "learning_rate": 3.601310631326429e-05,
      "loss": 0.009,
      "step": 6680
    },
    {
      "epoch": 10.552268244575936,
      "grad_norm": 0.2395109087228775,
      "learning_rate": 3.5983851149727926e-05,
      "loss": 0.0067,
      "step": 6690
    },
    {
      "epoch": 10.568047337278106,
      "grad_norm": 0.0020557779353111982,
      "learning_rate": 3.5954595986191566e-05,
      "loss": 0.008,
      "step": 6700
    },
    {
      "epoch": 10.583826429980276,
      "grad_norm": 0.30593141913414,
      "learning_rate": 3.59253408226552e-05,
      "loss": 0.0035,
      "step": 6710
    },
    {
      "epoch": 10.599605522682445,
      "grad_norm": 0.9717624187469482,
      "learning_rate": 3.589608565911884e-05,
      "loss": 0.0029,
      "step": 6720
    },
    {
      "epoch": 10.615384615384615,
      "grad_norm": 0.021186983212828636,
      "learning_rate": 3.586683049558247e-05,
      "loss": 0.0325,
      "step": 6730
    },
    {
      "epoch": 10.631163708086785,
      "grad_norm": 0.06437218189239502,
      "learning_rate": 3.5837575332046106e-05,
      "loss": 0.0101,
      "step": 6740
    },
    {
      "epoch": 10.646942800788954,
      "grad_norm": 0.011791453696787357,
      "learning_rate": 3.5808320168509746e-05,
      "loss": 0.0018,
      "step": 6750
    },
    {
      "epoch": 10.662721893491124,
      "grad_norm": 0.006758581381291151,
      "learning_rate": 3.577906500497338e-05,
      "loss": 0.0005,
      "step": 6760
    },
    {
      "epoch": 10.678500986193294,
      "grad_norm": 1.1863493919372559,
      "learning_rate": 3.574980984143701e-05,
      "loss": 0.0114,
      "step": 6770
    },
    {
      "epoch": 10.694280078895464,
      "grad_norm": 0.002779704052954912,
      "learning_rate": 3.572055467790065e-05,
      "loss": 0.0011,
      "step": 6780
    },
    {
      "epoch": 10.710059171597633,
      "grad_norm": 0.07955115288496017,
      "learning_rate": 3.5691299514364287e-05,
      "loss": 0.0306,
      "step": 6790
    },
    {
      "epoch": 10.725838264299803,
      "grad_norm": 0.3212168216705322,
      "learning_rate": 3.566204435082792e-05,
      "loss": 0.0324,
      "step": 6800
    },
    {
      "epoch": 10.741617357001973,
      "grad_norm": 1.1184675693511963,
      "learning_rate": 3.563278918729156e-05,
      "loss": 0.0106,
      "step": 6810
    },
    {
      "epoch": 10.757396449704142,
      "grad_norm": 0.3616137206554413,
      "learning_rate": 3.5603534023755193e-05,
      "loss": 0.0049,
      "step": 6820
    },
    {
      "epoch": 10.773175542406312,
      "grad_norm": 0.005026955623179674,
      "learning_rate": 3.557427886021883e-05,
      "loss": 0.0015,
      "step": 6830
    },
    {
      "epoch": 10.788954635108482,
      "grad_norm": 0.010283492505550385,
      "learning_rate": 3.554502369668247e-05,
      "loss": 0.002,
      "step": 6840
    },
    {
      "epoch": 10.804733727810651,
      "grad_norm": 0.018166039139032364,
      "learning_rate": 3.551576853314611e-05,
      "loss": 0.0043,
      "step": 6850
    },
    {
      "epoch": 10.820512820512821,
      "grad_norm": 0.031408291310071945,
      "learning_rate": 3.5486513369609734e-05,
      "loss": 0.0054,
      "step": 6860
    },
    {
      "epoch": 10.83629191321499,
      "grad_norm": 0.0021824976429343224,
      "learning_rate": 3.5457258206073374e-05,
      "loss": 0.0011,
      "step": 6870
    },
    {
      "epoch": 10.85207100591716,
      "grad_norm": 1.3000355958938599,
      "learning_rate": 3.5428003042537014e-05,
      "loss": 0.0115,
      "step": 6880
    },
    {
      "epoch": 10.867850098619328,
      "grad_norm": 0.006909544579684734,
      "learning_rate": 3.539874787900064e-05,
      "loss": 0.0102,
      "step": 6890
    },
    {
      "epoch": 10.883629191321498,
      "grad_norm": 0.024060960859060287,
      "learning_rate": 3.536949271546428e-05,
      "loss": 0.0036,
      "step": 6900
    },
    {
      "epoch": 10.899408284023668,
      "grad_norm": 1.4993252754211426,
      "learning_rate": 3.534023755192792e-05,
      "loss": 0.006,
      "step": 6910
    },
    {
      "epoch": 10.915187376725838,
      "grad_norm": 0.03653604909777641,
      "learning_rate": 3.531098238839155e-05,
      "loss": 0.0066,
      "step": 6920
    },
    {
      "epoch": 10.930966469428007,
      "grad_norm": 0.050362829118967056,
      "learning_rate": 3.528172722485519e-05,
      "loss": 0.0129,
      "step": 6930
    },
    {
      "epoch": 10.946745562130177,
      "grad_norm": 0.004509767051786184,
      "learning_rate": 3.525247206131883e-05,
      "loss": 0.0047,
      "step": 6940
    },
    {
      "epoch": 10.962524654832347,
      "grad_norm": 0.0029438657220453024,
      "learning_rate": 3.522321689778246e-05,
      "loss": 0.0048,
      "step": 6950
    },
    {
      "epoch": 10.978303747534516,
      "grad_norm": 0.0683722123503685,
      "learning_rate": 3.5193961734246094e-05,
      "loss": 0.0032,
      "step": 6960
    },
    {
      "epoch": 10.994082840236686,
      "grad_norm": 0.0035023908130824566,
      "learning_rate": 3.5164706570709735e-05,
      "loss": 0.002,
      "step": 6970
    },
    {
      "epoch": 11.0,
      "eval_accuracy": 0.8740930177233258,
      "eval_loss": 0.7714536190032959,
      "eval_runtime": 204.4726,
      "eval_samples_per_second": 82.231,
      "eval_steps_per_second": 5.14,
      "step": 6974
    },
    {
      "epoch": 11.009467455621301,
      "grad_norm": 0.0030651057604700327,
      "learning_rate": 3.513545140717337e-05,
      "loss": 0.0029,
      "step": 6980
    },
    {
      "epoch": 11.025246548323471,
      "grad_norm": 0.014527629129588604,
      "learning_rate": 3.5106196243637e-05,
      "loss": 0.0003,
      "step": 6990
    },
    {
      "epoch": 11.04102564102564,
      "grad_norm": 0.002551061101257801,
      "learning_rate": 3.507694108010064e-05,
      "loss": 0.0005,
      "step": 7000
    },
    {
      "epoch": 11.05680473372781,
      "grad_norm": 0.003355985041707754,
      "learning_rate": 3.5047685916564275e-05,
      "loss": 0.0012,
      "step": 7010
    },
    {
      "epoch": 11.07258382642998,
      "grad_norm": 0.003181581385433674,
      "learning_rate": 3.501843075302791e-05,
      "loss": 0.0005,
      "step": 7020
    },
    {
      "epoch": 11.08836291913215,
      "grad_norm": 0.017274050042033195,
      "learning_rate": 3.498917558949155e-05,
      "loss": 0.0017,
      "step": 7030
    },
    {
      "epoch": 11.10414201183432,
      "grad_norm": 0.0037028833758085966,
      "learning_rate": 3.495992042595518e-05,
      "loss": 0.0083,
      "step": 7040
    },
    {
      "epoch": 11.11992110453649,
      "grad_norm": 1.127634882926941,
      "learning_rate": 3.493066526241882e-05,
      "loss": 0.0056,
      "step": 7050
    },
    {
      "epoch": 11.13570019723866,
      "grad_norm": 0.005533966235816479,
      "learning_rate": 3.4901410098882455e-05,
      "loss": 0.0014,
      "step": 7060
    },
    {
      "epoch": 11.151479289940829,
      "grad_norm": 0.006593254394829273,
      "learning_rate": 3.487215493534609e-05,
      "loss": 0.0026,
      "step": 7070
    },
    {
      "epoch": 11.167258382642999,
      "grad_norm": 1.0645196437835693,
      "learning_rate": 3.484289977180973e-05,
      "loss": 0.0016,
      "step": 7080
    },
    {
      "epoch": 11.183037475345168,
      "grad_norm": 0.0034077083691954613,
      "learning_rate": 3.481364460827336e-05,
      "loss": 0.0004,
      "step": 7090
    },
    {
      "epoch": 11.198816568047338,
      "grad_norm": 0.053082965314388275,
      "learning_rate": 3.4784389444736995e-05,
      "loss": 0.0018,
      "step": 7100
    },
    {
      "epoch": 11.214595660749508,
      "grad_norm": 0.004420530516654253,
      "learning_rate": 3.4755134281200636e-05,
      "loss": 0.002,
      "step": 7110
    },
    {
      "epoch": 11.230374753451677,
      "grad_norm": 0.0029928318690508604,
      "learning_rate": 3.472587911766427e-05,
      "loss": 0.0146,
      "step": 7120
    },
    {
      "epoch": 11.246153846153845,
      "grad_norm": 0.005136427003890276,
      "learning_rate": 3.46966239541279e-05,
      "loss": 0.0005,
      "step": 7130
    },
    {
      "epoch": 11.261932938856015,
      "grad_norm": 0.47067663073539734,
      "learning_rate": 3.466736879059154e-05,
      "loss": 0.0031,
      "step": 7140
    },
    {
      "epoch": 11.277712031558185,
      "grad_norm": 0.03393568843603134,
      "learning_rate": 3.4638113627055176e-05,
      "loss": 0.0042,
      "step": 7150
    },
    {
      "epoch": 11.293491124260354,
      "grad_norm": 0.0034515298902988434,
      "learning_rate": 3.460885846351881e-05,
      "loss": 0.0011,
      "step": 7160
    },
    {
      "epoch": 11.309270216962524,
      "grad_norm": 0.002708927495405078,
      "learning_rate": 3.457960329998245e-05,
      "loss": 0.0015,
      "step": 7170
    },
    {
      "epoch": 11.325049309664694,
      "grad_norm": 0.004810943268239498,
      "learning_rate": 3.455034813644609e-05,
      "loss": 0.0007,
      "step": 7180
    },
    {
      "epoch": 11.340828402366864,
      "grad_norm": 0.015695294365286827,
      "learning_rate": 3.4521092972909716e-05,
      "loss": 0.0021,
      "step": 7190
    },
    {
      "epoch": 11.356607495069033,
      "grad_norm": 4.7105536460876465,
      "learning_rate": 3.4491837809373356e-05,
      "loss": 0.0214,
      "step": 7200
    },
    {
      "epoch": 11.372386587771203,
      "grad_norm": 0.016631705686450005,
      "learning_rate": 3.4462582645836996e-05,
      "loss": 0.0003,
      "step": 7210
    },
    {
      "epoch": 11.388165680473373,
      "grad_norm": 0.002824316034093499,
      "learning_rate": 3.443332748230062e-05,
      "loss": 0.0131,
      "step": 7220
    },
    {
      "epoch": 11.403944773175542,
      "grad_norm": 0.01344096940010786,
      "learning_rate": 3.440407231876426e-05,
      "loss": 0.0004,
      "step": 7230
    },
    {
      "epoch": 11.419723865877712,
      "grad_norm": 0.45031148195266724,
      "learning_rate": 3.43748171552279e-05,
      "loss": 0.0027,
      "step": 7240
    },
    {
      "epoch": 11.435502958579882,
      "grad_norm": 0.14628443121910095,
      "learning_rate": 3.434556199169153e-05,
      "loss": 0.011,
      "step": 7250
    },
    {
      "epoch": 11.451282051282051,
      "grad_norm": 0.0052710226736962795,
      "learning_rate": 3.431630682815517e-05,
      "loss": 0.0009,
      "step": 7260
    },
    {
      "epoch": 11.467061143984221,
      "grad_norm": 0.33104100823402405,
      "learning_rate": 3.428705166461881e-05,
      "loss": 0.004,
      "step": 7270
    },
    {
      "epoch": 11.48284023668639,
      "grad_norm": 0.002339364495128393,
      "learning_rate": 3.425779650108244e-05,
      "loss": 0.0004,
      "step": 7280
    },
    {
      "epoch": 11.49861932938856,
      "grad_norm": 0.0025768703781068325,
      "learning_rate": 3.422854133754608e-05,
      "loss": 0.0045,
      "step": 7290
    },
    {
      "epoch": 11.51439842209073,
      "grad_norm": 0.006809414830058813,
      "learning_rate": 3.419928617400972e-05,
      "loss": 0.0039,
      "step": 7300
    },
    {
      "epoch": 11.5301775147929,
      "grad_norm": 0.9007859826087952,
      "learning_rate": 3.417003101047335e-05,
      "loss": 0.0046,
      "step": 7310
    },
    {
      "epoch": 11.54595660749507,
      "grad_norm": 0.003017021808773279,
      "learning_rate": 3.4140775846936984e-05,
      "loss": 0.0003,
      "step": 7320
    },
    {
      "epoch": 11.56173570019724,
      "grad_norm": 0.3955838084220886,
      "learning_rate": 3.4111520683400624e-05,
      "loss": 0.0027,
      "step": 7330
    },
    {
      "epoch": 11.577514792899409,
      "grad_norm": 0.0016189623856917024,
      "learning_rate": 3.408226551986426e-05,
      "loss": 0.0003,
      "step": 7340
    },
    {
      "epoch": 11.593293885601579,
      "grad_norm": 0.004231889732182026,
      "learning_rate": 3.405301035632789e-05,
      "loss": 0.001,
      "step": 7350
    },
    {
      "epoch": 11.609072978303747,
      "grad_norm": 0.0017022951506078243,
      "learning_rate": 3.402375519279153e-05,
      "loss": 0.0004,
      "step": 7360
    },
    {
      "epoch": 11.624852071005916,
      "grad_norm": 0.003551754169166088,
      "learning_rate": 3.3994500029255164e-05,
      "loss": 0.0003,
      "step": 7370
    },
    {
      "epoch": 11.640631163708086,
      "grad_norm": 0.0014546236488968134,
      "learning_rate": 3.39652448657188e-05,
      "loss": 0.0004,
      "step": 7380
    },
    {
      "epoch": 11.656410256410256,
      "grad_norm": 0.0019238798413425684,
      "learning_rate": 3.393598970218244e-05,
      "loss": 0.0031,
      "step": 7390
    },
    {
      "epoch": 11.672189349112426,
      "grad_norm": 0.13240613043308258,
      "learning_rate": 3.390673453864607e-05,
      "loss": 0.0008,
      "step": 7400
    },
    {
      "epoch": 11.687968441814595,
      "grad_norm": 0.052029360085725784,
      "learning_rate": 3.387747937510971e-05,
      "loss": 0.0018,
      "step": 7410
    },
    {
      "epoch": 11.703747534516765,
      "grad_norm": 0.010411282069981098,
      "learning_rate": 3.3848224211573344e-05,
      "loss": 0.0003,
      "step": 7420
    },
    {
      "epoch": 11.719526627218935,
      "grad_norm": 0.0025558550842106342,
      "learning_rate": 3.381896904803698e-05,
      "loss": 0.0025,
      "step": 7430
    },
    {
      "epoch": 11.735305719921104,
      "grad_norm": 0.0019122197991237044,
      "learning_rate": 3.378971388450062e-05,
      "loss": 0.0096,
      "step": 7440
    },
    {
      "epoch": 11.751084812623274,
      "grad_norm": 5.553097248077393,
      "learning_rate": 3.376045872096425e-05,
      "loss": 0.0073,
      "step": 7450
    },
    {
      "epoch": 11.766863905325444,
      "grad_norm": 0.2399047166109085,
      "learning_rate": 3.3731203557427885e-05,
      "loss": 0.012,
      "step": 7460
    },
    {
      "epoch": 11.782642998027614,
      "grad_norm": 0.002845387440174818,
      "learning_rate": 3.3701948393891525e-05,
      "loss": 0.0006,
      "step": 7470
    },
    {
      "epoch": 11.798422090729783,
      "grad_norm": 0.044481582939624786,
      "learning_rate": 3.367269323035516e-05,
      "loss": 0.0004,
      "step": 7480
    },
    {
      "epoch": 11.814201183431953,
      "grad_norm": 1.11445152759552,
      "learning_rate": 3.364343806681879e-05,
      "loss": 0.0157,
      "step": 7490
    },
    {
      "epoch": 11.829980276134123,
      "grad_norm": 0.0021984297782182693,
      "learning_rate": 3.361418290328243e-05,
      "loss": 0.0149,
      "step": 7500
    },
    {
      "epoch": 11.845759368836292,
      "grad_norm": 0.00275429873727262,
      "learning_rate": 3.358492773974607e-05,
      "loss": 0.0029,
      "step": 7510
    },
    {
      "epoch": 11.861538461538462,
      "grad_norm": 0.012568310834467411,
      "learning_rate": 3.35556725762097e-05,
      "loss": 0.0123,
      "step": 7520
    },
    {
      "epoch": 11.877317554240632,
      "grad_norm": 0.006048243958503008,
      "learning_rate": 3.352641741267334e-05,
      "loss": 0.0032,
      "step": 7530
    },
    {
      "epoch": 11.893096646942801,
      "grad_norm": 0.06705928593873978,
      "learning_rate": 3.349716224913698e-05,
      "loss": 0.0117,
      "step": 7540
    },
    {
      "epoch": 11.908875739644971,
      "grad_norm": 0.0623910054564476,
      "learning_rate": 3.3467907085600605e-05,
      "loss": 0.0026,
      "step": 7550
    },
    {
      "epoch": 11.92465483234714,
      "grad_norm": 0.0023834197781980038,
      "learning_rate": 3.3438651922064245e-05,
      "loss": 0.0122,
      "step": 7560
    },
    {
      "epoch": 11.940433925049309,
      "grad_norm": 0.011005115695297718,
      "learning_rate": 3.3409396758527885e-05,
      "loss": 0.0017,
      "step": 7570
    },
    {
      "epoch": 11.956213017751478,
      "grad_norm": 0.0067744506523013115,
      "learning_rate": 3.338014159499151e-05,
      "loss": 0.0012,
      "step": 7580
    },
    {
      "epoch": 11.971992110453648,
      "grad_norm": 0.004826152231544256,
      "learning_rate": 3.335088643145515e-05,
      "loss": 0.0042,
      "step": 7590
    },
    {
      "epoch": 11.987771203155818,
      "grad_norm": 0.008455720730125904,
      "learning_rate": 3.332163126791879e-05,
      "loss": 0.0082,
      "step": 7600
    },
    {
      "epoch": 12.0,
      "eval_accuracy": 0.8761746163911026,
      "eval_loss": 0.7562293410301208,
      "eval_runtime": 207.6049,
      "eval_samples_per_second": 80.99,
      "eval_steps_per_second": 5.063,
      "step": 7608
    },
    {
      "epoch": 12.003155818540433,
      "grad_norm": 0.005033101886510849,
      "learning_rate": 3.3292376104382426e-05,
      "loss": 0.0019,
      "step": 7610
    },
    {
      "epoch": 12.018934911242603,
      "grad_norm": 0.41161084175109863,
      "learning_rate": 3.326312094084606e-05,
      "loss": 0.0133,
      "step": 7620
    },
    {
      "epoch": 12.034714003944773,
      "grad_norm": 0.018889974802732468,
      "learning_rate": 3.32338657773097e-05,
      "loss": 0.0054,
      "step": 7630
    },
    {
      "epoch": 12.050493096646942,
      "grad_norm": 0.033701326698064804,
      "learning_rate": 3.320461061377333e-05,
      "loss": 0.0024,
      "step": 7640
    },
    {
      "epoch": 12.066272189349112,
      "grad_norm": 0.0068438914604485035,
      "learning_rate": 3.3175355450236966e-05,
      "loss": 0.0003,
      "step": 7650
    },
    {
      "epoch": 12.082051282051282,
      "grad_norm": 0.4347286522388458,
      "learning_rate": 3.3146100286700606e-05,
      "loss": 0.0096,
      "step": 7660
    },
    {
      "epoch": 12.097830374753451,
      "grad_norm": 0.007393531035631895,
      "learning_rate": 3.311684512316424e-05,
      "loss": 0.0121,
      "step": 7670
    },
    {
      "epoch": 12.113609467455621,
      "grad_norm": 0.32057246565818787,
      "learning_rate": 3.308758995962787e-05,
      "loss": 0.0013,
      "step": 7680
    },
    {
      "epoch": 12.12938856015779,
      "grad_norm": 0.01302232127636671,
      "learning_rate": 3.305833479609151e-05,
      "loss": 0.0135,
      "step": 7690
    },
    {
      "epoch": 12.14516765285996,
      "grad_norm": 0.0034664892591536045,
      "learning_rate": 3.3029079632555146e-05,
      "loss": 0.0008,
      "step": 7700
    },
    {
      "epoch": 12.16094674556213,
      "grad_norm": 0.007907742634415627,
      "learning_rate": 3.299982446901878e-05,
      "loss": 0.0087,
      "step": 7710
    },
    {
      "epoch": 12.1767258382643,
      "grad_norm": 6.286482810974121,
      "learning_rate": 3.297056930548242e-05,
      "loss": 0.01,
      "step": 7720
    },
    {
      "epoch": 12.19250493096647,
      "grad_norm": 0.021112816408276558,
      "learning_rate": 3.294131414194605e-05,
      "loss": 0.0021,
      "step": 7730
    },
    {
      "epoch": 12.20828402366864,
      "grad_norm": 0.011295435018837452,
      "learning_rate": 3.291205897840969e-05,
      "loss": 0.0019,
      "step": 7740
    },
    {
      "epoch": 12.22406311637081,
      "grad_norm": 0.10437161475419998,
      "learning_rate": 3.288280381487333e-05,
      "loss": 0.001,
      "step": 7750
    },
    {
      "epoch": 12.239842209072979,
      "grad_norm": 0.027508558705449104,
      "learning_rate": 3.285354865133696e-05,
      "loss": 0.0004,
      "step": 7760
    },
    {
      "epoch": 12.255621301775149,
      "grad_norm": 0.0032349200919270515,
      "learning_rate": 3.28242934878006e-05,
      "loss": 0.001,
      "step": 7770
    },
    {
      "epoch": 12.271400394477318,
      "grad_norm": 0.4043903946876526,
      "learning_rate": 3.2795038324264234e-05,
      "loss": 0.0047,
      "step": 7780
    },
    {
      "epoch": 12.287179487179488,
      "grad_norm": 0.006378198973834515,
      "learning_rate": 3.276578316072787e-05,
      "loss": 0.0033,
      "step": 7790
    },
    {
      "epoch": 12.302958579881658,
      "grad_norm": 0.7330625057220459,
      "learning_rate": 3.273652799719151e-05,
      "loss": 0.0032,
      "step": 7800
    },
    {
      "epoch": 12.318737672583826,
      "grad_norm": 0.040399182587862015,
      "learning_rate": 3.270727283365514e-05,
      "loss": 0.0228,
      "step": 7810
    },
    {
      "epoch": 12.334516765285995,
      "grad_norm": 1.0677449703216553,
      "learning_rate": 3.2678017670118774e-05,
      "loss": 0.0094,
      "step": 7820
    },
    {
      "epoch": 12.350295857988165,
      "grad_norm": 0.11386439949274063,
      "learning_rate": 3.2648762506582414e-05,
      "loss": 0.0027,
      "step": 7830
    },
    {
      "epoch": 12.366074950690335,
      "grad_norm": 0.7315376400947571,
      "learning_rate": 3.2619507343046054e-05,
      "loss": 0.0113,
      "step": 7840
    },
    {
      "epoch": 12.381854043392504,
      "grad_norm": 0.006228604819625616,
      "learning_rate": 3.259025217950968e-05,
      "loss": 0.0006,
      "step": 7850
    },
    {
      "epoch": 12.397633136094674,
      "grad_norm": 0.02763386256992817,
      "learning_rate": 3.256099701597332e-05,
      "loss": 0.014,
      "step": 7860
    },
    {
      "epoch": 12.413412228796844,
      "grad_norm": 0.002609926974400878,
      "learning_rate": 3.253174185243696e-05,
      "loss": 0.0011,
      "step": 7870
    },
    {
      "epoch": 12.429191321499014,
      "grad_norm": 1.4897663593292236,
      "learning_rate": 3.250248668890059e-05,
      "loss": 0.0125,
      "step": 7880
    },
    {
      "epoch": 12.444970414201183,
      "grad_norm": 0.21925972402095795,
      "learning_rate": 3.247323152536423e-05,
      "loss": 0.0007,
      "step": 7890
    },
    {
      "epoch": 12.460749506903353,
      "grad_norm": 1.451847791671753,
      "learning_rate": 3.244397636182787e-05,
      "loss": 0.003,
      "step": 7900
    },
    {
      "epoch": 12.476528599605523,
      "grad_norm": 0.10682198405265808,
      "learning_rate": 3.2414721198291494e-05,
      "loss": 0.0143,
      "step": 7910
    },
    {
      "epoch": 12.492307692307692,
      "grad_norm": 0.06328678876161575,
      "learning_rate": 3.2385466034755135e-05,
      "loss": 0.0164,
      "step": 7920
    },
    {
      "epoch": 12.508086785009862,
      "grad_norm": 0.012818880379199982,
      "learning_rate": 3.2356210871218775e-05,
      "loss": 0.0021,
      "step": 7930
    },
    {
      "epoch": 12.523865877712032,
      "grad_norm": 0.06876115500926971,
      "learning_rate": 3.232695570768241e-05,
      "loss": 0.0009,
      "step": 7940
    },
    {
      "epoch": 12.539644970414201,
      "grad_norm": 0.020824607461690903,
      "learning_rate": 3.229770054414604e-05,
      "loss": 0.0068,
      "step": 7950
    },
    {
      "epoch": 12.555424063116371,
      "grad_norm": 0.008358901366591454,
      "learning_rate": 3.226844538060968e-05,
      "loss": 0.0005,
      "step": 7960
    },
    {
      "epoch": 12.57120315581854,
      "grad_norm": 0.004957279190421104,
      "learning_rate": 3.2239190217073315e-05,
      "loss": 0.0091,
      "step": 7970
    },
    {
      "epoch": 12.58698224852071,
      "grad_norm": 0.10631416738033295,
      "learning_rate": 3.220993505353695e-05,
      "loss": 0.0014,
      "step": 7980
    },
    {
      "epoch": 12.60276134122288,
      "grad_norm": 0.09562454372644424,
      "learning_rate": 3.218067989000059e-05,
      "loss": 0.0021,
      "step": 7990
    },
    {
      "epoch": 12.61854043392505,
      "grad_norm": 0.0071728527545928955,
      "learning_rate": 3.215142472646422e-05,
      "loss": 0.0005,
      "step": 8000
    },
    {
      "epoch": 12.63431952662722,
      "grad_norm": 0.0026386447716504335,
      "learning_rate": 3.2122169562927855e-05,
      "loss": 0.0133,
      "step": 8010
    },
    {
      "epoch": 12.650098619329388,
      "grad_norm": 0.01795203424990177,
      "learning_rate": 3.2092914399391495e-05,
      "loss": 0.003,
      "step": 8020
    },
    {
      "epoch": 12.665877712031559,
      "grad_norm": 0.02053672820329666,
      "learning_rate": 3.206365923585513e-05,
      "loss": 0.0012,
      "step": 8030
    },
    {
      "epoch": 12.681656804733727,
      "grad_norm": 0.002559560351073742,
      "learning_rate": 3.203440407231876e-05,
      "loss": 0.0012,
      "step": 8040
    },
    {
      "epoch": 12.697435897435897,
      "grad_norm": 0.006524285767227411,
      "learning_rate": 3.20051489087824e-05,
      "loss": 0.0004,
      "step": 8050
    },
    {
      "epoch": 12.713214990138066,
      "grad_norm": 0.0077858008444309235,
      "learning_rate": 3.1975893745246036e-05,
      "loss": 0.0068,
      "step": 8060
    },
    {
      "epoch": 12.728994082840236,
      "grad_norm": 0.02231493964791298,
      "learning_rate": 3.1946638581709676e-05,
      "loss": 0.0005,
      "step": 8070
    },
    {
      "epoch": 12.744773175542406,
      "grad_norm": 0.06506329774856567,
      "learning_rate": 3.191738341817331e-05,
      "loss": 0.0078,
      "step": 8080
    },
    {
      "epoch": 12.760552268244576,
      "grad_norm": 1.1349360942840576,
      "learning_rate": 3.188812825463694e-05,
      "loss": 0.0009,
      "step": 8090
    },
    {
      "epoch": 12.776331360946745,
      "grad_norm": 0.5832395553588867,
      "learning_rate": 3.185887309110058e-05,
      "loss": 0.0017,
      "step": 8100
    },
    {
      "epoch": 12.792110453648915,
      "grad_norm": 0.0017472893232479692,
      "learning_rate": 3.1829617927564216e-05,
      "loss": 0.0079,
      "step": 8110
    },
    {
      "epoch": 12.807889546351085,
      "grad_norm": 0.00506898108869791,
      "learning_rate": 3.180036276402785e-05,
      "loss": 0.0205,
      "step": 8120
    },
    {
      "epoch": 12.823668639053254,
      "grad_norm": 0.01336708851158619,
      "learning_rate": 3.177110760049149e-05,
      "loss": 0.0046,
      "step": 8130
    },
    {
      "epoch": 12.839447731755424,
      "grad_norm": 0.7338680624961853,
      "learning_rate": 3.174185243695512e-05,
      "loss": 0.0012,
      "step": 8140
    },
    {
      "epoch": 12.855226824457594,
      "grad_norm": 0.002208226826041937,
      "learning_rate": 3.1712597273418756e-05,
      "loss": 0.0135,
      "step": 8150
    },
    {
      "epoch": 12.871005917159763,
      "grad_norm": 0.006416019052267075,
      "learning_rate": 3.1683342109882396e-05,
      "loss": 0.0137,
      "step": 8160
    },
    {
      "epoch": 12.886785009861933,
      "grad_norm": 0.17156536877155304,
      "learning_rate": 3.1654086946346036e-05,
      "loss": 0.018,
      "step": 8170
    },
    {
      "epoch": 12.902564102564103,
      "grad_norm": 0.02013886533677578,
      "learning_rate": 3.162483178280966e-05,
      "loss": 0.0017,
      "step": 8180
    },
    {
      "epoch": 12.918343195266273,
      "grad_norm": 0.005943844094872475,
      "learning_rate": 3.15955766192733e-05,
      "loss": 0.0028,
      "step": 8190
    },
    {
      "epoch": 12.934122287968442,
      "grad_norm": 0.008362273685634136,
      "learning_rate": 3.156632145573694e-05,
      "loss": 0.0029,
      "step": 8200
    },
    {
      "epoch": 12.949901380670612,
      "grad_norm": 0.014743898063898087,
      "learning_rate": 3.153706629220058e-05,
      "loss": 0.0116,
      "step": 8210
    },
    {
      "epoch": 12.965680473372782,
      "grad_norm": 0.002414763206616044,
      "learning_rate": 3.150781112866421e-05,
      "loss": 0.001,
      "step": 8220
    },
    {
      "epoch": 12.981459566074951,
      "grad_norm": 0.0028746104799211025,
      "learning_rate": 3.147855596512785e-05,
      "loss": 0.0004,
      "step": 8230
    },
    {
      "epoch": 12.997238658777121,
      "grad_norm": 0.0023185284808278084,
      "learning_rate": 3.1449300801591484e-05,
      "loss": 0.0071,
      "step": 8240
    },
    {
      "epoch": 13.0,
      "eval_accuracy": 0.8756393481622458,
      "eval_loss": 0.805954098701477,
      "eval_runtime": 204.5027,
      "eval_samples_per_second": 82.219,
      "eval_steps_per_second": 5.139,
      "step": 8242
    },
    {
      "epoch": 13.012623274161736,
      "grad_norm": 0.004273651167750359,
      "learning_rate": 3.142004563805512e-05,
      "loss": 0.0094,
      "step": 8250
    },
    {
      "epoch": 13.028402366863906,
      "grad_norm": 0.018465476110577583,
      "learning_rate": 3.139079047451876e-05,
      "loss": 0.0012,
      "step": 8260
    },
    {
      "epoch": 13.044181459566074,
      "grad_norm": 0.0016149483853951097,
      "learning_rate": 3.136153531098239e-05,
      "loss": 0.0087,
      "step": 8270
    },
    {
      "epoch": 13.059960552268244,
      "grad_norm": 0.0016617265064269304,
      "learning_rate": 3.1332280147446024e-05,
      "loss": 0.0007,
      "step": 8280
    },
    {
      "epoch": 13.075739644970414,
      "grad_norm": 0.003769711358472705,
      "learning_rate": 3.1303024983909664e-05,
      "loss": 0.0039,
      "step": 8290
    },
    {
      "epoch": 13.091518737672583,
      "grad_norm": 0.09505932778120041,
      "learning_rate": 3.12737698203733e-05,
      "loss": 0.0194,
      "step": 8300
    },
    {
      "epoch": 13.107297830374753,
      "grad_norm": 0.005745739676058292,
      "learning_rate": 3.124451465683693e-05,
      "loss": 0.0262,
      "step": 8310
    },
    {
      "epoch": 13.123076923076923,
      "grad_norm": 1.1178052425384521,
      "learning_rate": 3.121525949330057e-05,
      "loss": 0.0013,
      "step": 8320
    },
    {
      "epoch": 13.138856015779092,
      "grad_norm": 0.019160596653819084,
      "learning_rate": 3.1186004329764204e-05,
      "loss": 0.0053,
      "step": 8330
    },
    {
      "epoch": 13.154635108481262,
      "grad_norm": 0.137118861079216,
      "learning_rate": 3.115674916622784e-05,
      "loss": 0.0027,
      "step": 8340
    },
    {
      "epoch": 13.170414201183432,
      "grad_norm": 0.027121594175696373,
      "learning_rate": 3.112749400269148e-05,
      "loss": 0.0109,
      "step": 8350
    },
    {
      "epoch": 13.186193293885601,
      "grad_norm": 0.03296160325407982,
      "learning_rate": 3.109823883915511e-05,
      "loss": 0.0036,
      "step": 8360
    },
    {
      "epoch": 13.201972386587771,
      "grad_norm": 0.013553225435316563,
      "learning_rate": 3.1068983675618744e-05,
      "loss": 0.0173,
      "step": 8370
    },
    {
      "epoch": 13.21775147928994,
      "grad_norm": 0.20788149535655975,
      "learning_rate": 3.1039728512082385e-05,
      "loss": 0.0165,
      "step": 8380
    },
    {
      "epoch": 13.23353057199211,
      "grad_norm": 0.1377742886543274,
      "learning_rate": 3.101047334854602e-05,
      "loss": 0.0017,
      "step": 8390
    },
    {
      "epoch": 13.24930966469428,
      "grad_norm": 0.22767817974090576,
      "learning_rate": 3.098121818500966e-05,
      "loss": 0.0089,
      "step": 8400
    },
    {
      "epoch": 13.26508875739645,
      "grad_norm": 0.0033075055107474327,
      "learning_rate": 3.095196302147329e-05,
      "loss": 0.0005,
      "step": 8410
    },
    {
      "epoch": 13.28086785009862,
      "grad_norm": 0.0035834116861224174,
      "learning_rate": 3.0922707857936925e-05,
      "loss": 0.0027,
      "step": 8420
    },
    {
      "epoch": 13.29664694280079,
      "grad_norm": 0.03310522809624672,
      "learning_rate": 3.0893452694400565e-05,
      "loss": 0.0024,
      "step": 8430
    },
    {
      "epoch": 13.312426035502959,
      "grad_norm": 3.060422658920288,
      "learning_rate": 3.08641975308642e-05,
      "loss": 0.0074,
      "step": 8440
    },
    {
      "epoch": 13.328205128205129,
      "grad_norm": 0.13474109768867493,
      "learning_rate": 3.083494236732783e-05,
      "loss": 0.0231,
      "step": 8450
    },
    {
      "epoch": 13.343984220907299,
      "grad_norm": 1.195319414138794,
      "learning_rate": 3.080568720379147e-05,
      "loss": 0.0046,
      "step": 8460
    },
    {
      "epoch": 13.359763313609468,
      "grad_norm": 0.12032677233219147,
      "learning_rate": 3.0776432040255105e-05,
      "loss": 0.004,
      "step": 8470
    },
    {
      "epoch": 13.375542406311638,
      "grad_norm": 0.007135229650884867,
      "learning_rate": 3.074717687671874e-05,
      "loss": 0.025,
      "step": 8480
    },
    {
      "epoch": 13.391321499013806,
      "grad_norm": 0.14222317934036255,
      "learning_rate": 3.071792171318238e-05,
      "loss": 0.0057,
      "step": 8490
    },
    {
      "epoch": 13.407100591715976,
      "grad_norm": 0.005776220932602882,
      "learning_rate": 3.068866654964601e-05,
      "loss": 0.0056,
      "step": 8500
    },
    {
      "epoch": 13.422879684418145,
      "grad_norm": 0.710269570350647,
      "learning_rate": 3.065941138610965e-05,
      "loss": 0.0032,
      "step": 8510
    },
    {
      "epoch": 13.438658777120315,
      "grad_norm": 0.052412841469049454,
      "learning_rate": 3.0630156222573286e-05,
      "loss": 0.0031,
      "step": 8520
    },
    {
      "epoch": 13.454437869822485,
      "grad_norm": 0.00816528033465147,
      "learning_rate": 3.0600901059036926e-05,
      "loss": 0.0025,
      "step": 8530
    },
    {
      "epoch": 13.470216962524654,
      "grad_norm": 4.462972164154053,
      "learning_rate": 3.057164589550056e-05,
      "loss": 0.0117,
      "step": 8540
    },
    {
      "epoch": 13.485996055226824,
      "grad_norm": 0.0034122876822948456,
      "learning_rate": 3.054239073196419e-05,
      "loss": 0.0028,
      "step": 8550
    },
    {
      "epoch": 13.501775147928994,
      "grad_norm": 0.005158793646842241,
      "learning_rate": 3.0513135568427833e-05,
      "loss": 0.0037,
      "step": 8560
    },
    {
      "epoch": 13.517554240631164,
      "grad_norm": 0.01029006764292717,
      "learning_rate": 3.0483880404891462e-05,
      "loss": 0.0087,
      "step": 8570
    },
    {
      "epoch": 13.533333333333333,
      "grad_norm": 0.007850906811654568,
      "learning_rate": 3.04546252413551e-05,
      "loss": 0.0009,
      "step": 8580
    },
    {
      "epoch": 13.549112426035503,
      "grad_norm": 0.0028469287790358067,
      "learning_rate": 3.042537007781874e-05,
      "loss": 0.0011,
      "step": 8590
    },
    {
      "epoch": 13.564891518737673,
      "grad_norm": 0.00405824976041913,
      "learning_rate": 3.039611491428237e-05,
      "loss": 0.0067,
      "step": 8600
    },
    {
      "epoch": 13.580670611439842,
      "grad_norm": 0.1919914335012436,
      "learning_rate": 3.0366859750746006e-05,
      "loss": 0.0214,
      "step": 8610
    },
    {
      "epoch": 13.596449704142012,
      "grad_norm": 0.0446244440972805,
      "learning_rate": 3.0337604587209646e-05,
      "loss": 0.0121,
      "step": 8620
    },
    {
      "epoch": 13.612228796844182,
      "grad_norm": 0.22793550789356232,
      "learning_rate": 3.0308349423673283e-05,
      "loss": 0.0042,
      "step": 8630
    },
    {
      "epoch": 13.628007889546351,
      "grad_norm": 0.004373049829155207,
      "learning_rate": 3.0279094260136913e-05,
      "loss": 0.0008,
      "step": 8640
    },
    {
      "epoch": 13.643786982248521,
      "grad_norm": 0.03340650722384453,
      "learning_rate": 3.0249839096600553e-05,
      "loss": 0.0039,
      "step": 8650
    },
    {
      "epoch": 13.65956607495069,
      "grad_norm": 0.003054186701774597,
      "learning_rate": 3.022058393306419e-05,
      "loss": 0.011,
      "step": 8660
    },
    {
      "epoch": 13.67534516765286,
      "grad_norm": 0.005372111219912767,
      "learning_rate": 3.019132876952782e-05,
      "loss": 0.0219,
      "step": 8670
    },
    {
      "epoch": 13.69112426035503,
      "grad_norm": 0.21000103652477264,
      "learning_rate": 3.016207360599146e-05,
      "loss": 0.0026,
      "step": 8680
    },
    {
      "epoch": 13.7069033530572,
      "grad_norm": 0.004481676500290632,
      "learning_rate": 3.0132818442455097e-05,
      "loss": 0.0008,
      "step": 8690
    },
    {
      "epoch": 13.722682445759368,
      "grad_norm": 0.003849675878882408,
      "learning_rate": 3.0103563278918727e-05,
      "loss": 0.0139,
      "step": 8700
    },
    {
      "epoch": 13.73846153846154,
      "grad_norm": 0.23080244660377502,
      "learning_rate": 3.0074308115382367e-05,
      "loss": 0.0221,
      "step": 8710
    },
    {
      "epoch": 13.754240631163707,
      "grad_norm": 0.022263385355472565,
      "learning_rate": 3.0045052951846004e-05,
      "loss": 0.0016,
      "step": 8720
    },
    {
      "epoch": 13.770019723865877,
      "grad_norm": 0.03867737576365471,
      "learning_rate": 3.001579778830964e-05,
      "loss": 0.0089,
      "step": 8730
    },
    {
      "epoch": 13.785798816568047,
      "grad_norm": 0.3634348213672638,
      "learning_rate": 2.9986542624773274e-05,
      "loss": 0.0085,
      "step": 8740
    },
    {
      "epoch": 13.801577909270216,
      "grad_norm": 0.21411365270614624,
      "learning_rate": 2.995728746123691e-05,
      "loss": 0.0057,
      "step": 8750
    },
    {
      "epoch": 13.817357001972386,
      "grad_norm": 0.026111334562301636,
      "learning_rate": 2.9928032297700547e-05,
      "loss": 0.002,
      "step": 8760
    },
    {
      "epoch": 13.833136094674556,
      "grad_norm": 0.04844934493303299,
      "learning_rate": 2.989877713416418e-05,
      "loss": 0.0028,
      "step": 8770
    },
    {
      "epoch": 13.848915187376726,
      "grad_norm": 0.012878901325166225,
      "learning_rate": 2.9869521970627817e-05,
      "loss": 0.0005,
      "step": 8780
    },
    {
      "epoch": 13.864694280078895,
      "grad_norm": 0.03841305151581764,
      "learning_rate": 2.9840266807091454e-05,
      "loss": 0.0022,
      "step": 8790
    },
    {
      "epoch": 13.880473372781065,
      "grad_norm": 0.020081792026758194,
      "learning_rate": 2.9811011643555087e-05,
      "loss": 0.0018,
      "step": 8800
    },
    {
      "epoch": 13.896252465483235,
      "grad_norm": 0.0040669916197657585,
      "learning_rate": 2.9781756480018724e-05,
      "loss": 0.0111,
      "step": 8810
    },
    {
      "epoch": 13.912031558185404,
      "grad_norm": 0.05807047709822655,
      "learning_rate": 2.975250131648236e-05,
      "loss": 0.0015,
      "step": 8820
    },
    {
      "epoch": 13.927810650887574,
      "grad_norm": 0.001783030922524631,
      "learning_rate": 2.9723246152945994e-05,
      "loss": 0.0082,
      "step": 8830
    },
    {
      "epoch": 13.943589743589744,
      "grad_norm": 0.006535305641591549,
      "learning_rate": 2.969399098940963e-05,
      "loss": 0.0164,
      "step": 8840
    },
    {
      "epoch": 13.959368836291913,
      "grad_norm": 0.0066330041736364365,
      "learning_rate": 2.9664735825873268e-05,
      "loss": 0.0023,
      "step": 8850
    },
    {
      "epoch": 13.975147928994083,
      "grad_norm": 5.2401442527771,
      "learning_rate": 2.9635480662336908e-05,
      "loss": 0.0096,
      "step": 8860
    },
    {
      "epoch": 13.990927021696253,
      "grad_norm": 0.016177350655198097,
      "learning_rate": 2.9606225498800538e-05,
      "loss": 0.0024,
      "step": 8870
    },
    {
      "epoch": 14.0,
      "eval_accuracy": 0.8820625669085286,
      "eval_loss": 0.7608409523963928,
      "eval_runtime": 213.321,
      "eval_samples_per_second": 78.82,
      "eval_steps_per_second": 4.927,
      "step": 8876
    },
    {
      "epoch": 14.006311637080868,
      "grad_norm": 0.06419822573661804,
      "learning_rate": 2.9576970335264175e-05,
      "loss": 0.0007,
      "step": 8880
    },
    {
      "epoch": 14.022090729783038,
      "grad_norm": 0.0038331933319568634,
      "learning_rate": 2.9547715171727815e-05,
      "loss": 0.0012,
      "step": 8890
    },
    {
      "epoch": 14.037869822485208,
      "grad_norm": 0.019924482330679893,
      "learning_rate": 2.9518460008191445e-05,
      "loss": 0.0006,
      "step": 8900
    },
    {
      "epoch": 14.053648915187377,
      "grad_norm": 0.08382726460695267,
      "learning_rate": 2.948920484465508e-05,
      "loss": 0.0027,
      "step": 8910
    },
    {
      "epoch": 14.069428007889547,
      "grad_norm": 0.003963787108659744,
      "learning_rate": 2.9459949681118722e-05,
      "loss": 0.0013,
      "step": 8920
    },
    {
      "epoch": 14.085207100591717,
      "grad_norm": 0.17688196897506714,
      "learning_rate": 2.9430694517582352e-05,
      "loss": 0.0014,
      "step": 8930
    },
    {
      "epoch": 14.100986193293886,
      "grad_norm": 0.23046079277992249,
      "learning_rate": 2.940143935404599e-05,
      "loss": 0.0023,
      "step": 8940
    },
    {
      "epoch": 14.116765285996054,
      "grad_norm": 0.004645843990147114,
      "learning_rate": 2.937218419050963e-05,
      "loss": 0.0051,
      "step": 8950
    },
    {
      "epoch": 14.132544378698224,
      "grad_norm": 0.00470576249063015,
      "learning_rate": 2.9342929026973265e-05,
      "loss": 0.0002,
      "step": 8960
    },
    {
      "epoch": 14.148323471400394,
      "grad_norm": 0.08427782356739044,
      "learning_rate": 2.9313673863436895e-05,
      "loss": 0.0003,
      "step": 8970
    },
    {
      "epoch": 14.164102564102564,
      "grad_norm": 0.0022790664806962013,
      "learning_rate": 2.9284418699900535e-05,
      "loss": 0.0018,
      "step": 8980
    },
    {
      "epoch": 14.179881656804733,
      "grad_norm": 0.0055382875725626945,
      "learning_rate": 2.9255163536364172e-05,
      "loss": 0.0003,
      "step": 8990
    },
    {
      "epoch": 14.195660749506903,
      "grad_norm": 0.0024787033908069134,
      "learning_rate": 2.9225908372827802e-05,
      "loss": 0.0004,
      "step": 9000
    },
    {
      "epoch": 14.211439842209073,
      "grad_norm": 0.0031055700965225697,
      "learning_rate": 2.9196653209291442e-05,
      "loss": 0.0006,
      "step": 9010
    },
    {
      "epoch": 14.227218934911242,
      "grad_norm": 0.04743006080389023,
      "learning_rate": 2.916739804575508e-05,
      "loss": 0.0006,
      "step": 9020
    },
    {
      "epoch": 14.242998027613412,
      "grad_norm": 0.014173786155879498,
      "learning_rate": 2.9138142882218712e-05,
      "loss": 0.0012,
      "step": 9030
    },
    {
      "epoch": 14.258777120315582,
      "grad_norm": 0.0033854807261377573,
      "learning_rate": 2.910888771868235e-05,
      "loss": 0.0002,
      "step": 9040
    },
    {
      "epoch": 14.274556213017751,
      "grad_norm": 0.0015075764385983348,
      "learning_rate": 2.9079632555145986e-05,
      "loss": 0.0058,
      "step": 9050
    },
    {
      "epoch": 14.290335305719921,
      "grad_norm": 0.27369368076324463,
      "learning_rate": 2.905037739160962e-05,
      "loss": 0.0044,
      "step": 9060
    },
    {
      "epoch": 14.30611439842209,
      "grad_norm": 0.11999664455652237,
      "learning_rate": 2.9021122228073256e-05,
      "loss": 0.0016,
      "step": 9070
    },
    {
      "epoch": 14.32189349112426,
      "grad_norm": 0.05671707168221474,
      "learning_rate": 2.8991867064536893e-05,
      "loss": 0.0038,
      "step": 9080
    },
    {
      "epoch": 14.33767258382643,
      "grad_norm": 0.001571544911712408,
      "learning_rate": 2.896261190100053e-05,
      "loss": 0.0002,
      "step": 9090
    },
    {
      "epoch": 14.3534516765286,
      "grad_norm": 0.001720766886137426,
      "learning_rate": 2.8933356737464163e-05,
      "loss": 0.0002,
      "step": 9100
    },
    {
      "epoch": 14.36923076923077,
      "grad_norm": 0.07996775954961777,
      "learning_rate": 2.89041015739278e-05,
      "loss": 0.0005,
      "step": 9110
    },
    {
      "epoch": 14.38500986193294,
      "grad_norm": 0.06880860775709152,
      "learning_rate": 2.8874846410391436e-05,
      "loss": 0.0022,
      "step": 9120
    },
    {
      "epoch": 14.400788954635109,
      "grad_norm": 0.001106088049709797,
      "learning_rate": 2.884559124685507e-05,
      "loss": 0.0002,
      "step": 9130
    },
    {
      "epoch": 14.416568047337279,
      "grad_norm": 0.010210609994828701,
      "learning_rate": 2.8816336083318707e-05,
      "loss": 0.0018,
      "step": 9140
    },
    {
      "epoch": 14.432347140039449,
      "grad_norm": 0.0018604178912937641,
      "learning_rate": 2.8787080919782343e-05,
      "loss": 0.0063,
      "step": 9150
    },
    {
      "epoch": 14.448126232741618,
      "grad_norm": 5.171316623687744,
      "learning_rate": 2.8757825756245977e-05,
      "loss": 0.0133,
      "step": 9160
    },
    {
      "epoch": 14.463905325443786,
      "grad_norm": 0.0012298185611143708,
      "learning_rate": 2.8728570592709613e-05,
      "loss": 0.0017,
      "step": 9170
    },
    {
      "epoch": 14.479684418145956,
      "grad_norm": 0.0014177864650264382,
      "learning_rate": 2.869931542917325e-05,
      "loss": 0.0112,
      "step": 9180
    },
    {
      "epoch": 14.495463510848126,
      "grad_norm": 0.06203952431678772,
      "learning_rate": 2.867006026563689e-05,
      "loss": 0.001,
      "step": 9190
    },
    {
      "epoch": 14.511242603550295,
      "grad_norm": 0.08231832087039948,
      "learning_rate": 2.864080510210052e-05,
      "loss": 0.0014,
      "step": 9200
    },
    {
      "epoch": 14.527021696252465,
      "grad_norm": 0.0027384813874959946,
      "learning_rate": 2.8611549938564157e-05,
      "loss": 0.0002,
      "step": 9210
    },
    {
      "epoch": 14.542800788954635,
      "grad_norm": 0.005296401213854551,
      "learning_rate": 2.8582294775027797e-05,
      "loss": 0.0003,
      "step": 9220
    },
    {
      "epoch": 14.558579881656804,
      "grad_norm": 0.0014872587053105235,
      "learning_rate": 2.8553039611491427e-05,
      "loss": 0.0071,
      "step": 9230
    },
    {
      "epoch": 14.574358974358974,
      "grad_norm": 0.0038264042232185602,
      "learning_rate": 2.8523784447955064e-05,
      "loss": 0.0004,
      "step": 9240
    },
    {
      "epoch": 14.590138067061144,
      "grad_norm": 0.004230465739965439,
      "learning_rate": 2.8494529284418704e-05,
      "loss": 0.0056,
      "step": 9250
    },
    {
      "epoch": 14.605917159763314,
      "grad_norm": 0.002324281493201852,
      "learning_rate": 2.8465274120882334e-05,
      "loss": 0.0037,
      "step": 9260
    },
    {
      "epoch": 14.621696252465483,
      "grad_norm": 0.013141890987753868,
      "learning_rate": 2.843601895734597e-05,
      "loss": 0.0002,
      "step": 9270
    },
    {
      "epoch": 14.637475345167653,
      "grad_norm": 0.0030102478340268135,
      "learning_rate": 2.840676379380961e-05,
      "loss": 0.0007,
      "step": 9280
    },
    {
      "epoch": 14.653254437869823,
      "grad_norm": 3.1538171768188477,
      "learning_rate": 2.8377508630273248e-05,
      "loss": 0.0072,
      "step": 9290
    },
    {
      "epoch": 14.669033530571992,
      "grad_norm": 0.017217449843883514,
      "learning_rate": 2.8348253466736878e-05,
      "loss": 0.0002,
      "step": 9300
    },
    {
      "epoch": 14.684812623274162,
      "grad_norm": 0.00180712784640491,
      "learning_rate": 2.8318998303200518e-05,
      "loss": 0.0191,
      "step": 9310
    },
    {
      "epoch": 14.700591715976332,
      "grad_norm": 0.016427312046289444,
      "learning_rate": 2.8289743139664155e-05,
      "loss": 0.0028,
      "step": 9320
    },
    {
      "epoch": 14.716370808678501,
      "grad_norm": 0.8491262197494507,
      "learning_rate": 2.8260487976127788e-05,
      "loss": 0.0065,
      "step": 9330
    },
    {
      "epoch": 14.732149901380671,
      "grad_norm": 0.02934822253882885,
      "learning_rate": 2.8231232812591425e-05,
      "loss": 0.0006,
      "step": 9340
    },
    {
      "epoch": 14.74792899408284,
      "grad_norm": 0.07824068516492844,
      "learning_rate": 2.820197764905506e-05,
      "loss": 0.0105,
      "step": 9350
    },
    {
      "epoch": 14.76370808678501,
      "grad_norm": 0.0018491331720724702,
      "learning_rate": 2.8172722485518695e-05,
      "loss": 0.0002,
      "step": 9360
    },
    {
      "epoch": 14.77948717948718,
      "grad_norm": 0.5457970499992371,
      "learning_rate": 2.814346732198233e-05,
      "loss": 0.0175,
      "step": 9370
    },
    {
      "epoch": 14.795266272189348,
      "grad_norm": 0.0039020655676722527,
      "learning_rate": 2.811421215844597e-05,
      "loss": 0.0057,
      "step": 9380
    },
    {
      "epoch": 14.811045364891518,
      "grad_norm": 0.0032468142453581095,
      "learning_rate": 2.80849569949096e-05,
      "loss": 0.0116,
      "step": 9390
    },
    {
      "epoch": 14.826824457593688,
      "grad_norm": 0.05455769598484039,
      "learning_rate": 2.805570183137324e-05,
      "loss": 0.006,
      "step": 9400
    },
    {
      "epoch": 14.842603550295857,
      "grad_norm": 0.0062849740497767925,
      "learning_rate": 2.8026446667836875e-05,
      "loss": 0.0089,
      "step": 9410
    },
    {
      "epoch": 14.858382642998027,
      "grad_norm": 0.06813128292560577,
      "learning_rate": 2.7997191504300512e-05,
      "loss": 0.0023,
      "step": 9420
    },
    {
      "epoch": 14.874161735700197,
      "grad_norm": 0.0019886575173586607,
      "learning_rate": 2.7967936340764145e-05,
      "loss": 0.008,
      "step": 9430
    },
    {
      "epoch": 14.889940828402366,
      "grad_norm": 0.35716986656188965,
      "learning_rate": 2.7938681177227782e-05,
      "loss": 0.0111,
      "step": 9440
    },
    {
      "epoch": 14.905719921104536,
      "grad_norm": 0.016183745115995407,
      "learning_rate": 2.790942601369142e-05,
      "loss": 0.0006,
      "step": 9450
    },
    {
      "epoch": 14.921499013806706,
      "grad_norm": 0.009386231191456318,
      "learning_rate": 2.7880170850155052e-05,
      "loss": 0.0072,
      "step": 9460
    },
    {
      "epoch": 14.937278106508876,
      "grad_norm": 0.014262611046433449,
      "learning_rate": 2.785091568661869e-05,
      "loss": 0.0005,
      "step": 9470
    },
    {
      "epoch": 14.953057199211045,
      "grad_norm": 0.002899003913626075,
      "learning_rate": 2.7821660523082326e-05,
      "loss": 0.001,
      "step": 9480
    },
    {
      "epoch": 14.968836291913215,
      "grad_norm": 0.006066762376576662,
      "learning_rate": 2.779240535954596e-05,
      "loss": 0.0024,
      "step": 9490
    },
    {
      "epoch": 14.984615384615385,
      "grad_norm": 0.13151395320892334,
      "learning_rate": 2.7763150196009596e-05,
      "loss": 0.003,
      "step": 9500
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.0014789921697229147,
      "learning_rate": 2.7733895032473233e-05,
      "loss": 0.0049,
      "step": 9510
    },
    {
      "epoch": 15.0,
      "eval_accuracy": 0.8645176638515523,
      "eval_loss": 0.8364310264587402,
      "eval_runtime": 203.3536,
      "eval_samples_per_second": 82.684,
      "eval_steps_per_second": 5.168,
      "step": 9510
    },
    {
      "epoch": 15.01577909270217,
      "grad_norm": 0.0015612408751621842,
      "learning_rate": 2.7704639868936873e-05,
      "loss": 0.0046,
      "step": 9520
    },
    {
      "epoch": 15.03155818540434,
      "grad_norm": 0.08165975660085678,
      "learning_rate": 2.7675384705400503e-05,
      "loss": 0.0003,
      "step": 9530
    },
    {
      "epoch": 15.04733727810651,
      "grad_norm": 0.06971374154090881,
      "learning_rate": 2.764612954186414e-05,
      "loss": 0.0013,
      "step": 9540
    },
    {
      "epoch": 15.063116370808679,
      "grad_norm": 0.001710659358650446,
      "learning_rate": 2.761687437832778e-05,
      "loss": 0.0003,
      "step": 9550
    },
    {
      "epoch": 15.078895463510849,
      "grad_norm": 0.0022341294679790735,
      "learning_rate": 2.758761921479141e-05,
      "loss": 0.0003,
      "step": 9560
    },
    {
      "epoch": 15.094674556213018,
      "grad_norm": 1.7150509357452393,
      "learning_rate": 2.7558364051255046e-05,
      "loss": 0.0027,
      "step": 9570
    },
    {
      "epoch": 15.110453648915188,
      "grad_norm": 1.4624521732330322,
      "learning_rate": 2.7529108887718686e-05,
      "loss": 0.001,
      "step": 9580
    },
    {
      "epoch": 15.126232741617358,
      "grad_norm": 0.009446721524000168,
      "learning_rate": 2.7499853724182316e-05,
      "loss": 0.0003,
      "step": 9590
    },
    {
      "epoch": 15.142011834319527,
      "grad_norm": 0.09175015985965729,
      "learning_rate": 2.7470598560645953e-05,
      "loss": 0.0011,
      "step": 9600
    },
    {
      "epoch": 15.157790927021697,
      "grad_norm": 0.003832767251878977,
      "learning_rate": 2.7441343397109593e-05,
      "loss": 0.0005,
      "step": 9610
    },
    {
      "epoch": 15.173570019723865,
      "grad_norm": 0.0010630643228068948,
      "learning_rate": 2.7412088233573223e-05,
      "loss": 0.0005,
      "step": 9620
    },
    {
      "epoch": 15.189349112426035,
      "grad_norm": 0.0032277607824653387,
      "learning_rate": 2.7382833070036863e-05,
      "loss": 0.0004,
      "step": 9630
    },
    {
      "epoch": 15.205128205128204,
      "grad_norm": 0.0581987239420414,
      "learning_rate": 2.73535779065005e-05,
      "loss": 0.0004,
      "step": 9640
    },
    {
      "epoch": 15.220907297830374,
      "grad_norm": 0.005820652469992638,
      "learning_rate": 2.7324322742964137e-05,
      "loss": 0.0004,
      "step": 9650
    },
    {
      "epoch": 15.236686390532544,
      "grad_norm": 0.0016970130382105708,
      "learning_rate": 2.729506757942777e-05,
      "loss": 0.0002,
      "step": 9660
    },
    {
      "epoch": 15.252465483234714,
      "grad_norm": 0.0034103423822671175,
      "learning_rate": 2.7265812415891407e-05,
      "loss": 0.0027,
      "step": 9670
    },
    {
      "epoch": 15.268244575936883,
      "grad_norm": 6.882563591003418,
      "learning_rate": 2.7236557252355044e-05,
      "loss": 0.01,
      "step": 9680
    },
    {
      "epoch": 15.284023668639053,
      "grad_norm": 0.0018558262381702662,
      "learning_rate": 2.7207302088818677e-05,
      "loss": 0.0003,
      "step": 9690
    },
    {
      "epoch": 15.299802761341223,
      "grad_norm": 0.007802326697856188,
      "learning_rate": 2.7178046925282314e-05,
      "loss": 0.0005,
      "step": 9700
    },
    {
      "epoch": 15.315581854043392,
      "grad_norm": 0.9796958565711975,
      "learning_rate": 2.714879176174595e-05,
      "loss": 0.0041,
      "step": 9710
    },
    {
      "epoch": 15.331360946745562,
      "grad_norm": 0.002544116461649537,
      "learning_rate": 2.7119536598209584e-05,
      "loss": 0.0038,
      "step": 9720
    },
    {
      "epoch": 15.347140039447732,
      "grad_norm": 0.005765337496995926,
      "learning_rate": 2.709028143467322e-05,
      "loss": 0.0008,
      "step": 9730
    },
    {
      "epoch": 15.362919132149901,
      "grad_norm": 0.05386771634221077,
      "learning_rate": 2.7061026271136858e-05,
      "loss": 0.0002,
      "step": 9740
    },
    {
      "epoch": 15.378698224852071,
      "grad_norm": 0.002460255054756999,
      "learning_rate": 2.7031771107600494e-05,
      "loss": 0.0003,
      "step": 9750
    },
    {
      "epoch": 15.39447731755424,
      "grad_norm": 0.0018699243664741516,
      "learning_rate": 2.7002515944064128e-05,
      "loss": 0.004,
      "step": 9760
    },
    {
      "epoch": 15.41025641025641,
      "grad_norm": 0.0025392360985279083,
      "learning_rate": 2.6973260780527764e-05,
      "loss": 0.0014,
      "step": 9770
    },
    {
      "epoch": 15.42603550295858,
      "grad_norm": 0.002148220781236887,
      "learning_rate": 2.69440056169914e-05,
      "loss": 0.0111,
      "step": 9780
    },
    {
      "epoch": 15.44181459566075,
      "grad_norm": 0.008194654248654842,
      "learning_rate": 2.6914750453455035e-05,
      "loss": 0.0072,
      "step": 9790
    },
    {
      "epoch": 15.45759368836292,
      "grad_norm": 0.01733442023396492,
      "learning_rate": 2.688549528991867e-05,
      "loss": 0.0012,
      "step": 9800
    },
    {
      "epoch": 15.47337278106509,
      "grad_norm": 0.04679076373577118,
      "learning_rate": 2.6856240126382308e-05,
      "loss": 0.0029,
      "step": 9810
    },
    {
      "epoch": 15.489151873767259,
      "grad_norm": 0.0013877032324671745,
      "learning_rate": 2.682698496284594e-05,
      "loss": 0.0104,
      "step": 9820
    },
    {
      "epoch": 15.504930966469429,
      "grad_norm": 0.0014065137365832925,
      "learning_rate": 2.6797729799309578e-05,
      "loss": 0.0011,
      "step": 9830
    },
    {
      "epoch": 15.520710059171599,
      "grad_norm": 0.0016988131683319807,
      "learning_rate": 2.6768474635773215e-05,
      "loss": 0.001,
      "step": 9840
    },
    {
      "epoch": 15.536489151873766,
      "grad_norm": 0.8622052073478699,
      "learning_rate": 2.6739219472236848e-05,
      "loss": 0.002,
      "step": 9850
    },
    {
      "epoch": 15.552268244575936,
      "grad_norm": 0.031266823410987854,
      "learning_rate": 2.6709964308700485e-05,
      "loss": 0.0016,
      "step": 9860
    },
    {
      "epoch": 15.568047337278106,
      "grad_norm": 0.002541863126680255,
      "learning_rate": 2.6680709145164122e-05,
      "loss": 0.0108,
      "step": 9870
    },
    {
      "epoch": 15.583826429980276,
      "grad_norm": 0.028179805725812912,
      "learning_rate": 2.6651453981627762e-05,
      "loss": 0.008,
      "step": 9880
    },
    {
      "epoch": 15.599605522682445,
      "grad_norm": 0.0021941971499472857,
      "learning_rate": 2.6622198818091392e-05,
      "loss": 0.0126,
      "step": 9890
    },
    {
      "epoch": 15.615384615384615,
      "grad_norm": 2.1758787631988525,
      "learning_rate": 2.6592943654555032e-05,
      "loss": 0.0118,
      "step": 9900
    },
    {
      "epoch": 15.631163708086785,
      "grad_norm": 0.009098522365093231,
      "learning_rate": 2.656368849101867e-05,
      "loss": 0.0002,
      "step": 9910
    },
    {
      "epoch": 15.646942800788954,
      "grad_norm": 0.0017025609267875552,
      "learning_rate": 2.65344333274823e-05,
      "loss": 0.01,
      "step": 9920
    },
    {
      "epoch": 15.662721893491124,
      "grad_norm": 0.0035752567928284407,
      "learning_rate": 2.650517816394594e-05,
      "loss": 0.0178,
      "step": 9930
    },
    {
      "epoch": 15.678500986193294,
      "grad_norm": 0.02707129344344139,
      "learning_rate": 2.6475923000409576e-05,
      "loss": 0.0027,
      "step": 9940
    },
    {
      "epoch": 15.694280078895464,
      "grad_norm": 0.1734130084514618,
      "learning_rate": 2.6446667836873206e-05,
      "loss": 0.004,
      "step": 9950
    },
    {
      "epoch": 15.710059171597633,
      "grad_norm": 0.4711430072784424,
      "learning_rate": 2.6417412673336846e-05,
      "loss": 0.014,
      "step": 9960
    },
    {
      "epoch": 15.725838264299803,
      "grad_norm": 2.5352680683135986,
      "learning_rate": 2.6388157509800483e-05,
      "loss": 0.008,
      "step": 9970
    },
    {
      "epoch": 15.741617357001973,
      "grad_norm": 0.004432269372045994,
      "learning_rate": 2.635890234626412e-05,
      "loss": 0.0017,
      "step": 9980
    },
    {
      "epoch": 15.757396449704142,
      "grad_norm": 0.09243686497211456,
      "learning_rate": 2.6329647182727753e-05,
      "loss": 0.0022,
      "step": 9990
    },
    {
      "epoch": 15.773175542406312,
      "grad_norm": 0.005376181099563837,
      "learning_rate": 2.630039201919139e-05,
      "loss": 0.0003,
      "step": 10000
    },
    {
      "epoch": 15.788954635108482,
      "grad_norm": 0.002355415839701891,
      "learning_rate": 2.6271136855655026e-05,
      "loss": 0.0003,
      "step": 10010
    },
    {
      "epoch": 15.804733727810651,
      "grad_norm": 0.0027366760186851025,
      "learning_rate": 2.624188169211866e-05,
      "loss": 0.0026,
      "step": 10020
    },
    {
      "epoch": 15.820512820512821,
      "grad_norm": 0.002709887456148863,
      "learning_rate": 2.6212626528582296e-05,
      "loss": 0.015,
      "step": 10030
    },
    {
      "epoch": 15.83629191321499,
      "grad_norm": 0.0042318906635046005,
      "learning_rate": 2.6183371365045933e-05,
      "loss": 0.0004,
      "step": 10040
    },
    {
      "epoch": 15.85207100591716,
      "grad_norm": 0.008711378090083599,
      "learning_rate": 2.6154116201509566e-05,
      "loss": 0.0108,
      "step": 10050
    },
    {
      "epoch": 15.867850098619328,
      "grad_norm": 0.10241005569696426,
      "learning_rate": 2.6124861037973203e-05,
      "loss": 0.0036,
      "step": 10060
    },
    {
      "epoch": 15.883629191321498,
      "grad_norm": 0.008860105648636818,
      "learning_rate": 2.609560587443684e-05,
      "loss": 0.0089,
      "step": 10070
    },
    {
      "epoch": 15.899408284023668,
      "grad_norm": 0.2447238564491272,
      "learning_rate": 2.6066350710900477e-05,
      "loss": 0.0014,
      "step": 10080
    },
    {
      "epoch": 15.915187376725838,
      "grad_norm": 0.016000770032405853,
      "learning_rate": 2.603709554736411e-05,
      "loss": 0.0025,
      "step": 10090
    },
    {
      "epoch": 15.930966469428007,
      "grad_norm": 0.4081135392189026,
      "learning_rate": 2.6007840383827747e-05,
      "loss": 0.0141,
      "step": 10100
    },
    {
      "epoch": 15.946745562130177,
      "grad_norm": 0.0040938975289464,
      "learning_rate": 2.5978585220291383e-05,
      "loss": 0.0004,
      "step": 10110
    },
    {
      "epoch": 15.962524654832347,
      "grad_norm": 0.07133615016937256,
      "learning_rate": 2.5949330056755017e-05,
      "loss": 0.0019,
      "step": 10120
    },
    {
      "epoch": 15.978303747534516,
      "grad_norm": 0.0017077638767659664,
      "learning_rate": 2.5920074893218654e-05,
      "loss": 0.01,
      "step": 10130
    },
    {
      "epoch": 15.994082840236686,
      "grad_norm": 0.012235915288329124,
      "learning_rate": 2.589081972968229e-05,
      "loss": 0.0058,
      "step": 10140
    },
    {
      "epoch": 16.0,
      "eval_accuracy": 0.8836683715950994,
      "eval_loss": 0.7940361499786377,
      "eval_runtime": 199.7371,
      "eval_samples_per_second": 84.181,
      "eval_steps_per_second": 5.262,
      "step": 10144
    },
    {
      "epoch": 16.0094674556213,
      "grad_norm": 0.002520802430808544,
      "learning_rate": 2.5861564566145924e-05,
      "loss": 0.0014,
      "step": 10150
    },
    {
      "epoch": 16.025246548323473,
      "grad_norm": 0.001682609086856246,
      "learning_rate": 2.583230940260956e-05,
      "loss": 0.0003,
      "step": 10160
    },
    {
      "epoch": 16.04102564102564,
      "grad_norm": 0.0031870820093899965,
      "learning_rate": 2.5803054239073197e-05,
      "loss": 0.0007,
      "step": 10170
    },
    {
      "epoch": 16.056804733727812,
      "grad_norm": 0.1883186548948288,
      "learning_rate": 2.577379907553683e-05,
      "loss": 0.0008,
      "step": 10180
    },
    {
      "epoch": 16.07258382642998,
      "grad_norm": 0.0017677521100267768,
      "learning_rate": 2.5744543912000467e-05,
      "loss": 0.0014,
      "step": 10190
    },
    {
      "epoch": 16.088362919132148,
      "grad_norm": 0.0027901851572096348,
      "learning_rate": 2.5715288748464107e-05,
      "loss": 0.0009,
      "step": 10200
    },
    {
      "epoch": 16.10414201183432,
      "grad_norm": 0.6662736535072327,
      "learning_rate": 2.5686033584927744e-05,
      "loss": 0.0111,
      "step": 10210
    },
    {
      "epoch": 16.119921104536488,
      "grad_norm": 0.06449916958808899,
      "learning_rate": 2.5656778421391374e-05,
      "loss": 0.0058,
      "step": 10220
    },
    {
      "epoch": 16.13570019723866,
      "grad_norm": 0.14713211357593536,
      "learning_rate": 2.5627523257855014e-05,
      "loss": 0.0016,
      "step": 10230
    },
    {
      "epoch": 16.151479289940827,
      "grad_norm": 0.026546284556388855,
      "learning_rate": 2.559826809431865e-05,
      "loss": 0.0046,
      "step": 10240
    },
    {
      "epoch": 16.167258382643,
      "grad_norm": 0.0016278140246868134,
      "learning_rate": 2.556901293078228e-05,
      "loss": 0.0022,
      "step": 10250
    },
    {
      "epoch": 16.183037475345166,
      "grad_norm": 0.005659659393131733,
      "learning_rate": 2.553975776724592e-05,
      "loss": 0.0004,
      "step": 10260
    },
    {
      "epoch": 16.198816568047338,
      "grad_norm": 0.0012587569653987885,
      "learning_rate": 2.5510502603709558e-05,
      "loss": 0.0026,
      "step": 10270
    },
    {
      "epoch": 16.214595660749506,
      "grad_norm": 0.004454891663044691,
      "learning_rate": 2.5481247440173188e-05,
      "loss": 0.0007,
      "step": 10280
    },
    {
      "epoch": 16.230374753451677,
      "grad_norm": 0.0031392790842801332,
      "learning_rate": 2.5451992276636828e-05,
      "loss": 0.0123,
      "step": 10290
    },
    {
      "epoch": 16.246153846153845,
      "grad_norm": 0.05181337893009186,
      "learning_rate": 2.5422737113100465e-05,
      "loss": 0.0018,
      "step": 10300
    },
    {
      "epoch": 16.261932938856017,
      "grad_norm": 0.005726780276745558,
      "learning_rate": 2.53934819495641e-05,
      "loss": 0.0047,
      "step": 10310
    },
    {
      "epoch": 16.277712031558185,
      "grad_norm": 0.0012540621683001518,
      "learning_rate": 2.5364226786027735e-05,
      "loss": 0.0062,
      "step": 10320
    },
    {
      "epoch": 16.293491124260356,
      "grad_norm": 0.0010677831014618278,
      "learning_rate": 2.5334971622491372e-05,
      "loss": 0.0002,
      "step": 10330
    },
    {
      "epoch": 16.309270216962524,
      "grad_norm": 0.0024082036688923836,
      "learning_rate": 2.530571645895501e-05,
      "loss": 0.0003,
      "step": 10340
    },
    {
      "epoch": 16.325049309664696,
      "grad_norm": 0.060878753662109375,
      "learning_rate": 2.5276461295418642e-05,
      "loss": 0.0049,
      "step": 10350
    },
    {
      "epoch": 16.340828402366864,
      "grad_norm": 0.003764478489756584,
      "learning_rate": 2.524720613188228e-05,
      "loss": 0.0008,
      "step": 10360
    },
    {
      "epoch": 16.356607495069035,
      "grad_norm": 0.012030082754790783,
      "learning_rate": 2.5217950968345915e-05,
      "loss": 0.001,
      "step": 10370
    },
    {
      "epoch": 16.372386587771203,
      "grad_norm": 0.0787397250533104,
      "learning_rate": 2.518869580480955e-05,
      "loss": 0.0009,
      "step": 10380
    },
    {
      "epoch": 16.388165680473374,
      "grad_norm": 0.0014409131836146116,
      "learning_rate": 2.5159440641273185e-05,
      "loss": 0.0007,
      "step": 10390
    },
    {
      "epoch": 16.403944773175542,
      "grad_norm": 0.0022572169546037912,
      "learning_rate": 2.5130185477736822e-05,
      "loss": 0.0013,
      "step": 10400
    },
    {
      "epoch": 16.419723865877714,
      "grad_norm": 0.001953636994585395,
      "learning_rate": 2.5100930314200456e-05,
      "loss": 0.007,
      "step": 10410
    },
    {
      "epoch": 16.43550295857988,
      "grad_norm": 0.00417944835498929,
      "learning_rate": 2.5071675150664092e-05,
      "loss": 0.0022,
      "step": 10420
    },
    {
      "epoch": 16.45128205128205,
      "grad_norm": 0.009270631708204746,
      "learning_rate": 2.504241998712773e-05,
      "loss": 0.0036,
      "step": 10430
    },
    {
      "epoch": 16.46706114398422,
      "grad_norm": 0.30964550375938416,
      "learning_rate": 2.5013164823591366e-05,
      "loss": 0.0014,
      "step": 10440
    },
    {
      "epoch": 16.48284023668639,
      "grad_norm": 0.02194126881659031,
      "learning_rate": 2.4983909660055003e-05,
      "loss": 0.0044,
      "step": 10450
    },
    {
      "epoch": 16.49861932938856,
      "grad_norm": 0.0019158720970153809,
      "learning_rate": 2.4954654496518636e-05,
      "loss": 0.0032,
      "step": 10460
    },
    {
      "epoch": 16.51439842209073,
      "grad_norm": 0.0029562038835138083,
      "learning_rate": 2.4925399332982273e-05,
      "loss": 0.0002,
      "step": 10470
    },
    {
      "epoch": 16.5301775147929,
      "grad_norm": 0.008335847407579422,
      "learning_rate": 2.489614416944591e-05,
      "loss": 0.0004,
      "step": 10480
    },
    {
      "epoch": 16.545956607495068,
      "grad_norm": 0.07991950958967209,
      "learning_rate": 2.4866889005909543e-05,
      "loss": 0.0011,
      "step": 10490
    },
    {
      "epoch": 16.56173570019724,
      "grad_norm": 0.02103612944483757,
      "learning_rate": 2.4837633842373183e-05,
      "loss": 0.0002,
      "step": 10500
    },
    {
      "epoch": 16.577514792899407,
      "grad_norm": 0.0017175448592752218,
      "learning_rate": 2.4808378678836816e-05,
      "loss": 0.0004,
      "step": 10510
    },
    {
      "epoch": 16.59329388560158,
      "grad_norm": 0.0012688732240349054,
      "learning_rate": 2.477912351530045e-05,
      "loss": 0.0004,
      "step": 10520
    },
    {
      "epoch": 16.609072978303747,
      "grad_norm": 0.001469347276724875,
      "learning_rate": 2.474986835176409e-05,
      "loss": 0.0003,
      "step": 10530
    },
    {
      "epoch": 16.624852071005918,
      "grad_norm": 0.10719682276248932,
      "learning_rate": 2.4720613188227723e-05,
      "loss": 0.0014,
      "step": 10540
    },
    {
      "epoch": 16.640631163708086,
      "grad_norm": 0.001274153240956366,
      "learning_rate": 2.4691358024691357e-05,
      "loss": 0.0001,
      "step": 10550
    },
    {
      "epoch": 16.656410256410258,
      "grad_norm": 0.0014518348034471273,
      "learning_rate": 2.4662102861154997e-05,
      "loss": 0.0147,
      "step": 10560
    },
    {
      "epoch": 16.672189349112426,
      "grad_norm": 0.05672314763069153,
      "learning_rate": 2.463284769761863e-05,
      "loss": 0.0014,
      "step": 10570
    },
    {
      "epoch": 16.687968441814597,
      "grad_norm": 0.0011826995760202408,
      "learning_rate": 2.4603592534082267e-05,
      "loss": 0.0001,
      "step": 10580
    },
    {
      "epoch": 16.703747534516765,
      "grad_norm": 0.001828715205192566,
      "learning_rate": 2.4574337370545904e-05,
      "loss": 0.0003,
      "step": 10590
    },
    {
      "epoch": 16.719526627218936,
      "grad_norm": 0.001064289826899767,
      "learning_rate": 2.4545082207009537e-05,
      "loss": 0.0007,
      "step": 10600
    },
    {
      "epoch": 16.735305719921104,
      "grad_norm": 0.0017996621318161488,
      "learning_rate": 2.4515827043473174e-05,
      "loss": 0.0001,
      "step": 10610
    },
    {
      "epoch": 16.751084812623276,
      "grad_norm": 0.0011588949710130692,
      "learning_rate": 2.448657187993681e-05,
      "loss": 0.0002,
      "step": 10620
    },
    {
      "epoch": 16.766863905325444,
      "grad_norm": 0.0009538801969029009,
      "learning_rate": 2.4457316716400447e-05,
      "loss": 0.0012,
      "step": 10630
    },
    {
      "epoch": 16.78264299802761,
      "grad_norm": 0.024894684553146362,
      "learning_rate": 2.442806155286408e-05,
      "loss": 0.0002,
      "step": 10640
    },
    {
      "epoch": 16.798422090729783,
      "grad_norm": 0.030054092407226562,
      "learning_rate": 2.4398806389327717e-05,
      "loss": 0.0017,
      "step": 10650
    },
    {
      "epoch": 16.81420118343195,
      "grad_norm": 0.0013835852732881904,
      "learning_rate": 2.4369551225791354e-05,
      "loss": 0.0003,
      "step": 10660
    },
    {
      "epoch": 16.829980276134123,
      "grad_norm": 0.002013215096667409,
      "learning_rate": 2.4340296062254987e-05,
      "loss": 0.0015,
      "step": 10670
    },
    {
      "epoch": 16.84575936883629,
      "grad_norm": 0.0009378216345794499,
      "learning_rate": 2.4311040898718628e-05,
      "loss": 0.0001,
      "step": 10680
    },
    {
      "epoch": 16.861538461538462,
      "grad_norm": 0.0011360106291249394,
      "learning_rate": 2.428178573518226e-05,
      "loss": 0.0035,
      "step": 10690
    },
    {
      "epoch": 16.87731755424063,
      "grad_norm": 0.0014536564704030752,
      "learning_rate": 2.4252530571645894e-05,
      "loss": 0.0144,
      "step": 10700
    },
    {
      "epoch": 16.8930966469428,
      "grad_norm": 0.018527207896113396,
      "learning_rate": 2.4223275408109534e-05,
      "loss": 0.0002,
      "step": 10710
    },
    {
      "epoch": 16.90887573964497,
      "grad_norm": 0.0013318851124495268,
      "learning_rate": 2.4194020244573168e-05,
      "loss": 0.0017,
      "step": 10720
    },
    {
      "epoch": 16.92465483234714,
      "grad_norm": 0.002198949456214905,
      "learning_rate": 2.4164765081036805e-05,
      "loss": 0.0003,
      "step": 10730
    },
    {
      "epoch": 16.94043392504931,
      "grad_norm": 0.00161993398796767,
      "learning_rate": 2.413550991750044e-05,
      "loss": 0.0008,
      "step": 10740
    },
    {
      "epoch": 16.95621301775148,
      "grad_norm": 0.007381064351648092,
      "learning_rate": 2.4106254753964075e-05,
      "loss": 0.0143,
      "step": 10750
    },
    {
      "epoch": 16.971992110453648,
      "grad_norm": 0.0018006126629188657,
      "learning_rate": 2.407699959042771e-05,
      "loss": 0.0001,
      "step": 10760
    },
    {
      "epoch": 16.98777120315582,
      "grad_norm": 0.001764865592122078,
      "learning_rate": 2.4047744426891348e-05,
      "loss": 0.0006,
      "step": 10770
    },
    {
      "epoch": 17.0,
      "eval_accuracy": 0.8769477816105626,
      "eval_loss": 0.8440099358558655,
      "eval_runtime": 207.3118,
      "eval_samples_per_second": 81.105,
      "eval_steps_per_second": 5.07,
      "step": 10778
    },
    {
      "epoch": 17.003155818540435,
      "grad_norm": 0.003965890500694513,
      "learning_rate": 2.4018489263354985e-05,
      "loss": 0.012,
      "step": 10780
    },
    {
      "epoch": 17.018934911242603,
      "grad_norm": 0.24228954315185547,
      "learning_rate": 2.398923409981862e-05,
      "loss": 0.0143,
      "step": 10790
    },
    {
      "epoch": 17.034714003944774,
      "grad_norm": 0.0026278861332684755,
      "learning_rate": 2.3959978936282255e-05,
      "loss": 0.0002,
      "step": 10800
    },
    {
      "epoch": 17.050493096646942,
      "grad_norm": 0.0032334132120013237,
      "learning_rate": 2.3930723772745892e-05,
      "loss": 0.0005,
      "step": 10810
    },
    {
      "epoch": 17.066272189349114,
      "grad_norm": 0.0029269715305417776,
      "learning_rate": 2.3901468609209525e-05,
      "loss": 0.0038,
      "step": 10820
    },
    {
      "epoch": 17.08205128205128,
      "grad_norm": 0.003140650922432542,
      "learning_rate": 2.3872213445673162e-05,
      "loss": 0.0002,
      "step": 10830
    },
    {
      "epoch": 17.097830374753453,
      "grad_norm": 0.008343193680047989,
      "learning_rate": 2.38429582821368e-05,
      "loss": 0.0096,
      "step": 10840
    },
    {
      "epoch": 17.11360946745562,
      "grad_norm": 0.0016207528533414006,
      "learning_rate": 2.3813703118600432e-05,
      "loss": 0.0105,
      "step": 10850
    },
    {
      "epoch": 17.129388560157793,
      "grad_norm": 0.12172874808311462,
      "learning_rate": 2.3784447955064072e-05,
      "loss": 0.0003,
      "step": 10860
    },
    {
      "epoch": 17.14516765285996,
      "grad_norm": 0.0020180426072329283,
      "learning_rate": 2.3755192791527706e-05,
      "loss": 0.0002,
      "step": 10870
    },
    {
      "epoch": 17.16094674556213,
      "grad_norm": 0.00154773925896734,
      "learning_rate": 2.372593762799134e-05,
      "loss": 0.0015,
      "step": 10880
    },
    {
      "epoch": 17.1767258382643,
      "grad_norm": 0.002427630592137575,
      "learning_rate": 2.369668246445498e-05,
      "loss": 0.0129,
      "step": 10890
    },
    {
      "epoch": 17.192504930966468,
      "grad_norm": 0.007945673540234566,
      "learning_rate": 2.3667427300918612e-05,
      "loss": 0.0002,
      "step": 10900
    },
    {
      "epoch": 17.20828402366864,
      "grad_norm": 0.13886819779872894,
      "learning_rate": 2.363817213738225e-05,
      "loss": 0.0011,
      "step": 10910
    },
    {
      "epoch": 17.224063116370807,
      "grad_norm": 0.0068458630703389645,
      "learning_rate": 2.3608916973845886e-05,
      "loss": 0.0021,
      "step": 10920
    },
    {
      "epoch": 17.23984220907298,
      "grad_norm": 0.0032145539298653603,
      "learning_rate": 2.357966181030952e-05,
      "loss": 0.0002,
      "step": 10930
    },
    {
      "epoch": 17.255621301775147,
      "grad_norm": 0.001457554055377841,
      "learning_rate": 2.3550406646773156e-05,
      "loss": 0.0002,
      "step": 10940
    },
    {
      "epoch": 17.27140039447732,
      "grad_norm": 0.0021320823580026627,
      "learning_rate": 2.3521151483236793e-05,
      "loss": 0.0003,
      "step": 10950
    },
    {
      "epoch": 17.287179487179486,
      "grad_norm": 0.001527238404378295,
      "learning_rate": 2.349189631970043e-05,
      "loss": 0.0002,
      "step": 10960
    },
    {
      "epoch": 17.302958579881658,
      "grad_norm": 0.003696333384141326,
      "learning_rate": 2.3462641156164063e-05,
      "loss": 0.0013,
      "step": 10970
    },
    {
      "epoch": 17.318737672583826,
      "grad_norm": 3.485599994659424,
      "learning_rate": 2.34333859926277e-05,
      "loss": 0.0053,
      "step": 10980
    },
    {
      "epoch": 17.334516765285997,
      "grad_norm": 0.07300885021686554,
      "learning_rate": 2.3404130829091336e-05,
      "loss": 0.0012,
      "step": 10990
    },
    {
      "epoch": 17.350295857988165,
      "grad_norm": 0.001517662894912064,
      "learning_rate": 2.337487566555497e-05,
      "loss": 0.0017,
      "step": 11000
    },
    {
      "epoch": 17.366074950690336,
      "grad_norm": 0.0010686094174161553,
      "learning_rate": 2.334562050201861e-05,
      "loss": 0.0004,
      "step": 11010
    },
    {
      "epoch": 17.381854043392504,
      "grad_norm": 0.0012465175241231918,
      "learning_rate": 2.3316365338482243e-05,
      "loss": 0.0001,
      "step": 11020
    },
    {
      "epoch": 17.397633136094676,
      "grad_norm": 0.0011339262127876282,
      "learning_rate": 2.3287110174945877e-05,
      "loss": 0.0002,
      "step": 11030
    },
    {
      "epoch": 17.413412228796844,
      "grad_norm": 0.0014225286431610584,
      "learning_rate": 2.3257855011409517e-05,
      "loss": 0.0001,
      "step": 11040
    },
    {
      "epoch": 17.429191321499015,
      "grad_norm": 0.0014513173373416066,
      "learning_rate": 2.322859984787315e-05,
      "loss": 0.0014,
      "step": 11050
    },
    {
      "epoch": 17.444970414201183,
      "grad_norm": 0.0009743675473146141,
      "learning_rate": 2.3199344684336787e-05,
      "loss": 0.0002,
      "step": 11060
    },
    {
      "epoch": 17.460749506903355,
      "grad_norm": 0.0024709170684218407,
      "learning_rate": 2.3170089520800424e-05,
      "loss": 0.0046,
      "step": 11070
    },
    {
      "epoch": 17.476528599605523,
      "grad_norm": 0.002480235183611512,
      "learning_rate": 2.3140834357264057e-05,
      "loss": 0.0001,
      "step": 11080
    },
    {
      "epoch": 17.49230769230769,
      "grad_norm": 0.001410090015269816,
      "learning_rate": 2.3111579193727694e-05,
      "loss": 0.0001,
      "step": 11090
    },
    {
      "epoch": 17.508086785009862,
      "grad_norm": 0.0023409035056829453,
      "learning_rate": 2.308232403019133e-05,
      "loss": 0.0002,
      "step": 11100
    },
    {
      "epoch": 17.52386587771203,
      "grad_norm": 0.0015815552324056625,
      "learning_rate": 2.3053068866654964e-05,
      "loss": 0.0006,
      "step": 11110
    },
    {
      "epoch": 17.5396449704142,
      "grad_norm": 0.01269581913948059,
      "learning_rate": 2.30238137031186e-05,
      "loss": 0.0005,
      "step": 11120
    },
    {
      "epoch": 17.55542406311637,
      "grad_norm": 0.000981411780230701,
      "learning_rate": 2.2994558539582237e-05,
      "loss": 0.0001,
      "step": 11130
    },
    {
      "epoch": 17.57120315581854,
      "grad_norm": 0.0016990635776892304,
      "learning_rate": 2.2965303376045874e-05,
      "loss": 0.0005,
      "step": 11140
    },
    {
      "epoch": 17.58698224852071,
      "grad_norm": 0.0011808726703748107,
      "learning_rate": 2.2936048212509508e-05,
      "loss": 0.0033,
      "step": 11150
    },
    {
      "epoch": 17.60276134122288,
      "grad_norm": 0.0023246430791914463,
      "learning_rate": 2.2906793048973144e-05,
      "loss": 0.0001,
      "step": 11160
    },
    {
      "epoch": 17.618540433925048,
      "grad_norm": 0.0021254962775856256,
      "learning_rate": 2.287753788543678e-05,
      "loss": 0.0019,
      "step": 11170
    },
    {
      "epoch": 17.63431952662722,
      "grad_norm": 0.004065992776304483,
      "learning_rate": 2.2848282721900414e-05,
      "loss": 0.0001,
      "step": 11180
    },
    {
      "epoch": 17.650098619329388,
      "grad_norm": 0.001059254864230752,
      "learning_rate": 2.2819027558364055e-05,
      "loss": 0.0001,
      "step": 11190
    },
    {
      "epoch": 17.66587771203156,
      "grad_norm": 0.041128166019916534,
      "learning_rate": 2.2789772394827688e-05,
      "loss": 0.0034,
      "step": 11200
    },
    {
      "epoch": 17.681656804733727,
      "grad_norm": 0.0014862656826153398,
      "learning_rate": 2.276051723129132e-05,
      "loss": 0.0015,
      "step": 11210
    },
    {
      "epoch": 17.6974358974359,
      "grad_norm": 0.0013500521890819073,
      "learning_rate": 2.273126206775496e-05,
      "loss": 0.0005,
      "step": 11220
    },
    {
      "epoch": 17.713214990138066,
      "grad_norm": 0.0010325182229280472,
      "learning_rate": 2.2702006904218595e-05,
      "loss": 0.0002,
      "step": 11230
    },
    {
      "epoch": 17.728994082840238,
      "grad_norm": 0.0009287115535698831,
      "learning_rate": 2.267275174068223e-05,
      "loss": 0.0124,
      "step": 11240
    },
    {
      "epoch": 17.744773175542406,
      "grad_norm": 0.0012921032030135393,
      "learning_rate": 2.2643496577145868e-05,
      "loss": 0.0001,
      "step": 11250
    },
    {
      "epoch": 17.760552268244577,
      "grad_norm": 0.001627807505428791,
      "learning_rate": 2.26142414136095e-05,
      "loss": 0.0002,
      "step": 11260
    },
    {
      "epoch": 17.776331360946745,
      "grad_norm": 0.0013090281281620264,
      "learning_rate": 2.258498625007314e-05,
      "loss": 0.0004,
      "step": 11270
    },
    {
      "epoch": 17.792110453648917,
      "grad_norm": 0.06745009124279022,
      "learning_rate": 2.2555731086536775e-05,
      "loss": 0.0002,
      "step": 11280
    },
    {
      "epoch": 17.807889546351085,
      "grad_norm": 0.0033813221380114555,
      "learning_rate": 2.2526475923000412e-05,
      "loss": 0.0019,
      "step": 11290
    },
    {
      "epoch": 17.823668639053256,
      "grad_norm": 0.002959426026791334,
      "learning_rate": 2.2497220759464045e-05,
      "loss": 0.0003,
      "step": 11300
    },
    {
      "epoch": 17.839447731755424,
      "grad_norm": 0.0019706515595316887,
      "learning_rate": 2.2467965595927682e-05,
      "loss": 0.0001,
      "step": 11310
    },
    {
      "epoch": 17.855226824457592,
      "grad_norm": 0.001563398982398212,
      "learning_rate": 2.243871043239132e-05,
      "loss": 0.0015,
      "step": 11320
    },
    {
      "epoch": 17.871005917159763,
      "grad_norm": 0.0011744771618396044,
      "learning_rate": 2.2409455268854952e-05,
      "loss": 0.0001,
      "step": 11330
    },
    {
      "epoch": 17.88678500986193,
      "grad_norm": 0.0015152891865000129,
      "learning_rate": 2.2380200105318592e-05,
      "loss": 0.0001,
      "step": 11340
    },
    {
      "epoch": 17.902564102564103,
      "grad_norm": 0.0014943269779905677,
      "learning_rate": 2.2350944941782226e-05,
      "loss": 0.0001,
      "step": 11350
    },
    {
      "epoch": 17.91834319526627,
      "grad_norm": 0.0009056292474269867,
      "learning_rate": 2.232168977824586e-05,
      "loss": 0.0002,
      "step": 11360
    },
    {
      "epoch": 17.934122287968442,
      "grad_norm": 0.0007182430708780885,
      "learning_rate": 2.22924346147095e-05,
      "loss": 0.0001,
      "step": 11370
    },
    {
      "epoch": 17.94990138067061,
      "grad_norm": 0.00091660360340029,
      "learning_rate": 2.2263179451173133e-05,
      "loss": 0.0019,
      "step": 11380
    },
    {
      "epoch": 17.96568047337278,
      "grad_norm": 0.00109160749707371,
      "learning_rate": 2.223392428763677e-05,
      "loss": 0.0001,
      "step": 11390
    },
    {
      "epoch": 17.98145956607495,
      "grad_norm": 0.0010624012211337686,
      "learning_rate": 2.2204669124100406e-05,
      "loss": 0.0001,
      "step": 11400
    },
    {
      "epoch": 17.99723865877712,
      "grad_norm": 0.044236231595277786,
      "learning_rate": 2.217541396056404e-05,
      "loss": 0.0006,
      "step": 11410
    },
    {
      "epoch": 18.0,
      "eval_accuracy": 0.88914000237897,
      "eval_loss": 0.8785476088523865,
      "eval_runtime": 206.4768,
      "eval_samples_per_second": 81.433,
      "eval_steps_per_second": 5.09,
      "step": 11412
    },
    {
      "epoch": 18.012623274161736,
      "grad_norm": 0.0011520360130816698,
      "learning_rate": 2.2146158797027676e-05,
      "loss": 0.0005,
      "step": 11420
    },
    {
      "epoch": 18.028402366863904,
      "grad_norm": 0.09601908922195435,
      "learning_rate": 2.2116903633491313e-05,
      "loss": 0.0013,
      "step": 11430
    },
    {
      "epoch": 18.044181459566076,
      "grad_norm": 0.0010930048301815987,
      "learning_rate": 2.2087648469954946e-05,
      "loss": 0.0001,
      "step": 11440
    },
    {
      "epoch": 18.059960552268244,
      "grad_norm": 0.0010031842393800616,
      "learning_rate": 2.2058393306418583e-05,
      "loss": 0.0129,
      "step": 11450
    },
    {
      "epoch": 18.075739644970415,
      "grad_norm": 0.0014818841591477394,
      "learning_rate": 2.202913814288222e-05,
      "loss": 0.0001,
      "step": 11460
    },
    {
      "epoch": 18.091518737672583,
      "grad_norm": 0.0013625845313072205,
      "learning_rate": 2.1999882979345857e-05,
      "loss": 0.0001,
      "step": 11470
    },
    {
      "epoch": 18.107297830374755,
      "grad_norm": 0.0865037739276886,
      "learning_rate": 2.197062781580949e-05,
      "loss": 0.0019,
      "step": 11480
    },
    {
      "epoch": 18.123076923076923,
      "grad_norm": 0.0011803985107690096,
      "learning_rate": 2.1941372652273127e-05,
      "loss": 0.0001,
      "step": 11490
    },
    {
      "epoch": 18.138856015779094,
      "grad_norm": 0.0008628918440081179,
      "learning_rate": 2.1912117488736763e-05,
      "loss": 0.0001,
      "step": 11500
    },
    {
      "epoch": 18.154635108481262,
      "grad_norm": 0.0015390426851809025,
      "learning_rate": 2.1882862325200397e-05,
      "loss": 0.0001,
      "step": 11510
    },
    {
      "epoch": 18.170414201183434,
      "grad_norm": 0.0008061094558797777,
      "learning_rate": 2.1853607161664037e-05,
      "loss": 0.0019,
      "step": 11520
    },
    {
      "epoch": 18.1861932938856,
      "grad_norm": 0.0013881236081942916,
      "learning_rate": 2.182435199812767e-05,
      "loss": 0.0015,
      "step": 11530
    },
    {
      "epoch": 18.201972386587773,
      "grad_norm": 0.0008661795291118324,
      "learning_rate": 2.1795096834591307e-05,
      "loss": 0.0001,
      "step": 11540
    },
    {
      "epoch": 18.21775147928994,
      "grad_norm": 0.000994325615465641,
      "learning_rate": 2.1765841671054944e-05,
      "loss": 0.0005,
      "step": 11550
    },
    {
      "epoch": 18.23353057199211,
      "grad_norm": 0.0025493830908089876,
      "learning_rate": 2.1736586507518577e-05,
      "loss": 0.0001,
      "step": 11560
    },
    {
      "epoch": 18.24930966469428,
      "grad_norm": 0.0017397572519257665,
      "learning_rate": 2.1707331343982214e-05,
      "loss": 0.0012,
      "step": 11570
    },
    {
      "epoch": 18.265088757396448,
      "grad_norm": 0.0017929661553353071,
      "learning_rate": 2.167807618044585e-05,
      "loss": 0.0014,
      "step": 11580
    },
    {
      "epoch": 18.28086785009862,
      "grad_norm": 0.0014382668305188417,
      "learning_rate": 2.1648821016909484e-05,
      "loss": 0.0003,
      "step": 11590
    },
    {
      "epoch": 18.296646942800788,
      "grad_norm": 0.0007526465342380106,
      "learning_rate": 2.161956585337312e-05,
      "loss": 0.0001,
      "step": 11600
    },
    {
      "epoch": 18.31242603550296,
      "grad_norm": 0.0011220122687518597,
      "learning_rate": 2.1590310689836757e-05,
      "loss": 0.0001,
      "step": 11610
    },
    {
      "epoch": 18.328205128205127,
      "grad_norm": 0.0009869628120213747,
      "learning_rate": 2.1561055526300394e-05,
      "loss": 0.0001,
      "step": 11620
    },
    {
      "epoch": 18.3439842209073,
      "grad_norm": 0.0017691456014290452,
      "learning_rate": 2.1531800362764028e-05,
      "loss": 0.0001,
      "step": 11630
    },
    {
      "epoch": 18.359763313609466,
      "grad_norm": 0.0011863172985613346,
      "learning_rate": 2.1502545199227664e-05,
      "loss": 0.0001,
      "step": 11640
    },
    {
      "epoch": 18.375542406311638,
      "grad_norm": 0.0012591694248840213,
      "learning_rate": 2.14732900356913e-05,
      "loss": 0.001,
      "step": 11650
    },
    {
      "epoch": 18.391321499013806,
      "grad_norm": 0.0006253356114029884,
      "learning_rate": 2.1444034872154934e-05,
      "loss": 0.0001,
      "step": 11660
    },
    {
      "epoch": 18.407100591715977,
      "grad_norm": 0.0012020764406770468,
      "learning_rate": 2.141477970861857e-05,
      "loss": 0.0001,
      "step": 11670
    },
    {
      "epoch": 18.422879684418145,
      "grad_norm": 0.0008731817943044007,
      "learning_rate": 2.1385524545082208e-05,
      "loss": 0.0001,
      "step": 11680
    },
    {
      "epoch": 18.438658777120317,
      "grad_norm": 0.0010452878195792437,
      "learning_rate": 2.1356269381545845e-05,
      "loss": 0.0001,
      "step": 11690
    },
    {
      "epoch": 18.454437869822485,
      "grad_norm": 0.0009173604194074869,
      "learning_rate": 2.132701421800948e-05,
      "loss": 0.0001,
      "step": 11700
    },
    {
      "epoch": 18.470216962524656,
      "grad_norm": 0.03597741946578026,
      "learning_rate": 2.1297759054473115e-05,
      "loss": 0.0004,
      "step": 11710
    },
    {
      "epoch": 18.485996055226824,
      "grad_norm": 0.0041304221376776695,
      "learning_rate": 2.126850389093675e-05,
      "loss": 0.0004,
      "step": 11720
    },
    {
      "epoch": 18.501775147928996,
      "grad_norm": 0.0006562511553056538,
      "learning_rate": 2.123924872740039e-05,
      "loss": 0.0001,
      "step": 11730
    },
    {
      "epoch": 18.517554240631164,
      "grad_norm": 0.0008934370125643909,
      "learning_rate": 2.1209993563864022e-05,
      "loss": 0.0001,
      "step": 11740
    },
    {
      "epoch": 18.533333333333335,
      "grad_norm": 0.0008368941489607096,
      "learning_rate": 2.118073840032766e-05,
      "loss": 0.0013,
      "step": 11750
    },
    {
      "epoch": 18.549112426035503,
      "grad_norm": 0.0026474460028111935,
      "learning_rate": 2.1151483236791295e-05,
      "loss": 0.0001,
      "step": 11760
    },
    {
      "epoch": 18.564891518737674,
      "grad_norm": 0.0009643069934099913,
      "learning_rate": 2.112222807325493e-05,
      "loss": 0.0001,
      "step": 11770
    },
    {
      "epoch": 18.580670611439842,
      "grad_norm": 0.0007810186943970621,
      "learning_rate": 2.1092972909718565e-05,
      "loss": 0.0001,
      "step": 11780
    },
    {
      "epoch": 18.59644970414201,
      "grad_norm": 0.0006108221714384854,
      "learning_rate": 2.1063717746182202e-05,
      "loss": 0.0005,
      "step": 11790
    },
    {
      "epoch": 18.61222879684418,
      "grad_norm": 0.000679858319927007,
      "learning_rate": 2.103446258264584e-05,
      "loss": 0.0001,
      "step": 11800
    },
    {
      "epoch": 18.62800788954635,
      "grad_norm": 0.000875591766089201,
      "learning_rate": 2.1005207419109472e-05,
      "loss": 0.0001,
      "step": 11810
    },
    {
      "epoch": 18.64378698224852,
      "grad_norm": 0.0006902972818352282,
      "learning_rate": 2.097595225557311e-05,
      "loss": 0.0179,
      "step": 11820
    },
    {
      "epoch": 18.65956607495069,
      "grad_norm": 0.0013575454941019416,
      "learning_rate": 2.0946697092036746e-05,
      "loss": 0.0069,
      "step": 11830
    },
    {
      "epoch": 18.67534516765286,
      "grad_norm": 0.07695122808218002,
      "learning_rate": 2.0917441928500382e-05,
      "loss": 0.0002,
      "step": 11840
    },
    {
      "epoch": 18.69112426035503,
      "grad_norm": 0.00795116275548935,
      "learning_rate": 2.088818676496402e-05,
      "loss": 0.0023,
      "step": 11850
    },
    {
      "epoch": 18.7069033530572,
      "grad_norm": 0.0018883143784478307,
      "learning_rate": 2.0858931601427653e-05,
      "loss": 0.0001,
      "step": 11860
    },
    {
      "epoch": 18.722682445759368,
      "grad_norm": 2.4513628482818604,
      "learning_rate": 2.082967643789129e-05,
      "loss": 0.0076,
      "step": 11870
    },
    {
      "epoch": 18.73846153846154,
      "grad_norm": 0.0014743655920028687,
      "learning_rate": 2.0800421274354926e-05,
      "loss": 0.0016,
      "step": 11880
    },
    {
      "epoch": 18.754240631163707,
      "grad_norm": 0.001154428580775857,
      "learning_rate": 2.077116611081856e-05,
      "loss": 0.0009,
      "step": 11890
    },
    {
      "epoch": 18.77001972386588,
      "grad_norm": 0.0010715071111917496,
      "learning_rate": 2.0741910947282196e-05,
      "loss": 0.0001,
      "step": 11900
    },
    {
      "epoch": 18.785798816568047,
      "grad_norm": 0.0021244999952614307,
      "learning_rate": 2.0712655783745833e-05,
      "loss": 0.0108,
      "step": 11910
    },
    {
      "epoch": 18.801577909270218,
      "grad_norm": 0.0009748671436682343,
      "learning_rate": 2.0683400620209466e-05,
      "loss": 0.0001,
      "step": 11920
    },
    {
      "epoch": 18.817357001972386,
      "grad_norm": 0.017171049490571022,
      "learning_rate": 2.0654145456673103e-05,
      "loss": 0.0002,
      "step": 11930
    },
    {
      "epoch": 18.833136094674558,
      "grad_norm": 0.0009355476940982044,
      "learning_rate": 2.062489029313674e-05,
      "loss": 0.0003,
      "step": 11940
    },
    {
      "epoch": 18.848915187376726,
      "grad_norm": 0.0025562734808772802,
      "learning_rate": 2.0595635129600373e-05,
      "loss": 0.0002,
      "step": 11950
    },
    {
      "epoch": 18.864694280078897,
      "grad_norm": 0.0014101974666118622,
      "learning_rate": 2.056637996606401e-05,
      "loss": 0.0001,
      "step": 11960
    },
    {
      "epoch": 18.880473372781065,
      "grad_norm": 0.0011642780154943466,
      "learning_rate": 2.0537124802527647e-05,
      "loss": 0.0002,
      "step": 11970
    },
    {
      "epoch": 18.896252465483236,
      "grad_norm": 0.04376600310206413,
      "learning_rate": 2.0507869638991283e-05,
      "loss": 0.0002,
      "step": 11980
    },
    {
      "epoch": 18.912031558185404,
      "grad_norm": 0.006503593642264605,
      "learning_rate": 2.047861447545492e-05,
      "loss": 0.0009,
      "step": 11990
    },
    {
      "epoch": 18.927810650887572,
      "grad_norm": 0.003861058969050646,
      "learning_rate": 2.0449359311918554e-05,
      "loss": 0.0022,
      "step": 12000
    },
    {
      "epoch": 18.943589743589744,
      "grad_norm": 0.07910457253456116,
      "learning_rate": 2.042010414838219e-05,
      "loss": 0.0003,
      "step": 12010
    },
    {
      "epoch": 18.95936883629191,
      "grad_norm": 0.0025116608012467623,
      "learning_rate": 2.0390848984845827e-05,
      "loss": 0.0016,
      "step": 12020
    },
    {
      "epoch": 18.975147928994083,
      "grad_norm": 0.001824497478082776,
      "learning_rate": 2.0361593821309464e-05,
      "loss": 0.0001,
      "step": 12030
    },
    {
      "epoch": 18.99092702169625,
      "grad_norm": 0.0011124125448986888,
      "learning_rate": 2.0332338657773097e-05,
      "loss": 0.0013,
      "step": 12040
    },
    {
      "epoch": 19.0,
      "eval_accuracy": 0.8768883073629119,
      "eval_loss": 0.8764836192131042,
      "eval_runtime": 214.7764,
      "eval_samples_per_second": 78.286,
      "eval_steps_per_second": 4.893,
      "step": 12046
    },
    {
      "epoch": 19.006311637080866,
      "grad_norm": 0.0011214723344892263,
      "learning_rate": 2.0303083494236734e-05,
      "loss": 0.0001,
      "step": 12050
    },
    {
      "epoch": 19.022090729783038,
      "grad_norm": 0.001675367122516036,
      "learning_rate": 2.027382833070037e-05,
      "loss": 0.0001,
      "step": 12060
    },
    {
      "epoch": 19.037869822485206,
      "grad_norm": 0.0007620393298566341,
      "learning_rate": 2.0244573167164004e-05,
      "loss": 0.0001,
      "step": 12070
    },
    {
      "epoch": 19.053648915187377,
      "grad_norm": 0.000986015540547669,
      "learning_rate": 2.021531800362764e-05,
      "loss": 0.0001,
      "step": 12080
    },
    {
      "epoch": 19.069428007889545,
      "grad_norm": 0.0008722713100723922,
      "learning_rate": 2.0186062840091278e-05,
      "loss": 0.0001,
      "step": 12090
    },
    {
      "epoch": 19.085207100591717,
      "grad_norm": 0.033150289207696915,
      "learning_rate": 2.015680767655491e-05,
      "loss": 0.0001,
      "step": 12100
    },
    {
      "epoch": 19.100986193293885,
      "grad_norm": 0.0019766490440815687,
      "learning_rate": 2.0127552513018548e-05,
      "loss": 0.0001,
      "step": 12110
    },
    {
      "epoch": 19.116765285996056,
      "grad_norm": 0.002571062184870243,
      "learning_rate": 2.0098297349482184e-05,
      "loss": 0.0001,
      "step": 12120
    },
    {
      "epoch": 19.132544378698224,
      "grad_norm": 0.004433928523212671,
      "learning_rate": 2.006904218594582e-05,
      "loss": 0.0001,
      "step": 12130
    },
    {
      "epoch": 19.148323471400396,
      "grad_norm": 0.0007761489832773805,
      "learning_rate": 2.0039787022409458e-05,
      "loss": 0.0001,
      "step": 12140
    },
    {
      "epoch": 19.164102564102564,
      "grad_norm": 0.0005743852816522121,
      "learning_rate": 2.001053185887309e-05,
      "loss": 0.0001,
      "step": 12150
    },
    {
      "epoch": 19.179881656804735,
      "grad_norm": 0.001339196809567511,
      "learning_rate": 1.9981276695336728e-05,
      "loss": 0.002,
      "step": 12160
    },
    {
      "epoch": 19.195660749506903,
      "grad_norm": 0.0012394001241773367,
      "learning_rate": 1.9952021531800365e-05,
      "loss": 0.0001,
      "step": 12170
    },
    {
      "epoch": 19.211439842209074,
      "grad_norm": 0.00094693957362324,
      "learning_rate": 1.9922766368264e-05,
      "loss": 0.0001,
      "step": 12180
    },
    {
      "epoch": 19.227218934911242,
      "grad_norm": 0.0007691420032642782,
      "learning_rate": 1.9893511204727635e-05,
      "loss": 0.0001,
      "step": 12190
    },
    {
      "epoch": 19.242998027613414,
      "grad_norm": 0.003781836247071624,
      "learning_rate": 1.9864256041191272e-05,
      "loss": 0.0003,
      "step": 12200
    },
    {
      "epoch": 19.25877712031558,
      "grad_norm": 0.0007541784434579313,
      "learning_rate": 1.983500087765491e-05,
      "loss": 0.0001,
      "step": 12210
    },
    {
      "epoch": 19.274556213017753,
      "grad_norm": 0.00249687978066504,
      "learning_rate": 1.9805745714118542e-05,
      "loss": 0.0001,
      "step": 12220
    },
    {
      "epoch": 19.29033530571992,
      "grad_norm": 0.0008758215699344873,
      "learning_rate": 1.977649055058218e-05,
      "loss": 0.0101,
      "step": 12230
    },
    {
      "epoch": 19.30611439842209,
      "grad_norm": 0.08150944858789444,
      "learning_rate": 1.9747235387045815e-05,
      "loss": 0.0025,
      "step": 12240
    },
    {
      "epoch": 19.32189349112426,
      "grad_norm": 0.08978661149740219,
      "learning_rate": 1.971798022350945e-05,
      "loss": 0.0014,
      "step": 12250
    },
    {
      "epoch": 19.33767258382643,
      "grad_norm": 0.0012419502018019557,
      "learning_rate": 1.968872505997309e-05,
      "loss": 0.0022,
      "step": 12260
    },
    {
      "epoch": 19.3534516765286,
      "grad_norm": 0.0013878503814339638,
      "learning_rate": 1.9659469896436722e-05,
      "loss": 0.0004,
      "step": 12270
    },
    {
      "epoch": 19.369230769230768,
      "grad_norm": 0.001936810789629817,
      "learning_rate": 1.9630214732900356e-05,
      "loss": 0.0001,
      "step": 12280
    },
    {
      "epoch": 19.38500986193294,
      "grad_norm": 0.010955074802041054,
      "learning_rate": 1.9600959569363996e-05,
      "loss": 0.0001,
      "step": 12290
    },
    {
      "epoch": 19.400788954635107,
      "grad_norm": 0.0007072204607538879,
      "learning_rate": 1.957170440582763e-05,
      "loss": 0.0001,
      "step": 12300
    },
    {
      "epoch": 19.41656804733728,
      "grad_norm": 0.0007770195952616632,
      "learning_rate": 1.9542449242291266e-05,
      "loss": 0.0001,
      "step": 12310
    },
    {
      "epoch": 19.432347140039447,
      "grad_norm": 0.0006655319011770189,
      "learning_rate": 1.9513194078754903e-05,
      "loss": 0.0001,
      "step": 12320
    },
    {
      "epoch": 19.44812623274162,
      "grad_norm": 0.0010732227237895131,
      "learning_rate": 1.9483938915218536e-05,
      "loss": 0.0017,
      "step": 12330
    },
    {
      "epoch": 19.463905325443786,
      "grad_norm": 0.09034194052219391,
      "learning_rate": 1.9454683751682173e-05,
      "loss": 0.0001,
      "step": 12340
    },
    {
      "epoch": 19.479684418145958,
      "grad_norm": 0.0006494965637102723,
      "learning_rate": 1.942542858814581e-05,
      "loss": 0.0001,
      "step": 12350
    },
    {
      "epoch": 19.495463510848126,
      "grad_norm": 0.002867910312488675,
      "learning_rate": 1.9396173424609446e-05,
      "loss": 0.0105,
      "step": 12360
    },
    {
      "epoch": 19.511242603550297,
      "grad_norm": 0.0009036939009092748,
      "learning_rate": 1.936691826107308e-05,
      "loss": 0.0014,
      "step": 12370
    },
    {
      "epoch": 19.527021696252465,
      "grad_norm": 0.008633827790617943,
      "learning_rate": 1.9337663097536716e-05,
      "loss": 0.0001,
      "step": 12380
    },
    {
      "epoch": 19.542800788954636,
      "grad_norm": 0.000797463464550674,
      "learning_rate": 1.9308407934000353e-05,
      "loss": 0.0024,
      "step": 12390
    },
    {
      "epoch": 19.558579881656804,
      "grad_norm": 0.0011750194244086742,
      "learning_rate": 1.9279152770463986e-05,
      "loss": 0.0001,
      "step": 12400
    },
    {
      "epoch": 19.574358974358976,
      "grad_norm": 0.41875308752059937,
      "learning_rate": 1.9249897606927627e-05,
      "loss": 0.0058,
      "step": 12410
    },
    {
      "epoch": 19.590138067061144,
      "grad_norm": 0.005283131264150143,
      "learning_rate": 1.922064244339126e-05,
      "loss": 0.0001,
      "step": 12420
    },
    {
      "epoch": 19.605917159763315,
      "grad_norm": 0.0007055127061903477,
      "learning_rate": 1.9191387279854893e-05,
      "loss": 0.0097,
      "step": 12430
    },
    {
      "epoch": 19.621696252465483,
      "grad_norm": 0.0007140010129660368,
      "learning_rate": 1.9162132116318533e-05,
      "loss": 0.0001,
      "step": 12440
    },
    {
      "epoch": 19.63747534516765,
      "grad_norm": 0.0009759814711287618,
      "learning_rate": 1.9132876952782167e-05,
      "loss": 0.0005,
      "step": 12450
    },
    {
      "epoch": 19.653254437869823,
      "grad_norm": 0.000694629386998713,
      "learning_rate": 1.9103621789245804e-05,
      "loss": 0.0005,
      "step": 12460
    },
    {
      "epoch": 19.66903353057199,
      "grad_norm": 0.0019198325462639332,
      "learning_rate": 1.907436662570944e-05,
      "loss": 0.0109,
      "step": 12470
    },
    {
      "epoch": 19.684812623274162,
      "grad_norm": 0.0007955427281558514,
      "learning_rate": 1.9045111462173074e-05,
      "loss": 0.0008,
      "step": 12480
    },
    {
      "epoch": 19.70059171597633,
      "grad_norm": 0.0007152442121878266,
      "learning_rate": 1.901585629863671e-05,
      "loss": 0.0103,
      "step": 12490
    },
    {
      "epoch": 19.7163708086785,
      "grad_norm": 0.0018206307431682944,
      "learning_rate": 1.8986601135100347e-05,
      "loss": 0.0001,
      "step": 12500
    },
    {
      "epoch": 19.73214990138067,
      "grad_norm": 0.0006569172837771475,
      "learning_rate": 1.895734597156398e-05,
      "loss": 0.0009,
      "step": 12510
    },
    {
      "epoch": 19.74792899408284,
      "grad_norm": 0.0024701773654669523,
      "learning_rate": 1.8928090808027617e-05,
      "loss": 0.0028,
      "step": 12520
    },
    {
      "epoch": 19.76370808678501,
      "grad_norm": 0.0013219339307397604,
      "learning_rate": 1.8898835644491254e-05,
      "loss": 0.0021,
      "step": 12530
    },
    {
      "epoch": 19.77948717948718,
      "grad_norm": 0.023130279034376144,
      "learning_rate": 1.886958048095489e-05,
      "loss": 0.0005,
      "step": 12540
    },
    {
      "epoch": 19.795266272189348,
      "grad_norm": 0.001736533478833735,
      "learning_rate": 1.8840325317418524e-05,
      "loss": 0.0004,
      "step": 12550
    },
    {
      "epoch": 19.81104536489152,
      "grad_norm": 0.6152355670928955,
      "learning_rate": 1.881107015388216e-05,
      "loss": 0.0047,
      "step": 12560
    },
    {
      "epoch": 19.826824457593688,
      "grad_norm": 0.0007819945458322763,
      "learning_rate": 1.8781814990345798e-05,
      "loss": 0.0001,
      "step": 12570
    },
    {
      "epoch": 19.84260355029586,
      "grad_norm": 0.002170632826164365,
      "learning_rate": 1.875255982680943e-05,
      "loss": 0.0015,
      "step": 12580
    },
    {
      "epoch": 19.858382642998027,
      "grad_norm": 0.005364635959267616,
      "learning_rate": 1.872330466327307e-05,
      "loss": 0.0001,
      "step": 12590
    },
    {
      "epoch": 19.8741617357002,
      "grad_norm": 0.021232513710856438,
      "learning_rate": 1.8694049499736705e-05,
      "loss": 0.0001,
      "step": 12600
    },
    {
      "epoch": 19.889940828402366,
      "grad_norm": 0.0010772538371384144,
      "learning_rate": 1.8664794336200338e-05,
      "loss": 0.0004,
      "step": 12610
    },
    {
      "epoch": 19.905719921104538,
      "grad_norm": 0.5581509470939636,
      "learning_rate": 1.8635539172663978e-05,
      "loss": 0.0005,
      "step": 12620
    },
    {
      "epoch": 19.921499013806706,
      "grad_norm": 0.0018211710266768932,
      "learning_rate": 1.860628400912761e-05,
      "loss": 0.0001,
      "step": 12630
    },
    {
      "epoch": 19.937278106508877,
      "grad_norm": 0.03292449936270714,
      "learning_rate": 1.8577028845591248e-05,
      "loss": 0.0002,
      "step": 12640
    },
    {
      "epoch": 19.953057199211045,
      "grad_norm": 0.0017975236987695098,
      "learning_rate": 1.8547773682054885e-05,
      "loss": 0.0006,
      "step": 12650
    },
    {
      "epoch": 19.968836291913213,
      "grad_norm": 0.05617338791489601,
      "learning_rate": 1.8518518518518518e-05,
      "loss": 0.0103,
      "step": 12660
    },
    {
      "epoch": 19.984615384615385,
      "grad_norm": 0.011479460634291172,
      "learning_rate": 1.8489263354982155e-05,
      "loss": 0.0003,
      "step": 12670
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.005936086177825928,
      "learning_rate": 1.8460008191445792e-05,
      "loss": 0.0054,
      "step": 12680
    },
    {
      "epoch": 20.0,
      "eval_accuracy": 0.8810515046984656,
      "eval_loss": 0.9462915658950806,
      "eval_runtime": 199.7758,
      "eval_samples_per_second": 84.164,
      "eval_steps_per_second": 5.261,
      "step": 12680
    },
    {
      "epoch": 20.015779092702168,
      "grad_norm": 0.001877986011095345,
      "learning_rate": 1.843075302790943e-05,
      "loss": 0.0001,
      "step": 12690
    },
    {
      "epoch": 20.03155818540434,
      "grad_norm": 0.0006111566326580942,
      "learning_rate": 1.8401497864373062e-05,
      "loss": 0.0008,
      "step": 12700
    },
    {
      "epoch": 20.047337278106507,
      "grad_norm": 0.017442328855395317,
      "learning_rate": 1.83722427008367e-05,
      "loss": 0.0001,
      "step": 12710
    },
    {
      "epoch": 20.06311637080868,
      "grad_norm": 0.0013680835254490376,
      "learning_rate": 1.8342987537300335e-05,
      "loss": 0.0027,
      "step": 12720
    },
    {
      "epoch": 20.078895463510847,
      "grad_norm": 0.005080795381218195,
      "learning_rate": 1.831373237376397e-05,
      "loss": 0.0001,
      "step": 12730
    },
    {
      "epoch": 20.09467455621302,
      "grad_norm": 0.0013635718496516347,
      "learning_rate": 1.828447721022761e-05,
      "loss": 0.0001,
      "step": 12740
    },
    {
      "epoch": 20.110453648915186,
      "grad_norm": 0.0009973769774660468,
      "learning_rate": 1.8255222046691242e-05,
      "loss": 0.0002,
      "step": 12750
    },
    {
      "epoch": 20.126232741617358,
      "grad_norm": 0.0007384013733826578,
      "learning_rate": 1.8225966883154876e-05,
      "loss": 0.0009,
      "step": 12760
    },
    {
      "epoch": 20.142011834319526,
      "grad_norm": 0.0011519077233970165,
      "learning_rate": 1.8196711719618516e-05,
      "loss": 0.0001,
      "step": 12770
    },
    {
      "epoch": 20.157790927021697,
      "grad_norm": 0.0039540845900774,
      "learning_rate": 1.816745655608215e-05,
      "loss": 0.0009,
      "step": 12780
    },
    {
      "epoch": 20.173570019723865,
      "grad_norm": 0.0010152424219995737,
      "learning_rate": 1.8138201392545783e-05,
      "loss": 0.0001,
      "step": 12790
    },
    {
      "epoch": 20.189349112426036,
      "grad_norm": 0.0007971201557666063,
      "learning_rate": 1.8108946229009423e-05,
      "loss": 0.0008,
      "step": 12800
    },
    {
      "epoch": 20.205128205128204,
      "grad_norm": 0.011436035856604576,
      "learning_rate": 1.8079691065473056e-05,
      "loss": 0.0018,
      "step": 12810
    },
    {
      "epoch": 20.220907297830376,
      "grad_norm": 0.002828844590112567,
      "learning_rate": 1.8050435901936693e-05,
      "loss": 0.0001,
      "step": 12820
    },
    {
      "epoch": 20.236686390532544,
      "grad_norm": 0.0014287852682173252,
      "learning_rate": 1.802118073840033e-05,
      "loss": 0.0001,
      "step": 12830
    },
    {
      "epoch": 20.252465483234715,
      "grad_norm": 0.003527109045535326,
      "learning_rate": 1.7991925574863963e-05,
      "loss": 0.0001,
      "step": 12840
    },
    {
      "epoch": 20.268244575936883,
      "grad_norm": 0.00509853707626462,
      "learning_rate": 1.79626704113276e-05,
      "loss": 0.0145,
      "step": 12850
    },
    {
      "epoch": 20.284023668639055,
      "grad_norm": 0.002860173350200057,
      "learning_rate": 1.7933415247791236e-05,
      "loss": 0.0003,
      "step": 12860
    },
    {
      "epoch": 20.299802761341223,
      "grad_norm": 0.013797259889543056,
      "learning_rate": 1.7904160084254873e-05,
      "loss": 0.0001,
      "step": 12870
    },
    {
      "epoch": 20.315581854043394,
      "grad_norm": 3.2527806758880615,
      "learning_rate": 1.7874904920718507e-05,
      "loss": 0.0056,
      "step": 12880
    },
    {
      "epoch": 20.331360946745562,
      "grad_norm": 0.0009077066788449883,
      "learning_rate": 1.7845649757182143e-05,
      "loss": 0.0009,
      "step": 12890
    },
    {
      "epoch": 20.34714003944773,
      "grad_norm": 0.002198333153501153,
      "learning_rate": 1.781639459364578e-05,
      "loss": 0.0002,
      "step": 12900
    },
    {
      "epoch": 20.3629191321499,
      "grad_norm": 0.0012105301721021533,
      "learning_rate": 1.7787139430109413e-05,
      "loss": 0.0015,
      "step": 12910
    },
    {
      "epoch": 20.37869822485207,
      "grad_norm": 0.0032419394701719284,
      "learning_rate": 1.7757884266573054e-05,
      "loss": 0.0001,
      "step": 12920
    },
    {
      "epoch": 20.39447731755424,
      "grad_norm": 0.0008222091128118336,
      "learning_rate": 1.7728629103036687e-05,
      "loss": 0.0001,
      "step": 12930
    },
    {
      "epoch": 20.41025641025641,
      "grad_norm": 0.0049181473441421986,
      "learning_rate": 1.769937393950032e-05,
      "loss": 0.0001,
      "step": 12940
    },
    {
      "epoch": 20.42603550295858,
      "grad_norm": 0.002351177390664816,
      "learning_rate": 1.767011877596396e-05,
      "loss": 0.0008,
      "step": 12950
    },
    {
      "epoch": 20.441814595660748,
      "grad_norm": 0.0063001541420817375,
      "learning_rate": 1.7640863612427594e-05,
      "loss": 0.0015,
      "step": 12960
    },
    {
      "epoch": 20.45759368836292,
      "grad_norm": 0.001530217006802559,
      "learning_rate": 1.761160844889123e-05,
      "loss": 0.0002,
      "step": 12970
    },
    {
      "epoch": 20.473372781065088,
      "grad_norm": 0.0041615222580730915,
      "learning_rate": 1.7582353285354867e-05,
      "loss": 0.0001,
      "step": 12980
    },
    {
      "epoch": 20.48915187376726,
      "grad_norm": 0.0030245506204664707,
      "learning_rate": 1.75530981218185e-05,
      "loss": 0.0001,
      "step": 12990
    },
    {
      "epoch": 20.504930966469427,
      "grad_norm": 0.000839400861877948,
      "learning_rate": 1.7523842958282137e-05,
      "loss": 0.0012,
      "step": 13000
    },
    {
      "epoch": 20.5207100591716,
      "grad_norm": 0.0008980403072200716,
      "learning_rate": 1.7494587794745774e-05,
      "loss": 0.0017,
      "step": 13010
    },
    {
      "epoch": 20.536489151873766,
      "grad_norm": 0.002006376162171364,
      "learning_rate": 1.746533263120941e-05,
      "loss": 0.0059,
      "step": 13020
    },
    {
      "epoch": 20.552268244575938,
      "grad_norm": 0.0009087208309210837,
      "learning_rate": 1.7436077467673044e-05,
      "loss": 0.002,
      "step": 13030
    },
    {
      "epoch": 20.568047337278106,
      "grad_norm": 0.0010553263127803802,
      "learning_rate": 1.740682230413668e-05,
      "loss": 0.0027,
      "step": 13040
    },
    {
      "epoch": 20.583826429980277,
      "grad_norm": 0.0018632098799571395,
      "learning_rate": 1.7377567140600318e-05,
      "loss": 0.0001,
      "step": 13050
    },
    {
      "epoch": 20.599605522682445,
      "grad_norm": 0.0009894628310576081,
      "learning_rate": 1.734831197706395e-05,
      "loss": 0.0001,
      "step": 13060
    },
    {
      "epoch": 20.615384615384617,
      "grad_norm": 0.0010665232548490167,
      "learning_rate": 1.7319056813527588e-05,
      "loss": 0.0004,
      "step": 13070
    },
    {
      "epoch": 20.631163708086785,
      "grad_norm": 0.0005686744698323309,
      "learning_rate": 1.7289801649991225e-05,
      "loss": 0.0004,
      "step": 13080
    },
    {
      "epoch": 20.646942800788956,
      "grad_norm": 0.0004605571157298982,
      "learning_rate": 1.7260546486454858e-05,
      "loss": 0.0005,
      "step": 13090
    },
    {
      "epoch": 20.662721893491124,
      "grad_norm": 0.005303764250129461,
      "learning_rate": 1.7231291322918498e-05,
      "loss": 0.0014,
      "step": 13100
    },
    {
      "epoch": 20.678500986193296,
      "grad_norm": 0.0027887988835573196,
      "learning_rate": 1.720203615938213e-05,
      "loss": 0.0001,
      "step": 13110
    },
    {
      "epoch": 20.694280078895464,
      "grad_norm": 0.002099380362778902,
      "learning_rate": 1.7172780995845765e-05,
      "loss": 0.0001,
      "step": 13120
    },
    {
      "epoch": 20.71005917159763,
      "grad_norm": 0.0009263040847145021,
      "learning_rate": 1.7143525832309405e-05,
      "loss": 0.0001,
      "step": 13130
    },
    {
      "epoch": 20.725838264299803,
      "grad_norm": 0.0005891583859920502,
      "learning_rate": 1.711427066877304e-05,
      "loss": 0.0005,
      "step": 13140
    },
    {
      "epoch": 20.74161735700197,
      "grad_norm": 0.001416133134625852,
      "learning_rate": 1.7085015505236675e-05,
      "loss": 0.0001,
      "step": 13150
    },
    {
      "epoch": 20.757396449704142,
      "grad_norm": 0.03279193863272667,
      "learning_rate": 1.7055760341700312e-05,
      "loss": 0.0031,
      "step": 13160
    },
    {
      "epoch": 20.77317554240631,
      "grad_norm": 0.015631163492798805,
      "learning_rate": 1.7026505178163945e-05,
      "loss": 0.0001,
      "step": 13170
    },
    {
      "epoch": 20.78895463510848,
      "grad_norm": 0.0005348908598534763,
      "learning_rate": 1.6997250014627582e-05,
      "loss": 0.0035,
      "step": 13180
    },
    {
      "epoch": 20.80473372781065,
      "grad_norm": 0.0007454592850990593,
      "learning_rate": 1.696799485109122e-05,
      "loss": 0.0001,
      "step": 13190
    },
    {
      "epoch": 20.82051282051282,
      "grad_norm": 0.2868264615535736,
      "learning_rate": 1.6938739687554855e-05,
      "loss": 0.0017,
      "step": 13200
    },
    {
      "epoch": 20.83629191321499,
      "grad_norm": 0.0076197413727641106,
      "learning_rate": 1.690948452401849e-05,
      "loss": 0.0016,
      "step": 13210
    },
    {
      "epoch": 20.85207100591716,
      "grad_norm": 0.0007240448612719774,
      "learning_rate": 1.6880229360482126e-05,
      "loss": 0.0001,
      "step": 13220
    },
    {
      "epoch": 20.86785009861933,
      "grad_norm": 0.012279552407562733,
      "learning_rate": 1.6850974196945762e-05,
      "loss": 0.0008,
      "step": 13230
    },
    {
      "epoch": 20.8836291913215,
      "grad_norm": 0.0005964517476968467,
      "learning_rate": 1.6821719033409396e-05,
      "loss": 0.0001,
      "step": 13240
    },
    {
      "epoch": 20.899408284023668,
      "grad_norm": 0.0005091517814435065,
      "learning_rate": 1.6792463869873036e-05,
      "loss": 0.0092,
      "step": 13250
    },
    {
      "epoch": 20.91518737672584,
      "grad_norm": 0.0005589555948972702,
      "learning_rate": 1.676320870633667e-05,
      "loss": 0.0105,
      "step": 13260
    },
    {
      "epoch": 20.930966469428007,
      "grad_norm": 0.0018962585600093007,
      "learning_rate": 1.6733953542800303e-05,
      "loss": 0.0008,
      "step": 13270
    },
    {
      "epoch": 20.94674556213018,
      "grad_norm": 0.3841184079647064,
      "learning_rate": 1.6704698379263943e-05,
      "loss": 0.0029,
      "step": 13280
    },
    {
      "epoch": 20.962524654832347,
      "grad_norm": 0.391123503446579,
      "learning_rate": 1.6675443215727576e-05,
      "loss": 0.0052,
      "step": 13290
    },
    {
      "epoch": 20.978303747534518,
      "grad_norm": 0.005486364010721445,
      "learning_rate": 1.6646188052191213e-05,
      "loss": 0.0002,
      "step": 13300
    },
    {
      "epoch": 20.994082840236686,
      "grad_norm": 0.001721558510325849,
      "learning_rate": 1.661693288865485e-05,
      "loss": 0.0004,
      "step": 13310
    },
    {
      "epoch": 21.0,
      "eval_accuracy": 0.8670155822528846,
      "eval_loss": 0.9325956106185913,
      "eval_runtime": 204.8434,
      "eval_samples_per_second": 82.082,
      "eval_steps_per_second": 5.131,
      "step": 13314
    },
    {
      "epoch": 21.0094674556213,
      "grad_norm": 0.021733656525611877,
      "learning_rate": 1.6587677725118483e-05,
      "loss": 0.0085,
      "step": 13320
    },
    {
      "epoch": 21.025246548323473,
      "grad_norm": 0.0008530798950232565,
      "learning_rate": 1.655842256158212e-05,
      "loss": 0.0005,
      "step": 13330
    },
    {
      "epoch": 21.04102564102564,
      "grad_norm": 0.000834450765978545,
      "learning_rate": 1.6529167398045756e-05,
      "loss": 0.0044,
      "step": 13340
    },
    {
      "epoch": 21.056804733727812,
      "grad_norm": 0.0008801804506219923,
      "learning_rate": 1.649991223450939e-05,
      "loss": 0.0223,
      "step": 13350
    },
    {
      "epoch": 21.07258382642998,
      "grad_norm": 0.15033359825611115,
      "learning_rate": 1.6470657070973027e-05,
      "loss": 0.0105,
      "step": 13360
    },
    {
      "epoch": 21.088362919132148,
      "grad_norm": 0.3797093629837036,
      "learning_rate": 1.6441401907436663e-05,
      "loss": 0.0012,
      "step": 13370
    },
    {
      "epoch": 21.10414201183432,
      "grad_norm": 0.002163258846849203,
      "learning_rate": 1.64121467439003e-05,
      "loss": 0.0002,
      "step": 13380
    },
    {
      "epoch": 21.119921104536488,
      "grad_norm": 0.035533588379621506,
      "learning_rate": 1.6382891580363933e-05,
      "loss": 0.0002,
      "step": 13390
    },
    {
      "epoch": 21.13570019723866,
      "grad_norm": 0.00475927023217082,
      "learning_rate": 1.635363641682757e-05,
      "loss": 0.0119,
      "step": 13400
    },
    {
      "epoch": 21.151479289940827,
      "grad_norm": 0.0006165693048387766,
      "learning_rate": 1.6324381253291207e-05,
      "loss": 0.0004,
      "step": 13410
    },
    {
      "epoch": 21.167258382643,
      "grad_norm": 0.0013018775498494506,
      "learning_rate": 1.629512608975484e-05,
      "loss": 0.0029,
      "step": 13420
    },
    {
      "epoch": 21.183037475345166,
      "grad_norm": 0.0036345990374684334,
      "learning_rate": 1.626587092621848e-05,
      "loss": 0.0003,
      "step": 13430
    },
    {
      "epoch": 21.198816568047338,
      "grad_norm": 0.7619420289993286,
      "learning_rate": 1.6236615762682114e-05,
      "loss": 0.002,
      "step": 13440
    },
    {
      "epoch": 21.214595660749506,
      "grad_norm": 0.0119115449488163,
      "learning_rate": 1.6207360599145747e-05,
      "loss": 0.0004,
      "step": 13450
    },
    {
      "epoch": 21.230374753451677,
      "grad_norm": 0.0014698720769956708,
      "learning_rate": 1.6178105435609387e-05,
      "loss": 0.0003,
      "step": 13460
    },
    {
      "epoch": 21.246153846153845,
      "grad_norm": 0.012821286916732788,
      "learning_rate": 1.614885027207302e-05,
      "loss": 0.0015,
      "step": 13470
    },
    {
      "epoch": 21.261932938856017,
      "grad_norm": 0.011289166286587715,
      "learning_rate": 1.6119595108536657e-05,
      "loss": 0.0002,
      "step": 13480
    },
    {
      "epoch": 21.277712031558185,
      "grad_norm": 0.1423947811126709,
      "learning_rate": 1.6090339945000294e-05,
      "loss": 0.0011,
      "step": 13490
    },
    {
      "epoch": 21.293491124260356,
      "grad_norm": 0.0008587966440245509,
      "learning_rate": 1.6061084781463928e-05,
      "loss": 0.0011,
      "step": 13500
    },
    {
      "epoch": 21.309270216962524,
      "grad_norm": 0.0021467164624482393,
      "learning_rate": 1.6031829617927564e-05,
      "loss": 0.002,
      "step": 13510
    },
    {
      "epoch": 21.325049309664696,
      "grad_norm": 0.005872789770364761,
      "learning_rate": 1.60025744543912e-05,
      "loss": 0.0004,
      "step": 13520
    },
    {
      "epoch": 21.340828402366864,
      "grad_norm": 0.007421239744871855,
      "learning_rate": 1.5973319290854838e-05,
      "loss": 0.0002,
      "step": 13530
    },
    {
      "epoch": 21.356607495069035,
      "grad_norm": 0.001328734215348959,
      "learning_rate": 1.594406412731847e-05,
      "loss": 0.0042,
      "step": 13540
    },
    {
      "epoch": 21.372386587771203,
      "grad_norm": 0.004015407059341669,
      "learning_rate": 1.5914808963782108e-05,
      "loss": 0.0007,
      "step": 13550
    },
    {
      "epoch": 21.388165680473374,
      "grad_norm": 0.0027573599945753813,
      "learning_rate": 1.5885553800245745e-05,
      "loss": 0.001,
      "step": 13560
    },
    {
      "epoch": 21.403944773175542,
      "grad_norm": 0.000798735418356955,
      "learning_rate": 1.5856298636709378e-05,
      "loss": 0.0001,
      "step": 13570
    },
    {
      "epoch": 21.419723865877714,
      "grad_norm": 0.0016419385792687535,
      "learning_rate": 1.5827043473173018e-05,
      "loss": 0.0004,
      "step": 13580
    },
    {
      "epoch": 21.43550295857988,
      "grad_norm": 0.0007050114218145609,
      "learning_rate": 1.579778830963665e-05,
      "loss": 0.0003,
      "step": 13590
    },
    {
      "epoch": 21.45128205128205,
      "grad_norm": 0.002647578017786145,
      "learning_rate": 1.576853314610029e-05,
      "loss": 0.0001,
      "step": 13600
    },
    {
      "epoch": 21.46706114398422,
      "grad_norm": 0.0013721726136282086,
      "learning_rate": 1.5739277982563925e-05,
      "loss": 0.0001,
      "step": 13610
    },
    {
      "epoch": 21.48284023668639,
      "grad_norm": 0.0007025881204754114,
      "learning_rate": 1.571002281902756e-05,
      "loss": 0.0002,
      "step": 13620
    },
    {
      "epoch": 21.49861932938856,
      "grad_norm": 0.0023246610071510077,
      "learning_rate": 1.5680767655491195e-05,
      "loss": 0.0108,
      "step": 13630
    },
    {
      "epoch": 21.51439842209073,
      "grad_norm": 0.0006649020360782743,
      "learning_rate": 1.5651512491954832e-05,
      "loss": 0.0007,
      "step": 13640
    },
    {
      "epoch": 21.5301775147929,
      "grad_norm": 0.0023295695427805185,
      "learning_rate": 1.5622257328418465e-05,
      "loss": 0.0006,
      "step": 13650
    },
    {
      "epoch": 21.545956607495068,
      "grad_norm": 0.0007995358901098371,
      "learning_rate": 1.5593002164882102e-05,
      "loss": 0.0117,
      "step": 13660
    },
    {
      "epoch": 21.56173570019724,
      "grad_norm": 0.07851125299930573,
      "learning_rate": 1.556374700134574e-05,
      "loss": 0.0008,
      "step": 13670
    },
    {
      "epoch": 21.577514792899407,
      "grad_norm": 0.0035764107014983892,
      "learning_rate": 1.5534491837809372e-05,
      "loss": 0.0005,
      "step": 13680
    },
    {
      "epoch": 21.59329388560158,
      "grad_norm": 0.0015995025169104338,
      "learning_rate": 1.550523667427301e-05,
      "loss": 0.0001,
      "step": 13690
    },
    {
      "epoch": 21.609072978303747,
      "grad_norm": 0.002475213259458542,
      "learning_rate": 1.5475981510736646e-05,
      "loss": 0.0001,
      "step": 13700
    },
    {
      "epoch": 21.624852071005918,
      "grad_norm": 0.0014150008792057633,
      "learning_rate": 1.5446726347200282e-05,
      "loss": 0.0056,
      "step": 13710
    },
    {
      "epoch": 21.640631163708086,
      "grad_norm": 0.011957303620874882,
      "learning_rate": 1.5417471183663916e-05,
      "loss": 0.0023,
      "step": 13720
    },
    {
      "epoch": 21.656410256410258,
      "grad_norm": 0.06131591275334358,
      "learning_rate": 1.5388216020127553e-05,
      "loss": 0.0004,
      "step": 13730
    },
    {
      "epoch": 21.672189349112426,
      "grad_norm": 0.004026828333735466,
      "learning_rate": 1.535896085659119e-05,
      "loss": 0.0022,
      "step": 13740
    },
    {
      "epoch": 21.687968441814597,
      "grad_norm": 0.004786651115864515,
      "learning_rate": 1.5329705693054826e-05,
      "loss": 0.0004,
      "step": 13750
    },
    {
      "epoch": 21.703747534516765,
      "grad_norm": 0.0035960583481937647,
      "learning_rate": 1.5300450529518463e-05,
      "loss": 0.0015,
      "step": 13760
    },
    {
      "epoch": 21.719526627218936,
      "grad_norm": 0.004954049363732338,
      "learning_rate": 1.5271195365982096e-05,
      "loss": 0.0053,
      "step": 13770
    },
    {
      "epoch": 21.735305719921104,
      "grad_norm": 0.000771326303947717,
      "learning_rate": 1.5241940202445731e-05,
      "loss": 0.0004,
      "step": 13780
    },
    {
      "epoch": 21.751084812623276,
      "grad_norm": 0.007372483145445585,
      "learning_rate": 1.521268503890937e-05,
      "loss": 0.0055,
      "step": 13790
    },
    {
      "epoch": 21.766863905325444,
      "grad_norm": 0.0016414847923442721,
      "learning_rate": 1.5183429875373003e-05,
      "loss": 0.0013,
      "step": 13800
    },
    {
      "epoch": 21.78264299802761,
      "grad_norm": 0.0015402025310322642,
      "learning_rate": 1.5154174711836642e-05,
      "loss": 0.0016,
      "step": 13810
    },
    {
      "epoch": 21.798422090729783,
      "grad_norm": 0.00856893789023161,
      "learning_rate": 1.5124919548300277e-05,
      "loss": 0.0001,
      "step": 13820
    },
    {
      "epoch": 21.81420118343195,
      "grad_norm": 0.0021176568698138,
      "learning_rate": 1.509566438476391e-05,
      "loss": 0.0001,
      "step": 13830
    },
    {
      "epoch": 21.829980276134123,
      "grad_norm": 0.0010703130392357707,
      "learning_rate": 1.5066409221227548e-05,
      "loss": 0.0008,
      "step": 13840
    },
    {
      "epoch": 21.84575936883629,
      "grad_norm": 0.0009060890297405422,
      "learning_rate": 1.5037154057691183e-05,
      "loss": 0.0001,
      "step": 13850
    },
    {
      "epoch": 21.861538461538462,
      "grad_norm": 0.09089434891939163,
      "learning_rate": 1.500789889415482e-05,
      "loss": 0.003,
      "step": 13860
    },
    {
      "epoch": 21.87731755424063,
      "grad_norm": 0.001052149455063045,
      "learning_rate": 1.4978643730618455e-05,
      "loss": 0.0002,
      "step": 13870
    },
    {
      "epoch": 21.8930966469428,
      "grad_norm": 0.0013111267471686006,
      "learning_rate": 1.494938856708209e-05,
      "loss": 0.0021,
      "step": 13880
    },
    {
      "epoch": 21.90887573964497,
      "grad_norm": 0.0012866145698353648,
      "learning_rate": 1.4920133403545727e-05,
      "loss": 0.0004,
      "step": 13890
    },
    {
      "epoch": 21.92465483234714,
      "grad_norm": 0.01952199637889862,
      "learning_rate": 1.4890878240009362e-05,
      "loss": 0.0001,
      "step": 13900
    },
    {
      "epoch": 21.94043392504931,
      "grad_norm": 0.004958416800945997,
      "learning_rate": 1.4861623076472997e-05,
      "loss": 0.0001,
      "step": 13910
    },
    {
      "epoch": 21.95621301775148,
      "grad_norm": 0.0018382023554295301,
      "learning_rate": 1.4832367912936634e-05,
      "loss": 0.0001,
      "step": 13920
    },
    {
      "epoch": 21.971992110453648,
      "grad_norm": 0.010126585140824318,
      "learning_rate": 1.4803112749400269e-05,
      "loss": 0.0001,
      "step": 13930
    },
    {
      "epoch": 21.98777120315582,
      "grad_norm": 0.0011916827643290162,
      "learning_rate": 1.4773857585863907e-05,
      "loss": 0.0001,
      "step": 13940
    },
    {
      "epoch": 22.0,
      "eval_accuracy": 0.8680861187105983,
      "eval_loss": 0.9535664319992065,
      "eval_runtime": 200.6504,
      "eval_samples_per_second": 83.797,
      "eval_steps_per_second": 5.238,
      "step": 13948
    }
  ],
  "logging_steps": 10,
  "max_steps": 18990,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.9134013582720565e+19,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
